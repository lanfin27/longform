"""
ì”¬ ë¶„ì„ê¸° - ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì”¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³  ì—°ì¶œê°€ì´ë“œ ìƒì„±

ì£¼ìš” ê¸°ëŠ¥:
1. ìŠ¤í¬ë¦½íŠ¸ â†’ ì”¬ ìë™ ë¶„í•  (ì¥ë©´ ì „í™˜ ê°ì§€)
2. ê° ì”¬ì˜ ì—°ì¶œê°€ì´ë“œ ìƒì„±
3. ë“±ì¥ ìºë¦­í„° ì¶”ì¶œ (ìƒì„¸ ì™¸ëª¨ í”„ë¡¬í”„íŠ¸ í¬í•¨)
4. ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
"""
import json
from pathlib import Path
from typing import List, Dict, Optional

import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from config.settings import ANTHROPIC_API_KEY, GOOGLE_API_KEY, GEMINI_API_KEY
from core.prompt.prompt_template_manager import get_template_manager

# ë””ë²„ê·¸ ëª¨ë“œ (Trueë¡œ ì„¤ì •í•˜ë©´ ìƒì„¸ ë¡œê·¸ ì¶œë ¥)
DEBUG = True

def debug_log(message: str):
    """ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥"""
    if DEBUG:
        print(f"[SceneAnalyzer] {message}")


# ============================================================
# ğŸ”´ ìºë¦­í„° ì´ë¦„ ìœ íš¨ì„± ê²€ì¦ìš© ìƒìˆ˜ ë° í•¨ìˆ˜ (Problem 49)
# ============================================================

# ì˜ëª»ëœ ìºë¦­í„°ë¡œ ì¶”ì¶œë˜ë©´ ì•ˆ ë˜ëŠ” ë‹¨ì–´ ëª©ë¡
INVALID_CHARACTER_WORDS = {
    # ì¡°ì‚¬/ì–´ë¯¸ê°€ ë¶™ì€ íŒ¨í„´
    'ì˜', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ë¥¼', 'ì„', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ',
    'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì™€', 'ê³¼', 'ì´ë‹¤', 'ì´ê³ ', 'ì´ë©°',

    # ì¼ë°˜ ëª…ì‚¬
    'íšŒì‚¬', 'ê¸°ì—…', 'ë¸Œëœë“œ', 'ì œí’ˆ', 'ì„œë¹„ìŠ¤', 'ì‹œì¥', 'ì‚°ì—…',
    'ê²½ìŸ', 'ì„±ì¥', 'ë§¤ì¶œ', 'ì´ìµ', 'ìˆ˜ìµ', 'íˆ¬ì', 'ê°€ì¹˜',
    'ì½˜í…ì¸ ', 'í”Œë«í¼', 'ì‚¬ì—…', 'ì „ëµ', 'ë¹„ì „', 'ëª©í‘œ',
    'íšŒì‚¬ì˜', 'ê¸°ì—…ì˜', 'ë¸Œëœë“œì˜', 'ì œí’ˆì˜', 'ì„œë¹„ìŠ¤ì˜',
    'ë¸Œëœë“œì´', 'íšŒì‚¬ê°€', 'ê¸°ì—…ì´', 'ì œí’ˆì´',

    # ì§ì±…ë§Œ (ì´ë¦„ ì—†ì´)
    'ëŒ€í‘œ', 'íšŒì¥', 'ì‚¬ì¥', 'ì´ì‚¬', 'ì„ì›', 'ì°½ì—…ì', 'ì„¤ë¦½ì',
    'ceo', 'cfo', 'cto', 'coo',

    # êµ­ê°€/ì§€ì—­
    'í•œêµ­', 'ë¯¸êµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ì‚¬ìš°ë””', 'ìœ ëŸ½', 'ì•„ì‹œì•„',
    'ì‚¬ìš°ë””ì˜', 'í•œêµ­ì˜', 'ë¯¸êµ­ì˜', 'ì¤‘êµ­ì˜', 'ì¼ë³¸ì˜',
    'ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„', 'ì•„ë¼ë¹„ì•„', 'ë¼ë¹„ì•„',

    # ì¼ë°˜ ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ê·¼
    'í•˜ëŠ”', 'ì´ë„ëŠ”', 'ë§Œë“œëŠ”', 'ì„±ì¥í•˜ëŠ”', 'ë°œì „í•˜ëŠ”',
    'ì‚¬ì‹¤ìƒ', 'ì‹¤ì§ˆì ', 'ê²°êµ­', 'ê²°ê³¼ì ',

    # ê¸°íƒ€ ì˜ëª» ì¶”ì¶œë˜ëŠ” íŒ¨í„´
    'êµ¬ê°•ê³¼', 'ê²½ì œë§ˆì €', 'ììœ ë³´ë‹¤', 'ë¼ë¹„ì•„ë¥¼', 'ëˆ„êµ¬ë„',
    'ì´ë²ˆ', 'ì§€ë‚œ', 'ë‹¤ìŒ', 'ì˜¬í•´', 'ë‚´ë…„', 'ì‘ë…„',
    'í•˜ë‚˜', 'ë‘˜', 'ì…‹', 'ë„·', 'ë‹¤ì„¯',
}

# ì•Œë ¤ì§„ ìºë¦­í„° IP ëª©ë¡ (ë™ë¬¼, ë§ˆìŠ¤ì½”íŠ¸, ê°€ìƒ ìºë¦­í„°)
KNOWN_CHARACTER_IPS = {
    'ì•„ê¸°ìƒì–´': {'name_en': 'Baby Shark', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'ë” í•‘í¬í ì»´í¼ë‹ˆ'},
    'ë² ì´ë¹„ìƒ¤í¬': {'name_en': 'Baby Shark', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'ë” í•‘í¬í ì»´í¼ë‹ˆ'},
    'í•‘í¬í': {'name_en': 'Pinkfong', 'category': 'ë§ˆìŠ¤ì½”íŠ¸', 'owner': 'ë” í•‘í¬í ì»´í¼ë‹ˆ'},
    'ë½€ë¡œë¡œ': {'name_en': 'Pororo', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'ì•„ì´ì½”ë‹‰ìŠ¤'},
    'ë¼ë°”': {'name_en': 'Larva', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'TUBAn'},
    'í­ìˆ˜': {'name_en': 'Pengsoo', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'EBS'},
    'ì˜¬ë¦¬': {'name_en': 'Ollie', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'ë” í•‘í¬í ì»´í¼ë‹ˆ'},
    'í˜¸ê¸°': {'name_en': 'Hogi', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'ë” í•‘í¬í ì»´í¼ë‹ˆ'},
    'í”¼ì¹´ì¸„': {'name_en': 'Pikachu', 'category': 'ë™ë¬¼ ìºë¦­í„°', 'owner': 'Nintendo'},
    'í—¬ë¡œí‚¤í‹°': {'name_en': 'Hello Kitty', 'category': 'ë§ˆìŠ¤ì½”íŠ¸', 'owner': 'Sanrio'},
    'ì¹´ì¹´ì˜¤í”„ë Œì¦ˆ': {'name_en': 'Kakao Friends', 'category': 'ë§ˆìŠ¤ì½”íŠ¸', 'owner': 'Kakao'},
    'ë¼ì¸í”„ë Œì¦ˆ': {'name_en': 'Line Friends', 'category': 'ë§ˆìŠ¤ì½”íŠ¸', 'owner': 'Line'},
    'ë¡œë³´ì¹´í´ë¦¬': {'name_en': 'Robocar Poli', 'category': 'ë¡œë´‡ ìºë¦­í„°', 'owner': 'Roi Visual'},
    'íƒ€ìš”': {'name_en': 'Tayo', 'category': 'ìºë¦­í„°', 'owner': 'Iconix'},
    'ì½©ìˆœì´': {'name_en': 'Kongsuni', 'category': 'ìºë¦­í„°', 'owner': 'Young Toys'},
    'ë˜ë´‡': {'name_en': 'Tobot', 'category': 'ë¡œë´‡ ìºë¦­í„°', 'owner': 'Young Toys'},
}


def is_valid_person_name(name: str) -> bool:
    """
    ìœ íš¨í•œ ì¸ë¬¼(ì‚¬ëŒ) ì´ë¦„ì¸ì§€ ê²€ì¦

    Rules:
    1. ìµœì†Œ 2ê¸€ì, ìµœëŒ€ 10ê¸€ì
    2. ê¸ˆì§€ ë‹¨ì–´ ëª©ë¡ì— ì—†ìŒ
    3. ì¡°ì‚¬ë¡œ ëë‚˜ì§€ ì•ŠìŒ
    4. ìˆ«ìë§Œ ìˆì§€ ì•ŠìŒ
    5. í•œê¸€ ììŒ/ëª¨ìŒë§Œ ìˆì§€ ì•ŠìŒ
    """
    import re

    if not name or len(name) < 2 or len(name) > 10:
        return False

    name_clean = name.strip()
    name_lower = name_clean.lower()

    # ê¸ˆì§€ ë‹¨ì–´ ì²´í¬
    if name_lower in INVALID_CHARACTER_WORDS:
        debug_log(f"    âŒ ê¸ˆì§€ ë‹¨ì–´ë¡œ í•„í„°ë§: '{name}'")
        return False

    # ì¡°ì‚¬ë¡œ ëë‚˜ëŠ”ì§€ ì²´í¬ (í•œê¸€ 2-4ì + ì¡°ì‚¬ íŒ¨í„´)
    particle_endings = ['ì˜', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ë¥¼', 'ì„', 'ì—', 'ë¡œ', 'ê³¼', 'ì™€', 'ë„']
    for particle in particle_endings:
        if name_clean.endswith(particle) and len(name_clean) > 2:
            # ì˜ˆì™¸: "ì†ì •ì˜" ê°™ì€ ì‹¤ì œ ì´ë¦„ (3ê¸€ì ì„±+ì´ë¦„)
            # ì´ë¦„ íŒ¨í„´: ë³´í†µ 2-4ê¸€ìì´ê³  ì¡°ì‚¬ê°€ í¬í•¨ë˜ë©´ ì•ˆë¨
            # "~ì˜"ë¡œ ëë‚˜ëŠ” 3ê¸€ì ì´ë¦„ì€ ë“œë¬¼ì§€ë§Œ í—ˆìš© (ì†ì •ì˜ ë“±)
            if particle == 'ì˜' and len(name_clean) == 3 and re.match(r'^[ê°€-í£]{3}$', name_clean):
                continue  # í—ˆìš©
            debug_log(f"    âŒ ì¡°ì‚¬ë¡œ ëë‚¨: '{name}' (ì¡°ì‚¬: {particle})")
            return False

    # ìˆ«ìë§Œ ìˆëŠ”ì§€ ì²´í¬
    if name_clean.isdigit():
        return False

    # í•œê¸€ ììŒ/ëª¨ìŒë§Œ ìˆëŠ”ì§€ ì²´í¬
    if re.match(r'^[ã„±-ã…ã…-ã…£]+$', name_clean):
        return False

    # ì¼ë°˜ì ì¸ 2ê¸€ì ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ê·¼ í•„í„°
    common_verbs = {
        'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'ê°™ì€', 'ë‹¤ë¥¸', 'ëª¨ë“ ', 'ê°ê°',
        'ìƒˆë¡œ', 'ë‹¤ì‹œ', 'ë§¤ìš°', 'ì •ë§', 'ì•„ì£¼', 'ë”ìš±',
    }
    if name_lower in common_verbs:
        debug_log(f"    âŒ ì¼ë°˜ ë™ì‚¬/í˜•ìš©ì‚¬: '{name}'")
        return False

    # í•œê¸€ ì´ë¦„ íŒ¨í„´ í™•ì¸ (2-4ì ì™„ì„±í˜• í•œê¸€)
    if re.match(r'^[ê°€-í£]{2,4}$', name_clean):
        return True

    # ì˜ë¬¸ ì´ë¦„ íŒ¨í„´ (First Last)
    if re.match(r'^[A-Z][a-z]+(\s+[A-Z][a-z]+)+$', name_clean):
        return True

    # ì•„ë/ì™¸ë˜ ì´ë¦„ íŒ¨í„´ (ê³µë°± í¬í•¨ í•œê¸€)
    if re.match(r'^[ê°€-í£]+(\s+[ê°€-í£]+)+$', name_clean):
        return True

    # ê·¸ ì™¸ í•œê¸€ í¬í•¨ íŒ¨í„´ (5ì ì´ìƒì€ ì¡°ì‹¬)
    if len(name_clean) <= 5 and re.search(r'[ê°€-í£]', name_clean):
        return True

    debug_log(f"    âŒ íŒ¨í„´ ë¶ˆì¼ì¹˜: '{name}'")
    return False


class SceneAnalyzer:
    """AI ê¸°ë°˜ ì”¬ ë¶„ì„ê¸°"""

    def __init__(
        self,
        provider: str = "anthropic",
        model_name: str = None,
        max_output_tokens: int = None
    ):
        """
        Args:
            provider: AI ì œê³µì ("anthropic", "google", "gemini", "openai")
            model_name: ì •í™•í•œ ëª¨ë¸ ID (ì˜ˆ: "gemini-2.0-flash-exp")
            max_output_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜ (Noneì´ë©´ ëª¨ë¸ ê¸°ë³¸ê°’)
        """
        debug_log(f"ì´ˆê¸°í™” ì‹œì‘ (provider={provider}, model={model_name}, max_tokens={max_output_tokens})")

        self.provider = provider
        self.requested_model_name = model_name  # â­ ìš”ì²­ëœ ëª¨ë¸ëª… ì €ì¥
        self.max_output_tokens = max_output_tokens or 65536  # â­ ê¸°ë³¸ê°’ 64K
        self.template_manager = get_template_manager()
        self.client = None
        self.gemini_model = None
        self.gemini_available = False

        # í…œí”Œë¦¿ ë§¤ë‹ˆì € í™•ì¸
        scene_prompt = self.template_manager.get_prompt("scene_analysis")
        debug_log(f"scene_analysis í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(scene_prompt)} ë¬¸ì")

        if not scene_prompt:
            debug_log("ê²½ê³ : scene_analysis í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")

        # providerë³„ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if provider in ("google", "gemini"):
            self._init_gemini()
        elif provider == "anthropic":
            self._init_anthropic()
        elif provider == "openai":
            self._init_openai()
        else:
            # ê¸°ë³¸ê°’: Anthropic
            debug_log(f"ì•Œ ìˆ˜ ì—†ëŠ” provider '{provider}', Anthropicìœ¼ë¡œ ëŒ€ì²´")
            self._init_anthropic()

    def _init_anthropic(self):
        """Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        from anthropic import Anthropic

        if not ANTHROPIC_API_KEY:
            raise ValueError("ANTHROPIC_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. API ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")

        self.client = Anthropic(api_key=ANTHROPIC_API_KEY)
        self.provider = "anthropic"
        debug_log("Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def _init_gemini(self):
        """Google Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            import google.generativeai as genai

            # API í‚¤ í™•ì¸ (GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEY)
            api_key = GOOGLE_API_KEY or GEMINI_API_KEY
            if not api_key:
                error_msg = "GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. API ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ì„¤ì •í•˜ì„¸ìš”."
                debug_log(f"âŒ {error_msg}")
                raise ValueError(error_msg)

            genai.configure(api_key=api_key)

            # â­ ìš”ì²­ëœ ëª¨ë¸ëª…ì´ ìˆìœ¼ë©´ í•´ë‹¹ ëª¨ë¸ ì‚¬ìš©
            if self.requested_model_name:
                model_candidates = [self.requested_model_name]
                debug_log(f"ğŸ“Œ ìš”ì²­ëœ ëª¨ë¸ ì‚¬ìš©: {self.requested_model_name}")
            else:
                # ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ëª¨ë¸ ì‹œë„ (API ë²„ì „ ë³€ê²½ì— ëŒ€ì‘)
                model_candidates = [
                    "gemini-2.0-flash-exp",     # ìµœì‹  2.0 (ë¬´ë£Œ, ë¹ ë¦„, 64K ì¶œë ¥)
                    "gemini-2.0-flash",         # 2.0 ì•ˆì •
                    "gemini-1.5-flash",         # 1.5 ê¸°ë³¸
                    "gemini-pro",               # Pro ê¸°ë³¸
                ]

            self.gemini_model = None
            self.gemini_model_name = None

            for model_name in model_candidates:
                try:
                    debug_log(f"ëª¨ë¸ '{model_name}' ì‹œë„ ì¤‘...")
                    test_model = genai.GenerativeModel(model_name)

                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
                    test_response = test_model.generate_content(
                        "Say OK",
                        generation_config={"max_output_tokens": 5}
                    )

                    if test_response and (test_response.text or
                        (hasattr(test_response, 'candidates') and test_response.candidates)):
                        self.gemini_model = test_model
                        self.gemini_model_name = model_name
                        debug_log(f"âœ… ëª¨ë¸ '{model_name}' ì‚¬ìš© ê°€ëŠ¥!")
                        break

                except Exception as model_error:
                    debug_log(f"âŒ ëª¨ë¸ '{model_name}' ì‹¤íŒ¨: {model_error}")
                    continue

            if self.gemini_model is None:
                raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

            self.provider = "google"
            self.gemini_available = True
            debug_log(f"âœ… Google Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            debug_log(f"   ğŸ“Œ ëª¨ë¸: {self.gemini_model_name}")
            debug_log(f"   ğŸ“Œ ìµœëŒ€ ì¶œë ¥ í† í°: {self.max_output_tokens:,}")

        except ImportError as e:
            error_msg = """
âŒ google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

ì„¤ì¹˜ ë°©ë²•:
  pip install google-generativeai

ì„¤ì¹˜ í›„ ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.
"""
            debug_log(error_msg)
            self.gemini_available = False
            raise ImportError(error_msg) from e

        except Exception as e:
            debug_log(f"âŒ Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gemini_available = False
            raise

    def _init_openai(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            from openai import OpenAI
            import os

            api_key = os.environ.get("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. API ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")

            self.client = OpenAI(api_key=api_key)
            self.provider = "openai"
            debug_log("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

        except ImportError as e:
            error_msg = "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai"
            debug_log(error_msg)
            raise ImportError(error_msg) from e

    def analyze_script(
        self,
        script: str,
        language: str = "ko",
        template_id: str = "scene_analysis"
    ) -> Dict:
        """
        ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì”¬, ìºë¦­í„°, ì—°ì¶œê°€ì´ë“œ ì¶”ì¶œ

        Args:
            script: ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
            language: ì–¸ì–´ ì½”ë“œ
            template_id: ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ID

        Returns:
            {
                "scenes": [...],
                "characters": [...],
                "total_scenes": int,
                "estimated_duration": float
            }
        """
        debug_log(f"analyze_script ì‹œì‘")
        debug_log(f"  ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´: {len(script)} ë¬¸ì")
        debug_log(f"  ì–¸ì–´: {language}, í…œí”Œë¦¿ ID: {template_id}")

        # ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦
        if not script or len(script.strip()) < 10:
            debug_log("ì˜¤ë¥˜: ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
            return {
                "scenes": [],
                "characters": [],
                "total_scenes": 0,
                "estimated_duration": 0,
                "error": "ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
            }

        # í…œí”Œë¦¿ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        template = self.template_manager.get_template(template_id)
        
        # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‹œë„
        if not template and template_id != "scene_analysis":
             debug_log(f"ê²½ê³ : í…œí”Œë¦¿ '{template_id}' ì—†ìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©.")
             template = self.template_manager.get_template("scene_analysis")
             
        base_prompt = template.prompt if template else ""

        debug_log(f"  base_prompt ê¸¸ì´: {len(base_prompt)} ë¬¸ì")
        debug_log(f"  ì‚¬ìš© í…œí”Œë¦¿: {template.name if template else 'Unknown'} ({template_id})")
        debug_log(f"  ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì‚¬ìš©: {not template.is_default if template else 'N/A'}")

        if not base_prompt:
            debug_log("ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return {
                "scenes": [],
                "characters": [],
                "total_scenes": 0,
                "estimated_duration": 0,
                "error": "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            }

        prompt = f"""{base_prompt}

## ìŠ¤í¬ë¦½íŠ¸
{script}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        debug_log(f"  ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        debug_log(f"  provider: {self.provider}")

        try:
            # providerë³„ API í˜¸ì¶œ
            if self.provider == "google":
                # â­ finish_reasonë„ í•¨ê»˜ ë°›ì•„ì„œ MAX_TOKENS ì‹œ ì´ì–´ì„œ ìƒì„±
                result_text, finish_reason = self._call_gemini_with_status(prompt)

                # â­ MAX_TOKENSë¡œ ì˜ë¦° ê²½ìš° ì´ì–´ì„œ ìƒì„±
                if finish_reason == 2:
                    debug_log("  ğŸ”„ MAX_TOKENS ê°ì§€ â†’ ì´ì–´ì„œ ìƒì„± ì‹œì‘")
                    result_text = self._continue_gemini_generation(result_text, script)
            else:
                result_text = self._call_anthropic(prompt)

            debug_log(f"  API ì‘ë‹µ ê¸¸ì´: {len(result_text)} ë¬¸ì")
            debug_log(f"  ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result_text[:200]}...")

        except Exception as e:
            debug_log(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            debug_log(traceback.format_exc())
            return {
                "scenes": [],
                "characters": [],
                "total_scenes": 0,
                "estimated_duration": 0,
                "error": f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
            }

        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_str = result_text
        json_truncated = False

        if "```json" in json_str:
            start = json_str.find("```json") + 7
            end = json_str.rfind("```")
            if end > start:
                json_str = json_str[start:end].strip()
            else:
                # ë‹«ëŠ” ``` ì—†ìŒ - ì˜ë¦° ê²ƒ
                json_str = json_str[start:].strip()
                json_truncated = True
                debug_log("  âš ï¸ JSON ë¸”ë¡ì´ ë‹«íˆì§€ ì•ŠìŒ (ì˜ë¦¼ ì˜ì‹¬)")
        elif "```" in json_str:
            start = json_str.find("```") + 3
            end = json_str.rfind("```")
            if end > start:
                json_str = json_str[start:end].strip()
            else:
                json_str = json_str[start:].strip()
                json_truncated = True

        try:
            result = json.loads(json_str)
            debug_log(f"  JSON íŒŒì‹± ì„±ê³µ: ì”¬ {len(result.get('scenes', []))}ê°œ")
            debug_log(f"    persons: {len(result.get('persons', []))}ëª…, characters: {len(result.get('characters', []))}ê°œ")

            # === ìºë¦­í„° ë°ì´í„° ì •ê·œí™” (v2.3: persons + characters ë³‘í•©) ===
            raw_characters = result.get("characters", [])
            raw_persons = result.get("persons", [])  # v2.3 í”„ë¡¬í”„íŠ¸
            result["characters"] = self._normalize_characters(raw_characters, raw_persons)
            debug_log(f"  ìºë¦­í„° ì •ê·œí™” ì™„ë£Œ: {len(result['characters'])}ê°œ (í•„í„°ë§ í›„)")

            # ğŸ”´ ìºë¦­í„°ê°€ ì—†ìœ¼ë©´ ì”¬ì—ì„œ í´ë°± ì¶”ì¶œ
            if not result["characters"]:
                debug_log("  âš ï¸ ìºë¦­í„°ê°€ ë¹„ì–´ìˆìŒ! ì”¬ì—ì„œ í´ë°± ì¶”ì¶œ ì‹œë„...")
                result["characters"] = self._extract_characters_from_scenes(result.get("scenes", []), script)
                debug_log(f"  ğŸ“Œ í´ë°± ì¶”ì¶œ ê²°ê³¼: {len(result['characters'])}ëª…")

            # === visual_promptê°€ ë¹„ì–´ìˆìœ¼ë©´ ìë™ ìƒì„± ===
            result["characters"] = self._ensure_visual_prompts(result["characters"], script)
            debug_log(f"  visual_prompt í™•ì¸ ì™„ë£Œ")

            # === ì”¬ ë°ì´í„° ì •ê·œí™” ===
            raw_scenes = result.get("scenes", [])
            result["scenes"] = self._normalize_scenes(raw_scenes)

        except json.JSONDecodeError as e:
            debug_log(f"  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            debug_log(f"  íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸ (ì²˜ìŒ 300ì): {json_str[:300]}...")

            # â­ JSON ë³µêµ¬ ì‹œë„
            debug_log("  JSON ë³µêµ¬ ì‹œë„ ì¤‘...")
            repaired_json = self._repair_truncated_json(json_str)

            try:
                result = json.loads(repaired_json)
                debug_log(f"  âœ… JSON ë³µêµ¬ ì„±ê³µ! ì”¬ {len(result.get('scenes', []))}ê°œ")
                debug_log(f"    persons: {len(result.get('persons', []))}ëª…, characters: {len(result.get('characters', []))}ê°œ")

                # ì •ê·œí™” ì§„í–‰ (v2.3: persons + characters ë³‘í•©)
                raw_characters = result.get("characters", [])
                raw_persons = result.get("persons", [])
                result["characters"] = self._normalize_characters(raw_characters, raw_persons)

                # ğŸ”´ ìºë¦­í„°ê°€ ì—†ìœ¼ë©´ ì”¬ì—ì„œ í´ë°± ì¶”ì¶œ
                if not result["characters"]:
                    debug_log("  âš ï¸ (ë³µêµ¬ í›„) ìºë¦­í„°ê°€ ë¹„ì–´ìˆìŒ! ì”¬ì—ì„œ í´ë°± ì¶”ì¶œ ì‹œë„...")
                    result["characters"] = self._extract_characters_from_scenes(result.get("scenes", []), script)
                    debug_log(f"  ğŸ“Œ í´ë°± ì¶”ì¶œ ê²°ê³¼: {len(result['characters'])}ëª…")

                result["characters"] = self._ensure_visual_prompts(result["characters"], script)
                raw_scenes = result.get("scenes", [])
                result["scenes"] = self._normalize_scenes(raw_scenes)

            except json.JSONDecodeError as e2:
                debug_log(f"  âŒ JSON ë³µêµ¬ í›„ì—ë„ íŒŒì‹± ì‹¤íŒ¨: {e2}")
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
                result = {
                    "scenes": [],
                    "characters": [],
                    "total_scenes": 0,
                    "estimated_duration": 0,
                    "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                    "raw_response": json_str[:500]
                }

        # ğŸ”´ ìŠ¤í¬ë¦½íŠ¸ ë³´ì¡´ ê²€ì¦ (Problem 51 í•´ê²°)
        if result.get('scenes'):
            debug_log("  ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë³´ì¡´ ê²€ì¦ ì‹œì‘...")
            result = self._validate_script_preservation(script, result)

            # ê²€ì¦ ê²°ê³¼ ë¡œê¹…
            validation = result.get('_script_validation', {})
            if validation.get('warning_count', 0) > 0:
                debug_log(f"  âš ï¸ AIê°€ {validation['warning_count']}ê°œ ì”¬ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë³€ì¡°í•¨")
                if validation.get('modified_count', 0) > 0:
                    debug_log(f"     â†’ {validation['modified_count']}ê°œ ìë™ ìˆ˜ì •ë¨")

        return result

    def _normalize_characters(self, raw_characters: list, raw_persons: list = None) -> list:
        """
        ìºë¦­í„° ë°°ì—´ ì •ê·œí™” (v2.3 - Problem 49 ê°œì„ )

        - ë¬¸ìì—´ ë°°ì—´ì´ë©´ ë”•ì…”ë„ˆë¦¬ ë°°ì—´ë¡œ ë³€í™˜
        - persons ë°°ì—´ê³¼ characters ë°°ì—´ ë³‘í•©
        - ì˜ëª»ëœ ì´ë¦„ í•„í„°ë§
        """
        if not raw_characters and not raw_persons:
            return []

        normalized = []
        seen_names = set()

        # persons ë°°ì—´ ì²˜ë¦¬ (v2.3 í”„ë¡¬í”„íŠ¸)
        if raw_persons:
            debug_log(f"  persons ë°°ì—´ ì²˜ë¦¬: {len(raw_persons)}ëª…")
            for person in raw_persons:
                if isinstance(person, str):
                    name = person.strip()
                elif isinstance(person, dict):
                    name = person.get("name", person.get("name_ko", "")).strip()
                else:
                    continue

                # ğŸ”´ ìœ íš¨ì„± ê²€ì¦
                if not name or name in seen_names:
                    continue
                if not is_valid_person_name(name):
                    debug_log(f"    âŒ ì˜ëª»ëœ ì¸ë¬¼ í•„í„°ë§: '{name}'")
                    continue

                seen_names.add(name)

                if isinstance(person, dict):
                    normalized.append({
                        "name": name,
                        "name_ko": person.get("name_ko", name),
                        "name_en": person.get("name_en", ""),
                        "type": "person",
                        "role": person.get("role", person.get("position", "ë“±ì¥ì¸ë¬¼")),
                        "company": person.get("company", ""),
                        "description": person.get("description", ""),
                        "appearance": person.get("appearance", ""),
                        "nationality": person.get("nationality", ""),
                        "era": person.get("era", person.get("age_era", "")),
                        "character_prompt": person.get("character_prompt", person.get("visual_prompt", "")),
                        "visual_prompt": person.get("visual_prompt", person.get("character_prompt", "")),
                        "appearance_scenes": person.get("appearance_scenes", [])
                    })
                else:
                    normalized.append({
                        "name": name,
                        "name_ko": name,
                        "name_en": "",
                        "type": "person",
                        "role": "ë“±ì¥ì¸ë¬¼",
                        "description": "",
                        "appearance": "",
                        "nationality": "",
                        "era": "",
                        "character_prompt": "",
                        "visual_prompt": "",
                        "appearance_scenes": []
                    })

        # characters ë°°ì—´ ì²˜ë¦¬ (ìºë¦­í„° IP í¬í•¨)
        for char in raw_characters:
            if isinstance(char, str):
                name = char.strip()
                char_type = "character_ip" if name in KNOWN_CHARACTER_IPS else "person"
            elif isinstance(char, dict):
                name = char.get("name", char.get("name_ko", "")).strip()
                char_type = char.get("type", "person")
            else:
                continue

            # ì¤‘ë³µ ì²´í¬
            if not name or name in seen_names:
                continue

            # ìºë¦­í„° IPì¸ì§€ í™•ì¸
            is_character_ip = (
                name in KNOWN_CHARACTER_IPS or
                char_type == "character_ip" or
                (isinstance(char, dict) and char.get("category"))
            )

            # ì¸ë¬¼ì´ë©´ ìœ íš¨ì„± ê²€ì¦
            if not is_character_ip and not is_valid_person_name(name):
                debug_log(f"    âŒ ì˜ëª»ëœ ìºë¦­í„° í•„í„°ë§: '{name}'")
                continue

            seen_names.add(name)

            if isinstance(char, dict):
                normalized.append({
                    "name": name,
                    "name_ko": char.get("name_ko", name),
                    "name_en": char.get("name_en", ""),
                    "type": char_type,
                    "category": char.get("category", ""),
                    "owner_company": char.get("owner_company", ""),
                    "role": char.get("role", "ìºë¦­í„°" if is_character_ip else "ë“±ì¥ì¸ë¬¼"),
                    "description": char.get("description", ""),
                    "appearance": char.get("appearance", ""),
                    "nationality": char.get("nationality", ""),
                    "era": char.get("era", char.get("age_era", "")),
                    "character_prompt": char.get("character_prompt", char.get("visual_prompt", char.get("prompt", ""))),
                    "visual_prompt": char.get("visual_prompt", char.get("character_prompt", char.get("prompt", ""))),
                    "appearance_scenes": char.get("appearance_scenes", [])
                })
            else:
                # ì•Œë ¤ì§„ ìºë¦­í„° IPë©´ ì •ë³´ ì¶”ê°€
                if name in KNOWN_CHARACTER_IPS:
                    ip_info = KNOWN_CHARACTER_IPS[name]
                    normalized.append({
                        "name": name,
                        "name_ko": name,
                        "name_en": ip_info.get("name_en", ""),
                        "type": "character_ip",
                        "category": ip_info.get("category", ""),
                        "owner_company": ip_info.get("owner", ""),
                        "role": "ìºë¦­í„° IP",
                        "description": f"{ip_info.get('category', '')} - {ip_info.get('owner', '')}",
                        "appearance": "",
                        "nationality": "",
                        "era": "",
                        "character_prompt": "",
                        "visual_prompt": "",
                        "appearance_scenes": []
                    })
                else:
                    normalized.append({
                        "name": name,
                        "name_ko": name,
                        "name_en": "",
                        "type": "person",
                        "role": "ë“±ì¥ì¸ë¬¼",
                        "description": "",
                        "appearance": "",
                        "nationality": "",
                        "era": "",
                        "character_prompt": "",
                        "visual_prompt": "",
                        "appearance_scenes": []
                    })

        debug_log(f"  ì •ê·œí™” ì™„ë£Œ: {len(normalized)}ê°œ (í•„í„°ë§ í›„)")
        return normalized

    def _extract_characters_from_scenes(self, scenes: list, script: str = "") -> list:
        """
        ì”¬ ë°ì´í„°ì—ì„œ ì¸ë¬¼ + ìºë¦­í„° IP í´ë°± ì¶”ì¶œ (Problem 49 ê°œì„ )

        AIê°€ characters/persons ë°°ì—´ì„ ë¹„ì›Œë‘ê±°ë‚˜ ëˆ„ë½í–ˆì„ ë•Œ
        ê° ì”¬ì˜ characters í•„ë“œì™€ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì¶”ì¶œ

        Args:
            scenes: ì”¬ ë°°ì—´
            script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ (ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ìš©)

        Returns:
            ì¶”ì¶œëœ ìºë¦­í„° ë”•ì…”ë„ˆë¦¬ ë°°ì—´ (persons + character_ips)
        """
        import re

        debug_log("  ğŸ” ì”¬ì—ì„œ ìºë¦­í„° í´ë°± ì¶”ì¶œ ì‹œì‘ (v2 - ê°œì„ ëœ í•„í„°ë§)...")

        # ì”¬ì—ì„œ ìˆ˜ì§‘ëœ ì´ë¦„ë“¤
        person_names = set()
        person_scenes = {}  # ì¸ë¬¼ â†’ ë“±ì¥ ì”¬ ëª©ë¡

        # ============================================================
        # 1. ê° ì”¬ì˜ characters/persons í•„ë“œì—ì„œ ì¶”ì¶œ
        # ============================================================
        for scene in scenes:
            scene_id = scene.get("scene_id", 0)

            # characters í•„ë“œ
            for char in scene.get("characters", []):
                if isinstance(char, str) and char.strip():
                    name = char.strip()
                    if is_valid_person_name(name):
                        person_names.add(name)
                        if name not in person_scenes:
                            person_scenes[name] = []
                        person_scenes[name].append(scene_id)
                elif isinstance(char, dict):
                    name = char.get("name", char.get("name_ko", "")).strip()
                    if name and is_valid_person_name(name):
                        person_names.add(name)
                        if name not in person_scenes:
                            person_scenes[name] = []
                        person_scenes[name].append(scene_id)

            # persons í•„ë“œ (ìƒˆ í”„ë¡¬í”„íŠ¸ v2.3)
            for person in scene.get("persons", []):
                if isinstance(person, str) and person.strip():
                    name = person.strip()
                    if is_valid_person_name(name):
                        person_names.add(name)
                        if name not in person_scenes:
                            person_scenes[name] = []
                        person_scenes[name].append(scene_id)

        debug_log(f"    ì”¬ í•„ë“œì—ì„œ ìœ íš¨í•œ ì¸ë¬¼ {len(person_names)}ëª…: {list(person_names)[:5]}")

        # ============================================================
        # 2. ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì¸ë¬¼ ì´ë¦„ íŒ¨í„´ ì¶”ì¶œ (í´ë°±)
        # ============================================================
        if not person_names and script:
            debug_log("    ì”¬ì—ì„œ ì¸ë¬¼ ì—†ìŒ, ìŠ¤í¬ë¦½íŠ¸ íŒ¨í„´ ë¶„ì„ ì‹œë„...")

            # íŒ¨í„´ 1: í•œê¸€ ì´ë¦„ + ì§ì±… (ì˜ˆ: "ê¹€ë¯¼ì„ ëŒ€í‘œ", "í™ê¸¸ë™ CEO")
            pattern1 = r'([ê°€-í£]{2,4})\s*(ëŒ€í‘œ|íšŒì¥|ì‚¬ì¥|ì´ì‚¬|CEO|CFO|CTO|ì°½ì—…ì|ì„¤ë¦½ì|ì”¨|ë‹˜)'
            for match in re.finditer(pattern1, script):
                name = match.group(1).strip()
                if is_valid_person_name(name):
                    person_names.add(name)
                    debug_log(f"      âœ… íŒ¨í„´1 ì¶”ì¶œ: '{name}' (+ {match.group(2)})")

            # íŒ¨í„´ 2: ì§ì±… + í•œê¸€ ì´ë¦„ (ì˜ˆ: "ëŒ€í‘œ ê¹€ë¯¼ì„", "ì°½ì—…ì í™ê¸¸ë™")
            pattern2 = r'(ëŒ€í‘œ|íšŒì¥|ì‚¬ì¥|ì´ì‚¬|CEO|ì°½ì—…ì|ì„¤ë¦½ì)\s+([ê°€-í£]{2,4})(?=[ì´ê°€ì€ëŠ”ì„ë¥¼\s,.])'
            for match in re.finditer(pattern2, script):
                name = match.group(2).strip()
                if is_valid_person_name(name):
                    person_names.add(name)
                    debug_log(f"      âœ… íŒ¨í„´2 ì¶”ì¶œ: '{name}' ({match.group(1)} +)")

            # íŒ¨í„´ 3: ì™¸êµ­ ì´ë¦„ (ì˜ˆ: "Elon Musk", "Tim Cook")
            pattern3 = r'([A-Z][a-z]+)\s+([A-Z][a-z]+)'
            for match in re.finditer(pattern3, script):
                name = f"{match.group(1)} {match.group(2)}"
                person_names.add(name)
                debug_log(f"      âœ… íŒ¨í„´3 ì¶”ì¶œ: '{name}'")

            # íŒ¨í„´ 4: ì•„ë/ì™¸ë˜ ì´ë¦„ (ì˜ˆ: "ë¬´í•¨ë§ˆë“œ ë¹ˆ ì‚´ë§Œ", "ìë§ ì¹´ìŠˆë„ì§€")
            pattern4 = r'([ê°€-í£]{2,5})\s+([ê°€-í£]{1,3})\s+([ê°€-í£]{2,4})'
            for match in re.finditer(pattern4, script):
                name = f"{match.group(1)} {match.group(2)} {match.group(3)}"
                # êµ­ê°€ëª… ë“± ì œì™¸
                if not any(kw in name for kw in ['ì‚¬ìš°ë””', 'ì•„ë¼ë¹„ì•„', 'ëŒ€í•œë¯¼êµ­']):
                    person_names.add(name)
                    debug_log(f"      âœ… íŒ¨í„´4 ì¶”ì¶œ: '{name}'")

            debug_log(f"    ìŠ¤í¬ë¦½íŠ¸ íŒ¨í„´ì—ì„œ {len(person_names)}ëª… ë°œê²¬: {list(person_names)[:5]}")

        # ============================================================
        # 3. ìºë¦­í„° IP ì¶”ì¶œ (ë™ë¬¼, ë§ˆìŠ¤ì½”íŠ¸ ë“±)
        # ============================================================
        character_ips = []
        found_ips = set()

        # ì•Œë ¤ì§„ ìºë¦­í„° IP ê²€ìƒ‰
        for ip_name, ip_info in KNOWN_CHARACTER_IPS.items():
            if ip_name in script and ip_name not in found_ips:
                found_ips.add(ip_name)
                # ë“±ì¥ ì”¬ ì°¾ê¸°
                ip_scenes = []
                for scene in scenes:
                    scene_text = scene.get("script_text", "")
                    if ip_name in scene_text:
                        ip_scenes.append(scene.get("scene_id", 0))

                character_ips.append({
                    "name": ip_name,
                    "name_ko": ip_name,
                    "name_en": ip_info.get('name_en', ''),
                    "type": "character_ip",
                    "category": ip_info.get('category', 'ìºë¦­í„°'),
                    "owner_company": ip_info.get('owner', ''),
                    "role": "ìºë¦­í„° IP",
                    "description": f"{ip_info.get('category', 'ìºë¦­í„°')} - {ip_info.get('owner', '')}",
                    "visual_prompt": self._generate_character_ip_prompt(ip_name, ip_info),
                    "appearance_scenes": ip_scenes
                })
                debug_log(f"    âœ… ìºë¦­í„° IP ë°œê²¬: '{ip_name}' ({ip_info.get('category', '')})")

        # íŒ¨í„´ ê¸°ë°˜ ìºë¦­í„° IP ì¶”ì¶œ (~ìºë¦­í„°, ~ë§ˆìŠ¤ì½”íŠ¸)
        ip_pattern = r'([ê°€-í£a-zA-Z]{2,10})\s*(ìºë¦­í„°|ë§ˆìŠ¤ì½”íŠ¸)'
        for match in re.finditer(ip_pattern, script):
            name = match.group(1).strip()
            if name not in found_ips and name not in INVALID_CHARACTER_WORDS:
                if len(name) >= 2 and not is_valid_person_name(name):  # ì‚¬ëŒ ì´ë¦„ ì•„ë‹Œ ê²ƒë§Œ
                    found_ips.add(name)
                    character_ips.append({
                        "name": name,
                        "name_ko": name,
                        "name_en": "",
                        "type": "character_ip",
                        "category": match.group(2),
                        "role": match.group(2),
                        "description": f"ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì¶”ì¶œëœ {match.group(2)}",
                        "visual_prompt": "",
                        "appearance_scenes": []
                    })
                    debug_log(f"    âœ… íŒ¨í„´ ìºë¦­í„° IP: '{name}' ({match.group(2)})")

        debug_log(f"    ìºë¦­í„° IP ì´ {len(character_ips)}ê°œ ë°œê²¬")

        # ============================================================
        # 4. ì¸ë¬¼ ê°ì²´ ìƒì„±
        # ============================================================
        characters = []

        for name in person_names:
            # ì—­í•  ì¶”ë¡ 
            role = "ë“±ì¥ì¸ë¬¼"
            name_context = script[:3000] if script else ""

            # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì—­í•  ì¶”ë¡ 
            name_patterns = [
                (f"{name}\\s*ëŒ€í‘œ", "ëŒ€í‘œ"),
                (f"{name}\\s*CEO", "CEO"),
                (f"{name}\\s*íšŒì¥", "íšŒì¥"),
                (f"{name}\\s*ì°½ì—…", "ì°½ì—…ì"),
                (f"{name}\\s*ì„¤ë¦½", "ì°½ì—…ì"),
                (f"ì°½ì—…ì\\s*{name}", "ì°½ì—…ì"),
                (f"ëŒ€í‘œ\\s*{name}", "ëŒ€í‘œ"),
            ]
            for pattern, detected_role in name_patterns:
                if re.search(pattern, name_context, re.IGNORECASE):
                    role = detected_role
                    break

            char = {
                "name": name,
                "name_ko": name,
                "name_en": "",
                "type": "person",
                "role": role,
                "description": f"ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì¶”ì¶œëœ ì¸ë¬¼: {name} ({role})",
                "appearance": "",
                "nationality": "",
                "era": "",
                "character_prompt": "",
                "visual_prompt": "",
                "appearance_scenes": person_scenes.get(name, [])
            }
            characters.append(char)

        # ìºë¦­í„° IPë„ characters ë°°ì—´ì— ì¶”ê°€
        characters.extend(character_ips)

        debug_log(f"    ìµœì¢… í´ë°±: ì¸ë¬¼ {len(person_names)}ëª… + ìºë¦­í„° IP {len(character_ips)}ê°œ = {len(characters)}ê°œ")
        return characters

    def _generate_character_ip_prompt(self, name: str, info: dict) -> str:
        """ìºë¦­í„° IPìš© visual_prompt ìƒì„±"""
        category = info.get('category', '')
        name_en = info.get('name_en', name)

        prompts = {
            'ì•„ê¸°ìƒì–´': "Cute blue baby shark character, cartoon style, big round friendly eyes, small dorsal fin, happy wide smile, underwater ocean background with bubbles, bright vibrant blue and yellow colors, kawaii chibi aesthetic, no text, no letters, no words",
            'í•‘í¬í': "Cute pink fox mascot character, bright magenta and coral pink fur, big sparkling round eyes, small cute nose, friendly cheerful smile, fluffy tail, cartoon kawaii style, no text, no letters, no words",
            'ë½€ë¡œë¡œ': "Cute little penguin character in aviator helmet and goggles, blue and white colors, round body, friendly eyes, cartoon style, no text, no letters, no words",
            'í­ìˆ˜': "Tall penguin character, EBS mascot, wearing blue hoodie, expressive eyes, quirky personality, cartoon style, no text, no letters, no words",
        }

        if name in prompts:
            return prompts[name]

        # ê¸°ë³¸ í…œí”Œë¦¿
        if 'ë™ë¬¼' in category:
            return f"Cute {name_en} animal character, cartoon style, friendly expression, bright vibrant colors, kawaii aesthetic, no text, no letters, no words"
        elif 'ë§ˆìŠ¤ì½”íŠ¸' in category:
            return f"Cute {name_en} mascot character, brand mascot style, friendly smile, bright colors, cartoon aesthetic, no text, no letters, no words"
        else:
            return f"{name_en} character, cartoon style, friendly appearance, no text, no letters, no words"

    def _normalize_scenes(self, raw_scenes: list) -> list:
        """
        ì”¬ ë°°ì—´ ì •ê·œí™”

        - ì”¬ ë‚´ë¶€ì˜ characters í•„ë“œ ì²˜ë¦¬
        - ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ê¸°ë³¸ê°’ ìƒì„±
        - ê¸€ì ìˆ˜ ê²€ì¦ ë¡œê·¸
        """
        if not raw_scenes:
            return []

        normalized = []

        for scene in raw_scenes:
            if not isinstance(scene, dict):
                continue

            # ì”¬ ë‚´ë¶€ì˜ charactersë„ ë¬¸ìì—´ ë°°ì—´ì¼ ìˆ˜ ìˆìŒ
            scene_characters = scene.get("characters", [])

            # ìºë¦­í„° ì´ë¦„ë§Œ ë¬¸ìì—´ ë°°ì—´ë¡œ ì •ê·œí™”
            if scene_characters:
                if all(isinstance(c, str) for c in scene_characters):
                    # ì´ë¯¸ ë¬¸ìì—´ ë°°ì—´ - OK
                    pass
                elif scene_characters and isinstance(scene_characters[0], dict):
                    # ë”•ì…”ë„ˆë¦¬ ë°°ì—´ â†’ ì´ë¦„ë§Œ ì¶”ì¶œ
                    scene["characters"] = [
                        c.get("name", c.get("name_ko", str(c)))
                        for c in scene_characters
                    ]

            # === ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ì •ê·œí™” ===
            # video_prompt_characterê°€ ì—†ê±°ë‚˜ N/Aë©´ ê¸°ë³¸ê°’ ìƒì„±
            video_char = scene.get("video_prompt_character", "")
            if not video_char or video_char == "N/A":
                scene["video_prompt_character"] = self._generate_default_video_prompt_character(scene)
                debug_log(f"  ì”¬ {scene.get('scene_id', '?')}: video_prompt_character ìë™ ìƒì„±")

            # video_prompt_fullì´ ì—†ê±°ë‚˜ N/Aë©´ ê¸°ë³¸ê°’ ìƒì„±
            video_full = scene.get("video_prompt_full", "")
            if not video_full or video_full == "N/A":
                scene["video_prompt_full"] = self._generate_default_video_prompt_full(scene)
                debug_log(f"  ì”¬ {scene.get('scene_id', '?')}: video_prompt_full ìë™ ìƒì„±")

            # === ê¸€ì ìˆ˜ ê²€ì¦ ===
            script_text = scene.get("script_text", "")
            char_count = len(script_text)
            scene["char_count"] = char_count  # ê¸€ì ìˆ˜ í•„ë“œ ì¶”ê°€

            if char_count > 250:
                debug_log(f"  âš ï¸ ì”¬ {scene.get('scene_id', '?')}: ê¸€ì ìˆ˜ {char_count}ì (ê¶Œì¥ 250ì ì´ˆê³¼)")

            normalized.append(scene)

        return normalized

    def _validate_script_preservation(self, original_script: str, analysis_result: dict) -> dict:
        """
        ë¶„ì„ ê²°ê³¼ì˜ script_textê°€ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì¦

        ğŸ”´ í•µì‹¬: AIê°€ ì°½ì‘í•œ ë¬¸ì¥ì„ ê°ì§€í•˜ê³  ìˆ˜ì •

        Args:
            original_script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸
            analysis_result: ë¶„ì„ ê²°ê³¼

        Returns:
            ê²€ì¦/ìˆ˜ì •ëœ ë¶„ì„ ê²°ê³¼
        """
        scenes = analysis_result.get('scenes', [])
        if not scenes or not original_script:
            return analysis_result

        # ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì •ê·œí™” (ë¹„êµìš©)
        original_normalized = original_script.lower().replace('\n', ' ').replace('  ', ' ').strip()

        validated_scenes = []
        modified_count = 0
        warning_count = 0

        for scene in scenes:
            script_text = scene.get('script_text', '')

            if not script_text:
                validated_scenes.append(scene)
                continue

            # script_text ì •ê·œí™”
            script_normalized = script_text.lower().replace('\n', ' ').replace('  ', ' ').strip()

            # ì›ë³¸ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ë¶€ë¶„ ì¼ì¹˜)
            if script_normalized in original_normalized:
                # âœ… ì›ë³¸ì— ì¡´ì¬ - ê·¸ëŒ€ë¡œ ì‚¬ìš©
                validated_scenes.append(scene)
            else:
                # âŒ ì›ë³¸ì— ì—†ìŒ - AIê°€ ì°½ì‘í•œ ë¬¸ì¥
                scene_id = scene.get('scene_id', '?')
                debug_log(f"  âš ï¸ ì”¬ {scene_id}: ì›ë³¸ì— ì—†ëŠ” ë¬¸ì¥ ê°ì§€!")
                debug_log(f"     AI ìƒì„±: {script_text[:80]}...")
                warning_count += 1

                # ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸° ì‹œë„
                matched_text = self._find_similar_text_in_script(original_script, script_text)

                if matched_text:
                    debug_log(f"     â†’ ìœ ì‚¬ ë¬¸ì¥ìœ¼ë¡œ ëŒ€ì²´: {matched_text[:80]}...")
                    scene['script_text'] = matched_text
                    scene['_was_corrected'] = True
                    scene['_original_ai_text'] = script_text
                    modified_count += 1
                else:
                    # ì°¾ì§€ ëª»í•˜ë©´ ê²½ê³ ë§Œ (ë¹ˆ ë¬¸ì¥ ë°©ì§€)
                    debug_log(f"     â†’ ìœ ì‚¬ ë¬¸ì¥ ì—†ìŒ, ì›ë³¸ ìœ ì§€ (ìˆ˜ë™ í™•ì¸ í•„ìš”)")
                    scene['_verification_failed'] = True

                validated_scenes.append(scene)

        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        analysis_result['scenes'] = validated_scenes

        # ê²€ì¦ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        analysis_result['_script_validation'] = {
            'total_scenes': len(scenes),
            'modified_count': modified_count,
            'warning_count': warning_count,
            'all_verified': warning_count == 0
        }

        if modified_count > 0:
            debug_log(f"  âš ï¸ {modified_count}ê°œ ì”¬ì˜ script_textê°€ ìˆ˜ì •ë¨")
        if warning_count > 0:
            debug_log(f"  âš ï¸ {warning_count}ê°œ ì”¬ì—ì„œ ì›ë³¸ì— ì—†ëŠ” ë¬¸ì¥ ê°ì§€ë¨")
        if warning_count == 0:
            debug_log(f"  âœ… ëª¨ë“  ì”¬ì˜ script_textê°€ ì›ë³¸ê³¼ ì¼ì¹˜í•¨")

        return analysis_result

    def _find_similar_text_in_script(self, original_script: str, target_text: str, threshold: float = 0.6) -> str:
        """
        ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ target_textì™€ ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸°

        Args:
            original_script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸
            target_text: ì°¾ì„ í…ìŠ¤íŠ¸
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’

        Returns:
            ìœ ì‚¬í•œ ì›ë³¸ ë¬¸ì¥ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        from difflib import SequenceMatcher
        import re

        # ì›ë³¸ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = re.split(r'[.!?]\s*', original_script)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 5]

        # ì¶”ê°€ë¡œ ì¤„ë°”ê¿ˆ ë‹¨ìœ„ ë¶„í• ë„ í¬í•¨
        lines = original_script.split('\n')
        lines = [l.strip() for l in lines if l.strip() and len(l.strip()) > 10]

        all_candidates = list(set(sentences + lines))

        best_match = None
        best_ratio = 0

        target_lower = target_text.lower().strip()

        for candidate in all_candidates:
            candidate_lower = candidate.lower().strip()

            # í¬í•¨ ê´€ê³„ í™•ì¸
            if target_lower in candidate_lower or candidate_lower in target_lower:
                return candidate

            # ìœ ì‚¬ë„ ê³„ì‚°
            ratio = SequenceMatcher(None, target_lower, candidate_lower).ratio()
            if ratio > best_ratio and ratio >= threshold:
                best_ratio = ratio
                best_match = candidate

        return best_match if best_match else ""

    def analyze_script_chunked(
        self,
        script: str,
        language: str = "ko",
        template_id: str = "scene_analysis",
        chunk_size: int = 2500
    ) -> Dict:
        """
        ê¸´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„

        MAX_TOKENS ë¬¸ì œë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ë°©ë²•.
        ìŠ¤í¬ë¦½íŠ¸ê°€ chunk_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ì¼ë°˜ analyze_script ì‚¬ìš©.

        Args:
            script: ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
            language: ì–¸ì–´ ì½”ë“œ
            template_id: ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ID
            chunk_size: ì²­í¬ë‹¹ ìµœëŒ€ ê¸€ì ìˆ˜

        Returns:
            í†µí•©ëœ ë¶„ì„ ê²°ê³¼
        """
        # ì§§ì€ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¼ë°˜ ì²˜ë¦¬
        if len(script) < chunk_size:
            debug_log(f"  ìŠ¤í¬ë¦½íŠ¸ê°€ ì§§ìŒ ({len(script)}ì) - ì¼ë°˜ ë¶„ì„ ì‚¬ìš©")
            return self.analyze_script(script, language, template_id)

        debug_log(f"[SceneAnalyzer] ğŸ“„ ê¸´ ìŠ¤í¬ë¦½íŠ¸ ê°ì§€ ({len(script)}ì) - ì²­í¬ ë¶„í•  ì²˜ë¦¬")

        # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ë¬¸ì¥ ë‹¨ìœ„)
        chunks = self._split_script_into_chunks(script, chunk_size)
        debug_log(f"  â†’ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")

        all_scenes = []
        all_persons = []
        all_characters = []
        all_companies = []
        scene_id_offset = 0

        for i, chunk in enumerate(chunks):
            debug_log(f"  ğŸ”„ ì²­í¬ {i+1}/{len(chunks)} ë¶„ì„ ì¤‘... ({len(chunk)}ì)")

            # ì²­í¬ ë¶„ì„
            chunk_result = self._analyze_single_chunk(
                chunk_text=chunk,
                chunk_index=i,
                total_chunks=len(chunks),
                language=language,
                template_id=template_id,
                full_script=script  # ì›ë³¸ ì „ë‹¬ (ê²€ì¦ìš©)
            )

            if chunk_result and not chunk_result.get('error'):
                # ì”¬ ID ì¡°ì • ë° ë³‘í•©
                for scene in chunk_result.get('scenes', []):
                    original_id = scene.get('scene_id', 0)
                    scene['scene_id'] = original_id + scene_id_offset
                    scene['_chunk_index'] = i
                    all_scenes.append(scene)

                scene_id_offset = len(all_scenes)

                # ì¸ë¬¼/ìºë¦­í„°/íšŒì‚¬ ë³‘í•© (ì¤‘ë³µ ì œê±°)
                for person in chunk_result.get('persons', []):
                    name = person.get('name', '')
                    if name and not any(p.get('name') == name for p in all_persons):
                        all_persons.append(person)

                for char in chunk_result.get('characters', []):
                    name = char.get('name', '')
                    if name and not any(c.get('name') == name for c in all_characters):
                        all_characters.append(char)

                for company in chunk_result.get('companies', []):
                    name = company.get('name', '')
                    if name and not any(c.get('name') == name for c in all_companies):
                        all_companies.append(company)

        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        final_result = {
            'metadata': {
                'processed_in_chunks': True,
                'total_chunks': len(chunks)
            },
            'scenes': all_scenes,
            'persons': all_persons,
            'characters': all_characters,
            'companies': all_companies,
            'summary': {
                'total_scenes': len(all_scenes),
                'total_persons': len(all_persons),
                'total_characters': len(all_characters),
                'total_companies': len(all_companies)
            }
        }

        # ğŸ”´ ìµœì¢… ê²€ì¦
        debug_log("  ğŸ“‹ ì²­í¬ ë¶„ì„ ê²°ê³¼ ìµœì¢… ê²€ì¦...")
        final_result = self._validate_script_preservation(script, final_result)

        debug_log(f"  âœ… ì²­í¬ ë¶„ì„ ì™„ë£Œ: ì”¬ {len(all_scenes)}ê°œ, ìºë¦­í„° {len(all_characters)}ê°œ")

        return final_result

    def _split_script_into_chunks(self, script: str, chunk_size: int = 2500) -> list:
        """
        ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í¬ ë¶„í• 

        ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ëŠê¸°ì§€ ì•Šë„ë¡ í•¨.
        """
        import re

        # ë¬¸ì¥ ë¶„í•  (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ í›„)
        sentences = re.split(r'(?<=[.!?])\s+', script)

        chunks = []
        current_chunk = ""

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            # í˜„ì¬ ì²­í¬ì— ë¬¸ì¥ ì¶”ê°€ ê°€ëŠ¥ ì—¬ë¶€
            if len(current_chunk) + len(sentence) + 1 < chunk_size:
                current_chunk += (" " if current_chunk else "") + sentence
            else:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence

        # ë§ˆì§€ë§‰ ì²­í¬
        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

    def _analyze_single_chunk(
        self,
        chunk_text: str,
        chunk_index: int,
        total_chunks: int,
        language: str,
        template_id: str,
        full_script: str
    ) -> dict:
        """
        ë‹¨ì¼ ì²­í¬ ë¶„ì„

        Args:
            chunk_text: ì²­í¬ í…ìŠ¤íŠ¸
            chunk_index: ì²­í¬ ì¸ë±ìŠ¤
            total_chunks: ì „ì²´ ì²­í¬ ìˆ˜
            language: ì–¸ì–´
            template_id: í…œí”Œë¦¿ ID
            full_script: ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ (ê²€ì¦ìš©)

        Returns:
            ì²­í¬ ë¶„ì„ ê²°ê³¼
        """
        # ì²­í¬ìš© í”„ë¡¬í”„íŠ¸ (ê°„ì†Œí™” ë²„ì „)
        chunk_prompt = f"""ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ ì²­í¬ë¥¼ ë¶„ì„í•˜ì„¸ìš”. (ì²­í¬ {chunk_index + 1}/{total_chunks})

ğŸ”´ğŸ”´ğŸ”´ [CRITICAL] ìŠ¤í¬ë¦½íŠ¸ ì›ë³¸ ë³´ì¡´ ì ˆëŒ€ ê·œì¹™ ğŸ”´ğŸ”´ğŸ”´

âš ï¸ ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™: script_textì—ëŠ” ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ì— ìˆëŠ” ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!

**ğŸš« ì ˆëŒ€ ê¸ˆì§€:**
- ìŠ¤í¬ë¦½íŠ¸ì— ì—†ëŠ” ë¬¸ì¥ ë§Œë“¤ê¸° âŒ
- "êµ¬ë…ê³¼ ì¢‹ì•„ìš” ë¶€íƒë“œë¦½ë‹ˆë‹¤" ê°™ì€ ì¼ë°˜ ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€ âŒ
- ì›ë³¸ ë¬¸ì¥ì„ ë‹¤ë¥´ê²Œ ë°”ê¾¸ê¸° âŒ

=== ìŠ¤í¬ë¦½íŠ¸ ì²­í¬ (ì´ ë‚´ìš©ë§Œ ì‚¬ìš©!) ===
{chunk_text}
=== ìŠ¤í¬ë¦½íŠ¸ ë ===

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
```json
{{
  "scenes": [
    {{
      "scene_id": 1,
      "script_text": "ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€!)",
      "char_count": 100,
      "duration_estimate": 8,
      "persons": [],
      "characters": [],
      "mood": "ë¶„ìœ„ê¸°",
      "image_prompt_en": "..., no text, no letters"
    }}
  ],
  "persons": [],
  "characters": [],
  "companies": []
}}
```

âš ï¸ script_textì—ëŠ” ìœ„ ìŠ¤í¬ë¦½íŠ¸ì˜ ë¬¸ì¥ë§Œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
âš ï¸ ìŠ¤í¬ë¦½íŠ¸ì— ì—†ëŠ” ë¬¸ì¥ì„ ë§Œë“¤ì–´ë‚´ë©´ ì•ˆë©ë‹ˆë‹¤!
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        try:
            if self.provider == "google":
                result_text, finish_reason = self._call_gemini_with_status(chunk_prompt)

                # MAX_TOKENS ì²˜ë¦¬
                if finish_reason == 2:
                    debug_log(f"    ì²­í¬ {chunk_index + 1}: MAX_TOKENS - ì´ì–´ì„œ ìƒì„±")
                    result_text = self._continue_gemini_generation(result_text, chunk_text)
            else:
                result_text = self._call_anthropic(chunk_prompt)

            # JSON íŒŒì‹±
            json_str = result_text
            if "```json" in json_str:
                start = json_str.find("```json") + 7
                end = json_str.rfind("```")
                json_str = json_str[start:end].strip() if end > start else json_str[start:].strip()
            elif "```" in json_str:
                start = json_str.find("```") + 3
                end = json_str.rfind("```")
                json_str = json_str[start:end].strip() if end > start else json_str[start:].strip()

            return json.loads(json_str)

        except Exception as e:
            debug_log(f"    ì²­í¬ {chunk_index + 1} ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e), 'scenes': [], 'characters': []}

    def _repair_truncated_json(self, json_str: str) -> str:
        """
        ì˜ë¦° JSON ë³µêµ¬ ì‹œë„

        Geminiê°€ ì¶œë ¥ í† í° ì œí•œìœ¼ë¡œ JSONì„ ì™„ì„±í•˜ì§€ ëª»í•œ ê²½ìš°,
        ìµœëŒ€í•œ ë³µêµ¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
        """

        # 1. ì´ë¯¸ ìœ íš¨í•œ JSONì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        try:
            json.loads(json_str)
            return json_str
        except:
            pass

        debug_log(f"  JSON ë³µêµ¬ ì‹œë„ ì¤‘... (ê¸¸ì´: {len(json_str)})")

        repaired = json_str

        # 2. ì—´ë¦° ë¬¸ìì—´ ë‹«ê¸° (Unterminated string í•´ê²°)
        in_string = False
        escape_next = False

        for char in repaired:
            if escape_next:
                escape_next = False
                continue
            if char == '\\':
                escape_next = True
                continue
            if char == '"':
                in_string = not in_string

        # ë¬¸ìì—´ì´ ì—´ë¦° ìƒíƒœë¡œ ëë‚¬ìœ¼ë©´ ë‹«ê¸°
        if in_string:
            repaired = repaired + '"'
            debug_log("  ì—´ë¦° ë¬¸ìì—´ ë‹«ìŒ")

        # 3. ë§ˆì§€ë§‰ ì™„ì „í•œ ì”¬/ê°ì²´ ì°¾ê¸°
        # scenes ë°°ì—´ ë‚´ì—ì„œ ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ ìœ„ì¹˜ ì°¾ê¸°
        last_complete = repaired.rfind('},')
        if last_complete == -1:
            last_complete = repaired.rfind('}')

        if last_complete > 0 and last_complete < len(repaired) - 1:
            # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ë§Œ ì‚¬ìš©
            repaired = repaired[:last_complete + 1]
            debug_log(f"  ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ ìë¦„ (ìœ„ì¹˜: {last_complete})")

        # 4. ì—´ë¦° ë°°ì—´/ê°ì²´ ë‹«ê¸°
        open_braces = repaired.count('{') - repaired.count('}')
        open_brackets = repaired.count('[') - repaired.count(']')

        # ë°°ì—´ ë¨¼ì € ë‹«ê³ , ê°ì²´ ë‹«ê¸°
        if open_brackets > 0:
            repaired = repaired + (']' * open_brackets)
            debug_log(f"  ] {open_brackets}ê°œ ì¶”ê°€")
        if open_braces > 0:
            repaired = repaired + ('}' * open_braces)
            debug_log(f"  }} {open_braces}ê°œ ì¶”ê°€")

        # 5. ê²€ì¦
        try:
            json.loads(repaired)
            debug_log("  âœ… JSON ë³µêµ¬ ì„±ê³µ!")
            return repaired
        except json.JSONDecodeError as e:
            debug_log(f"  âŒ 1ì°¨ ë³µêµ¬ ì‹¤íŒ¨: {e}")

        # 6. ë” ê³µê²©ì ì¸ ë³µêµ¬ - scenes ë°°ì—´ë§Œ ì¶”ì¶œ ì‹œë„
        return self._extract_partial_scenes(json_str)

    def _extract_partial_scenes(self, json_str: str) -> str:
        """
        ë¶€ë¶„ì ìœ¼ë¡œ ì”¬ë§Œ ì¶”ì¶œí•˜ì—¬ ìœ íš¨í•œ JSON ìƒì„±
        """
        import re

        debug_log("  ë¶€ë¶„ ì”¬ ì¶”ì¶œ ì‹œë„...")

        # scenes ë°°ì—´ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
        scenes_start = json_str.find('"scenes"')
        if scenes_start == -1:
            debug_log("  scenes ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return '{"scenes": [], "characters": []}'

        # ê° ì”¬ ê°ì²´ ì¶”ì¶œ (ì •ê·œì‹ìœ¼ë¡œ)
        # scene_idê°€ ìˆëŠ” ê°ì²´ ì°¾ê¸°
        scene_pattern = r'\{\s*"scene_id"\s*:\s*(\d+)[^}]*?"script_text"\s*:\s*"[^"]*"[^}]*?\}'

        scenes = []
        for match in re.finditer(scene_pattern, json_str, re.DOTALL):
            try:
                scene_str = match.group(0)
                # ì™„ì „í•œ ê°ì²´ì¸ì§€ í™•ì¸
                if scene_str.count('{') == scene_str.count('}'):
                    scene = json.loads(scene_str)
                    scenes.append(scene)
            except:
                continue

        if scenes:
            debug_log(f"  ë¶€ë¶„ ì¶”ì¶œ ì„±ê³µ: {len(scenes)}ê°œ ì”¬ ë°œê²¬")
            return json.dumps({
                "scenes": scenes,
                "characters": []
            }, ensure_ascii=False)

        debug_log("  ë¶€ë¶„ ì¶”ì¶œ ì‹¤íŒ¨")
        return '{"scenes": [], "characters": []}'

    def _generate_default_video_prompt_character(self, scene: dict) -> str:
        """ê¸°ë³¸ ìºë¦­í„° ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        mood = scene.get("mood", "neutral")

        mood_prompts = {
            "ê¸´ì¥ê°": "Serious expression, intense eye contact, measured breathing, subtle tension in facial muscles, mouth moving naturally while speaking",
            "ê¸´ì¥": "Serious expression, intense eye contact, measured breathing, subtle tension in facial muscles, mouth moving naturally while speaking",
            "ìŠ¬í””": "Sorrowful expression, eyes glistening, slight trembling of lips, looking down occasionally, speaking softly",
            "ë¶„ë…¸": "Angry expression, furrowed brows, tight jaw, intense gaze, controlled breathing, emphatic speech",
            "ê¸°ì¨": "Happy expression, warm smile, bright eyes, relaxed facial muscles, enthusiastic speaking",
            "ì§„ì§€í•¨": "Serious focused expression, thoughtful eye movements, measured speaking pace, subtle nods",
            "ì„¤ëª…ì ": "Engaged expression, eyebrows moving expressively, clear articulation, occasional hand gestures",
            "ì—­ì‚¬ì ": "Dignified expression, steady gaze, measured speaking, scholarly demeanor",
            "ë¹„íŒì ": "Critical expression, raised eyebrow, intense gaze, deliberate speaking pace",
            "ì–µì••ì ": "Stern expression, tight-lipped, cold gaze, authoritative tone",
            "ê¶Œìœ„ì ": "Authoritative expression, confident posture, commanding voice, powerful presence"
        }

        return mood_prompts.get(mood, "Calm expression, natural eye blinks, subtle head movements, mouth moving naturally while speaking")

    def _generate_default_video_prompt_full(self, scene: dict) -> str:
        """ê¸°ë³¸ ì „ì²´ ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        camera = scene.get("camera_suggestion", "medium shot")
        mood = scene.get("mood", "neutral")

        # ì¹´ë©”ë¼ ì›€ì§ì„ ë§¤í•‘
        camera_motion = "steady shot"
        if "ì¤Œì¸" in camera or "zoom in" in camera.lower():
            camera_motion = "camera slowly zooms in"
        elif "ì¤Œì•„ì›ƒ" in camera or "zoom out" in camera.lower():
            camera_motion = "camera slowly zooms out"
        elif "íŒ¨ë‹" in camera or "pan" in camera.lower():
            camera_motion = "camera pans across the scene"
        elif "ì „í™˜" in camera:
            camera_motion = "smooth transition"
        else:
            camera_motion = "camera holds steady with subtle movement"

        return f"{camera_motion}, character speaking with natural gestures, subtle background movement, atmospheric lighting matching {mood} mood"

    def _ensure_visual_prompts(self, characters: list, script: str = "") -> list:
        """
        visual_promptê°€ ë¹„ì–´ìˆëŠ” ìºë¦­í„°ì— ëŒ€í•´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            characters: ì •ê·œí™”ëœ ìºë¦­í„° ë¦¬ìŠ¤íŠ¸
            script: ì»¨í…ìŠ¤íŠ¸ìš© ìŠ¤í¬ë¦½íŠ¸

        Returns:
            visual_promptê°€ ì±„ì›Œì§„ ìºë¦­í„° ë¦¬ìŠ¤íŠ¸
        """
        if not characters:
            return characters

        script_lower = script[:1000].lower() if script else ""

        for char in characters:
            # visual_promptì™€ character_prompt ëª¨ë‘ í™•ì¸
            existing_prompt = char.get("visual_prompt") or char.get("character_prompt") or ""

            if not existing_prompt.strip():
                name = char.get("name", "")
                description = char.get("description", "")

                debug_log(f"  '{name}' visual_prompt ìë™ ìƒì„± ì¤‘...")
                char["visual_prompt"] = self._generate_fallback_visual_prompt(
                    name, description, script_lower
                )
                char["character_prompt"] = char["visual_prompt"]
                debug_log(f"    ìƒì„±ë¨: {char['visual_prompt'][:60]}...")

        return characters

    def _generate_fallback_visual_prompt(self, name: str, description: str, script_context: str) -> str:
        """
        ê·œì¹™ ê¸°ë°˜ í´ë°± visual_prompt ìƒì„±

        ìºë¦­í„° ì´ë¦„ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        prompt_parts = []

        # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰
        name_lower = name.lower()
        desc_lower = description.lower()
        context = f"{name_lower} {desc_lower} {script_context}"

        # === ì¤‘ë™/ì•„ë ê´€ë ¨ ===
        arab_keywords = ["ì‚¬ìš°ë””", "ì•„ë", "ì´ìŠ¬ëŒ", "ë¬´í•¨ë§ˆë“œ", "ë¹ˆ ì‚´ë§Œ", "ì™•ì„¸ì", "ì™•ê°€", "ë©”ì¹´", "ì¹´ìŠˆí¬ì§€", "khashoggi", "saudi", "arab"]
        if any(kw in context for kw in arab_keywords):
            if "ì™•ì„¸ì" in name or "ì™•" in name or "ë¹ˆ ì‚´ë§Œ" in name or "prince" in name_lower:
                prompt_parts.append("Saudi Arabian royal figure, early 30s, clean-shaven with trimmed goatee, wearing traditional white thobe with gold-trimmed bisht cloak, red-checkered keffiyeh headpiece, authoritative posture")
            elif "ì¹´ìŠˆí¬ì§€" in name or "khashoggi" in name_lower or "ê¸°ì" in desc_lower or "ì–¸ë¡ " in desc_lower:
                prompt_parts.append("Middle Eastern man, late 50s, salt-and-pepper beard neatly trimmed, glasses with thin metal frames, wearing dark gray business suit, professional journalist appearance, serious expression")
            elif "ìˆœë¡€" in name or "ì‹ ë„" in name:
                prompt_parts.append("Group of Muslim pilgrims, diverse ages, wearing white ihram garments, reverent expressions")
            else:
                prompt_parts.append("Middle Eastern person, traditional Arab appearance, dignified posture")

        # === ê³ ëŒ€ ì´ì§‘íŠ¸ ===
        elif any(kw in context for kw in ["ì´ì§‘íŠ¸", "í”¼ë¼ë¯¸ë“œ", "íŒŒë¼ì˜¤", "egypt", "pharaoh", "pyramid"]):
            if "íŒŒë¼ì˜¤" in name or "ì™•" in name or "pharaoh" in name_lower:
                prompt_parts.append("Ancient Egyptian pharaoh, golden headdress with cobra emblem, kohl-lined eyes, ceremonial regalia, powerful stance")
            elif "ì œì‚¬ì¥" in name or "ì‹ ê´€" in name or "priest" in name_lower:
                prompt_parts.append("Ancient Egyptian priest, shaved head, kohl-lined eyes, white linen robe, golden necklace, holding staff")
            else:
                prompt_parts.append("Ancient Egyptian figure, traditional ancient Egyptian attire, dignified appearance")

        # === ë©”ì†Œí¬íƒ€ë¯¸ì•„/ìˆ˜ë©”ë¥´ ===
        elif any(kw in context for kw in ["ë©”ì†Œí¬íƒ€ë¯¸ì•„", "ìˆ˜ë©”ë¥´", "ë°”ë¹Œë¡ ", "ì§€êµ¬ë¼íŠ¸", "mesopotamia", "sumerian", "babylon"]):
            if "ì™•" in name or "king" in name_lower:
                prompt_parts.append("Ancient Mesopotamian king, long curled beard, conical crown, ornate robes, holding scepter")
            elif "ì œì‚¬ì¥" in name or "ì‹ ê´€" in name:
                prompt_parts.append("Ancient Mesopotamian priest, ceremonial robes, ritual headdress")
            else:
                prompt_parts.append("Ancient Mesopotamian figure, traditional Sumerian attire")

        # === ì›ì‹œ/ì„ ì‚¬ì‹œëŒ€ ===
        elif any(kw in context for kw in ["ì›ì‹œ", "ì„ ì‚¬", "ì¡±ì¥", "ì£¼ìˆ ì‚¬", "ë¶€ì¡±", "primitive", "tribal", "shaman"]):
            if "ì¡±ì¥" in name or "chief" in name_lower:
                prompt_parts.append("Primitive tribal chief, strong muscular build, animal hide clothing, bone necklace, commanding presence")
            elif "ì£¼ìˆ ì‚¬" in name or "shaman" in name_lower:
                prompt_parts.append("Tribal shaman, mystical appearance, feathered headdress, ritual face paint, holding staff with animal skull")
            else:
                prompt_parts.append("Prehistoric human, primitive clothing, weathered appearance")

        # === í˜„ëŒ€ ì¸ë¬¼ ===
        elif any(kw in context for kw in ["í˜„ëŒ€", "ëŒ€í†µë ¹", "ì •ì¹˜", "ê¸°ì", "ì–¸ë¡ ", "modern", "president", "journalist"]):
            if "ëŒ€í†µë ¹" in name or "president" in name_lower:
                prompt_parts.append("Modern political leader, formal suit, confident posture, professional appearance")
            elif "ê¸°ì" in name or "ì–¸ë¡ " in desc_lower:
                prompt_parts.append("Modern journalist, professional attire, press badge, determined expression")
            else:
                prompt_parts.append("Modern professional, business attire, contemporary appearance")

        # === í•œêµ­ ê´€ë ¨ ===
        elif any(kw in context for kw in ["í•œêµ­", "ì¡°ì„ ", "korean", "korea"]):
            if "ì™•" in name or "king" in name_lower:
                prompt_parts.append("Korean king, traditional royal hanbok with gold embroidery, royal crown, dignified appearance")
            else:
                prompt_parts.append("Korean person, traditional or modern Korean attire, dignified appearance")

        # === ì§‘ë‹¨/ê·¸ë£¹ ===
        if any(kw in name for kw in ["ë“¤", "êµ­ë¯¼", "ì‚¬ëŒë“¤", "êµ°ì¤‘", "ì§‘ë‹¨"]):
            if not prompt_parts:
                prompt_parts.append("Group of people, diverse ages and appearances, unified expression")

        # === ê¸°ë³¸ê°’ ===
        if not prompt_parts:
            # ì„¤ëª…ì—ì„œ íŒíŠ¸ ì¶”ì¶œ
            if description:
                prompt_parts.append(f"Person characterized as {description[:80]}, appropriate historical or cultural attire")
            else:
                prompt_parts.append("Person in appropriate historical or cultural attire, neutral expression")

        return prompt_parts[0] if prompt_parts else "Person in appropriate attire"

    def _call_anthropic(self, prompt: str) -> str:
        """Anthropic API í˜¸ì¶œ"""
        debug_log("  Anthropic API í˜¸ì¶œ ì¤‘...")
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=8000,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text

    def _call_gemini(self, prompt: str) -> str:
        """Google Gemini API í˜¸ì¶œ (í•˜ìœ„ í˜¸í™˜ìš© ë˜í¼)"""
        text, _ = self._call_gemini_with_status(prompt)
        return text

    def _call_gemini_with_status(self, prompt: str) -> tuple:
        """
        Google Gemini API í˜¸ì¶œ (finish_reason ë°˜í™˜)

        Returns:
            (response_text, finish_reason)
            finish_reason: 1=STOP(ì •ìƒ), 2=MAX_TOKENS(ì˜ë¦¼!), 3=SAFETY, etc.
        """
        model_name = getattr(self, 'gemini_model_name', 'unknown')
        max_tokens = getattr(self, 'max_output_tokens', 65536)
        debug_log(f"  Gemini API í˜¸ì¶œ ì¤‘...")
        debug_log(f"  ğŸ“Œ ëª¨ë¸: {model_name}")
        debug_log(f"  ğŸ“Œ ìµœëŒ€ ì¶œë ¥ í† í°: {max_tokens:,}")
        debug_log(f"  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")

        if not self.gemini_available or self.gemini_model is None:
            raise RuntimeError("""
Geminië¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
1. pip install google-generativeai
2. GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •
""")

        try:
            # â­ ì„ íƒëœ ëª¨ë¸ì˜ max_output_tokens ì‚¬ìš©
            response = self.gemini_model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.2,
                    "max_output_tokens": max_tokens,  # â­ ëª¨ë¸ë³„ ì„¤ì • ì ìš©
                    "top_p": 0.95,
                }
            )

            # ì‘ë‹µ í™•ì¸ - ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            if response is None:
                debug_log("âŒ Gemini ì‘ë‹µ None")
                return "", 0

            # â­ ì‘ë‹µ ì¢…ë£Œ ì´ìœ  í™•ì¸ (ìˆ«ìë¡œ ë°˜í™˜)
            finish_reason = 1  # ê¸°ë³¸ê°’: STOP (ì •ìƒ)
            finish_reason_names = {
                0: "FINISH_REASON_UNSPECIFIED",
                1: "STOP (ì •ìƒ)",
                2: "MAX_TOKENS (ì˜ë¦¼!)",
                3: "SAFETY",
                4: "RECITATION",
                5: "OTHER"
            }

            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    raw_reason = candidate.finish_reason
                    # Enumì´ë©´ ê°’ ì¶”ì¶œ, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ
                    if hasattr(raw_reason, 'value'):
                        finish_reason = raw_reason.value
                    elif isinstance(raw_reason, int):
                        finish_reason = raw_reason
                    else:
                        # ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                        reason_str = str(raw_reason)
                        if "MAX_TOKENS" in reason_str or "2" in reason_str:
                            finish_reason = 2
                        elif "STOP" in reason_str or "1" in reason_str:
                            finish_reason = 1

                    reason_name = finish_reason_names.get(finish_reason, f"UNKNOWN({finish_reason})")
                    debug_log(f"  ì¢…ë£Œ ì´ìœ : {finish_reason} ({reason_name})")

                    if finish_reason == 2:
                        debug_log("  âš ï¸ ì¶œë ¥ í† í° ì œí•œìœ¼ë¡œ ì‘ë‹µì´ ì˜ë ¸ìŠµë‹ˆë‹¤!")

            # ë°©ë²• 1: response.text ì§ì ‘ ì ‘ê·¼
            if hasattr(response, 'text') and response.text:
                result = response.text
                debug_log(f"  ì‘ë‹µ ê¸¸ì´: {len(result)} ë¬¸ì")
                return result, finish_reason

            # ë°©ë²• 2: candidatesì—ì„œ ì¶”ì¶œ
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and candidate.content:
                    parts = candidate.content.parts
                    if parts:
                        result = parts[0].text
                        debug_log(f"  ì‘ë‹µ ê¸¸ì´ (candidates): {len(result)} ë¬¸ì")
                        return result, finish_reason

            # ë°©ë²• 3: í”„ë¡¬í”„íŠ¸ í”¼ë“œë°± í™•ì¸ (ì°¨ë‹¨ëœ ê²½ìš°)
            if hasattr(response, 'prompt_feedback'):
                feedback = response.prompt_feedback
                debug_log(f"âš ï¸ í”„ë¡¬í”„íŠ¸ í”¼ë“œë°±: {feedback}")
                if hasattr(feedback, 'block_reason') and feedback.block_reason:
                    debug_log(f"âŒ ì°¨ë‹¨ ì´ìœ : {feedback.block_reason}")

            debug_log("âŒ Gemini ë¹ˆ ì‘ë‹µ ë°›ìŒ")
            return "", finish_reason

        except Exception as e:
            error_msg = str(e)
            debug_log(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {error_msg}")

            # 404 ì˜¤ë¥˜ ì‹œ ë” ìì„¸í•œ ì•ˆë‚´
            if "404" in error_msg:
                debug_log(f"âš ï¸ ëª¨ë¸ '{model_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                debug_log("   ì•±ì„ ì¬ì‹œì‘í•˜ì—¬ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‹œë„í•˜ì„¸ìš”.")

            raise

    def _continue_gemini_generation(self, partial_response: str, original_script: str) -> str:
        """
        MAX_TOKENSë¡œ ì˜ë¦° ì‘ë‹µì„ ì´ì–´ì„œ ìƒì„±

        Args:
            partial_response: ì˜ë¦° ì‘ë‹µ
            original_script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸

        Returns:
            ì™„ì„±ëœ ì‘ë‹µ
        """
        debug_log("  ğŸ”„ ì´ì–´ì„œ ìƒì„± ì‹œì‘...")

        all_response = partial_response
        max_continuations = 3  # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì´ì–´ì„œ ìƒì„±

        # ğŸ”´ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ìš©)
        script_ending = original_script[-2000:] if len(original_script) > 2000 else original_script

        for i in range(max_continuations):
            debug_log(f"  ì´ì–´ì„œ ìƒì„± {i+1}/{max_continuations}")

            # ğŸ”´ ê°œì„ ëœ ì´ì–´ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ - ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ í¬í•¨ ë° ë³´ì¡´ ê·œì¹™ ê°•ì¡°
            continuation_prompt = f"""ì´ì „ JSON ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì¤‘ê°„ì— ì˜ë ¸ìŠµë‹ˆë‹¤.
ì´ì–´ì„œ JSONì„ ì™„ì„±í•´ì£¼ì„¸ìš”.

ğŸ”´ğŸ”´ğŸ”´ [CRITICAL] ìŠ¤í¬ë¦½íŠ¸ ì›ë³¸ ë³´ì¡´ ì ˆëŒ€ ê·œì¹™ ğŸ”´ğŸ”´ğŸ”´

âš ï¸ ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™: script_textì—ëŠ” ì•„ë˜ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì— ìˆëŠ” ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!

**ğŸš« ì ˆëŒ€ ê¸ˆì§€:**
- ìŠ¤í¬ë¦½íŠ¸ì— ì—†ëŠ” ë¬¸ì¥ ë§Œë“¤ê¸° âŒ
- "êµ¬ë…ê³¼ ì¢‹ì•„ìš” ë¶€íƒë“œë¦½ë‹ˆë‹¤" ê°™ì€ ì¼ë°˜ ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€ âŒ
- "ë‹¤ìŒ ì˜ìƒì—ì„œ ë§Œë‚˜ìš”" ê°™ì€ ë¬¸ì¥ ì¶”ê°€ âŒ
- ì›ë³¸ ë¬¸ì¥ì„ ë‹¤ë¥´ê²Œ ë°”ê¾¸ê¸° âŒ

**âœ… ë°˜ë“œì‹œ:**
- ì•„ë˜ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì— ìˆëŠ” ë¬¸ì¥ë§Œ script_textì— ì‚¬ìš©
- ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë³µì‚¬

=== ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ (ì´ ë‚´ìš©ë§Œ ì‚¬ìš©!) ===
{original_script}
=== ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë ===

=== íŠ¹íˆ ìŠ¤í¬ë¦½íŠ¸ ë§ˆì§€ë§‰ ë¶€ë¶„ (ì´ ë¬¸ì¥ë“¤ë¡œ ë§ˆì§€ë§‰ ì”¬ì„ ë§Œë“œì„¸ìš”!) ===
{script_ending}
=== ë§ˆì§€ë§‰ ë¶€ë¶„ ë ===

=== ì´ì „ ì‘ë‹µì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ (ì—¬ê¸°ì„œ ì´ì–´ì„œ ì‘ì„±) ===
{all_response[-2000:]}
=== ì´ì „ ì‘ë‹µ ë ===

ìœ„ JSONì„ ì´ì–´ì„œ ì™„ì„±í•´ì£¼ì„¸ìš”:
1. ì¤‘ë³µ ì—†ì´ ì´ì–´ì„œ ì‘ì„± (ë§ˆì§€ë§‰ ë¶€ë¶„ ë°”ë¡œ ë‹¤ìŒë¶€í„°)
2. ë‚¨ì€ ì”¬ë“¤ì„ ëª¨ë‘ í¬í•¨
3. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONìœ¼ë¡œ ì™„ì„±
4. ë§ˆì§€ë§‰ì— }}ë¡œ JSON ë‹«ê¸°
5. ğŸ”´ script_textì—ëŠ” ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì— ìˆëŠ” ë¬¸ì¥ë§Œ ì‚¬ìš©!

ë°”ë¡œ ì´ì–´ì„œ ì‘ì„± (```json ì—†ì´):"""

            continuation_text, finish_reason = self._call_gemini_with_status(continuation_prompt)

            if not continuation_text:
                debug_log("  âš ï¸ ì´ì–´ì„œ ìƒì„± ì‘ë‹µ ì—†ìŒ")
                break

            # ì‘ë‹µ ë³‘í•©
            all_response = self._smart_merge_responses(all_response, continuation_text)
            debug_log(f"  ë³‘í•© í›„ ê¸¸ì´: {len(all_response)} ë¬¸ì")

            # ì •ìƒ ì¢…ë£Œë©´ ì¤‘ë‹¨
            if finish_reason == 1:
                debug_log("  âœ… ì •ìƒ ì¢…ë£Œ - ì´ì–´ì„œ ìƒì„± ì™„ë£Œ")
                break

        return all_response

    def _smart_merge_responses(self, original: str, continuation: str) -> str:
        """ì‘ë‹µ ìŠ¤ë§ˆíŠ¸ ë³‘í•© (ì¤‘ë³µ ì œê±°)"""

        # continuation ì •ë¦¬
        continuation = continuation.strip()

        # ```json ë¸”ë¡ ì œê±°
        if "```json" in continuation:
            continuation = continuation.split("```json")[-1]
        if "```" in continuation:
            parts = continuation.split("```")
            continuation = parts[0] if parts else continuation

        continuation = continuation.strip()

        if not continuation:
            return original

        # originalì—ì„œ ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¶€ë¶„ ì°¾ê¸°
        # ì¼ë°˜ì ìœ¼ë¡œ }, ë˜ëŠ” ] ì´í›„ê°€ ì™„ì „í•œ ìœ„ì¹˜
        last_complete_obj = original.rfind('},')
        last_complete_arr = original.rfind('],')
        last_complete = max(last_complete_obj, last_complete_arr)

        if last_complete > len(original) - 1000:
            # ë§ˆì§€ë§‰ ì™„ì „í•œ ìš”ì†Œê¹Œì§€ë§Œ ì‚¬ìš©
            original_clean = original[:last_complete + 2]  # }, ë˜ëŠ” ], í¬í•¨

            # continuationì´ ì‰¼í‘œë‚˜ ê³µë°±ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì •ë¦¬
            cont_clean = continuation.lstrip(', \n\t')

            # { ë˜ëŠ” "ë¡œ ì‹œì‘í•˜ë©´ ìƒˆ ìš”ì†Œ
            if cont_clean.startswith('{') or cont_clean.startswith('"'):
                merged = original_clean + "\n" + cont_clean
            elif cont_clean.startswith(']') or cont_clean.startswith('}'):
                # ë‹«ëŠ” ê´„í˜¸ë©´ ê·¸ëŒ€ë¡œ ë¶™ì´ê¸°
                merged = original_clean + cont_clean
            else:
                # ê¸°íƒ€: ê·¸ëƒ¥ ì´ì–´ë¶™ì´ê¸°
                merged = original + continuation
        else:
            # ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì°¾ê¸° ì‹œë„
            overlap_len = min(100, len(original), len(continuation))
            for i in range(overlap_len, 10, -5):
                search = original[-i:]
                pos = continuation.find(search)
                if pos != -1:
                    merged = original + continuation[pos + len(search):]
                    debug_log(f"  ì¤‘ë³µ {i}ì ì œê±°")
                    return merged

            # ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì´ì–´ë¶™ì´ê¸°
            merged = original + continuation

        return merged

    def extract_characters(self, script: str) -> List[Dict]:
        """ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë“±ì¥ì¸ë¬¼ë§Œ ì¶”ì¶œ (ìƒì„¸ ì™¸ëª¨ í”„ë¡¬í”„íŠ¸ í¬í•¨)"""
        debug_log("extract_characters ì‹œì‘")
        debug_log(f"  ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´: {len(script)} ë¬¸ì")

        # ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦
        if not script or len(script.strip()) < 10:
            debug_log("ì˜¤ë¥˜: ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
            return []

        # í…œí”Œë¦¿ì—ì„œ ìºë¦­í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        base_prompt = self.template_manager.get_prompt("character_extraction")
        debug_log(f"  base_prompt ê¸¸ì´: {len(base_prompt)} ë¬¸ì")

        if not base_prompt:
            debug_log("ì˜¤ë¥˜: character_extraction í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return []

        prompt = f"""{base_prompt}

## ìŠ¤í¬ë¦½íŠ¸
{script}

JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        try:
            if self.provider == "google":
                result_text = self._call_gemini(prompt)
            else:
                result_text = self._call_anthropic(prompt)

            debug_log(f"  API ì‘ë‹µ ê¸¸ì´: {len(result_text)} ë¬¸ì")
        except Exception as e:
            debug_log(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return []

        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0]

        try:
            characters = json.loads(result_text.strip())
            debug_log(f"  ìºë¦­í„° {len(characters)}ëª… ì¶”ì¶œë¨")
        except json.JSONDecodeError as e:
            debug_log(f"  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            characters = []

        return characters

    def generate_direction_guide(self, scene_text: str, characters: List[str] = None) -> Dict:
        """ë‹¨ì¼ ì”¬ì— ëŒ€í•œ ì—°ì¶œê°€ì´ë“œ ìƒì„±"""

        characters = characters or []

        prompt = f"""ë‹¤ìŒ ì”¬ì— ëŒ€í•œ ì—°ì¶œê°€ì´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì”¬ í…ìŠ¤íŠ¸
{scene_text}

## ë“±ì¥ ìºë¦­í„°
{', '.join(characters) if characters else 'ì—†ìŒ'}

## ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "direction_guide": "ìƒì„¸í•œ ì—°ì¶œ ì„¤ëª…",
    "visual_composition": "í™”ë©´ êµ¬ì„± ì„¤ëª…",
    "background": "ë°°ê²½ ì„¤ëª…",
    "character_actions": "ìºë¦­í„° ë™ì‘/í‘œì •",
    "mood_lighting": "ë¶„ìœ„ê¸°ì™€ ì¡°ëª…",
    "image_prompt_en": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (FLUXìš©, ìƒì„¸í•˜ê²Œ)"
}}

JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )

        result_text = response.content[0].text

        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]

        try:
            guide = json.loads(result_text.strip())
        except json.JSONDecodeError:
            guide = {"direction_guide": "", "image_prompt_en": ""}

        return guide


def analyze_and_save(script_path: str, output_dir: str, language: str = "ko") -> Dict:
    """ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ ì €ì¥"""

    script_path = Path(script_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
    script = script_path.read_text(encoding="utf-8")

    # ë¶„ì„
    analyzer = SceneAnalyzer()
    result = analyzer.analyze_script(script, language)

    # ì €ì¥
    scenes_path = output_dir / "scenes.json"
    characters_path = output_dir / "characters.json"

    with open(scenes_path, "w", encoding="utf-8") as f:
        json.dump(result.get("scenes", []), f, ensure_ascii=False, indent=2)

    with open(characters_path, "w", encoding="utf-8") as f:
        json.dump(result.get("characters", []), f, ensure_ascii=False, indent=2)

    return result
