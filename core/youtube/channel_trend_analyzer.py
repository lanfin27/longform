# -*- coding: utf-8 -*-
"""
ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„ê¸°

ì—­ì¶”ì  ë¡œì§ì„ ì‚¬ìš©í•˜ì—¬ ì‹ ê·œ ì±„ë„ ë°œêµ´ ë° íŠ¸ë Œë“œ ë¶„ì„
YouTube APIëŠ” ì±„ë„ ìƒì„±ì¼ ê¸°ì¤€ ê²€ìƒ‰ì´ ì•ˆ ë˜ë¯€ë¡œ,
"ìµœê·¼ ì˜ìƒ ê²€ìƒ‰ â†’ ì±„ë„ ID ì¶”ì¶œ â†’ ì±„ë„ ìƒì„±ì¼ í•„í„°ë§" ë°©ì‹ ì‚¬ìš©
"""
import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from collections import Counter
from dateutil import parser
import hashlib

from googleapiclient.discovery import build

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from config.settings import YOUTUBE_API_KEY
from core.youtube.cache import get_cache


@dataclass
class NewChannel:
    """ì‹ ê·œ ì±„ë„ ì •ë³´"""
    channel_id: str
    title: str
    description: str
    created_at: str  # YYYY-MM-DD
    created_at_dt: datetime
    subscribers: int
    video_count: int
    view_count: int
    thumbnail_url: str
    channel_url: str

    # ê³„ì‚° ì§€í‘œ
    avg_views_per_video: float = 0.0
    subscribers_per_video: float = 0.0  # ì˜ìƒë‹¹ êµ¬ë…ì íš¨ìœ¨
    days_since_creation: int = 0
    growth_rate: str = "ë³´í†µ"  # ê¸‰ì„±ì¥/ë³´í†µ/ì €ì¡°

    def calculate_metrics(self):
        """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
        if self.video_count > 0:
            self.avg_views_per_video = self.view_count / self.video_count
            self.subscribers_per_video = self.subscribers / self.video_count

        self.days_since_creation = (datetime.now() - self.created_at_dt).days

        # ì„±ì¥ë¥  íŒì • (ì˜ìƒë‹¹ êµ¬ë…ì ê¸°ì¤€)
        if self.subscribers_per_video >= 100:
            self.growth_rate = "ğŸš€ ê¸‰ì„±ì¥"
        elif self.subscribers_per_video >= 30:
            self.growth_rate = "ğŸ“ˆ ì–‘í˜¸"
        elif self.subscribers_per_video >= 10:
            self.growth_rate = "â¡ï¸ ë³´í†µ"
        else:
            self.growth_rate = "ğŸ“‰ ì €ì¡°"

    def to_dict(self) -> dict:
        return {
            "channel_id": self.channel_id,
            "title": self.title,
            "description": self.description[:200] if self.description else "",
            "created_at": self.created_at,
            "subscribers": self.subscribers,
            "video_count": self.video_count,
            "view_count": self.view_count,
            "avg_views_per_video": round(self.avg_views_per_video, 1),
            "subscribers_per_video": round(self.subscribers_per_video, 1),
            "days_since_creation": self.days_since_creation,
            "growth_rate": self.growth_rate,
            "channel_url": self.channel_url,
            "thumbnail_url": self.thumbnail_url
        }


@dataclass
class TrendAnalysisResult:
    """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼"""
    keyword: str
    region: str
    period_months: int
    analysis_date: str

    total_videos_searched: int
    unique_channels_found: int
    new_channels_count: int

    new_channels: List[NewChannel] = field(default_factory=list)
    monthly_trend: Dict[str, int] = field(default_factory=dict)  # {"2024-01": 3, "2024-02": 5, ...}

    # ìš”ì•½ í†µê³„
    avg_subscribers: float = 0.0
    avg_video_count: float = 0.0
    avg_views: float = 0.0

    # AI ì¸ì‚¬ì´íŠ¸
    ai_insight: str = ""

    def calculate_summary(self):
        """ìš”ì•½ í†µê³„ ê³„ì‚°"""
        if self.new_channels:
            self.avg_subscribers = sum(c.subscribers for c in self.new_channels) / len(self.new_channels)
            self.avg_video_count = sum(c.video_count for c in self.new_channels) / len(self.new_channels)
            self.avg_views = sum(c.view_count for c in self.new_channels) / len(self.new_channels)


class ChannelTrendAnalyzer:
    """ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„ê¸°"""

    def __init__(self, api_key: str = None, cache_dir: str = "data/cache/channel_trends"):
        """
        Args:
            api_key: YouTube API í‚¤ (ê¸°ë³¸: í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬
        """
        self.api_key = api_key or YOUTUBE_API_KEY
        if not self.api_key:
            raise ValueError("YouTube API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

        self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

        self.cache_expiry_days = 7
        self._cache = get_cache()

    def _get_cache_key(self, keyword: str, region: str, months: int) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_str = f"trend_{keyword}_{region}_{months}"
        return hashlib.md5(key_str.encode()).hexdigest()[:16]

    def _get_cached_result(self, cache_key: str) -> Optional[dict]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")

        if os.path.exists(cache_file):
            stat = os.stat(cache_file)
            age_days = (datetime.now().timestamp() - stat.st_mtime) / 86400

            if age_days < self.cache_expiry_days:
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
                except:
                    pass

        return None

    def _save_cache(self, cache_key: str, data: dict):
        """ê²°ê³¼ ìºì‹±"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            print(f"[ChannelTrend] ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")

    def analyze_channel_trend(
        self,
        keyword: str,
        region: str = "KR",
        months: int = 6,
        max_videos: int = 100,
        use_cache: bool = True,
        progress_callback=None
    ) -> TrendAnalysisResult:
        """
        ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤í–‰

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            region: êµ­ê°€ ì½”ë“œ (KR, JP, US ë“±)
            months: ë¶„ì„ ê¸°ê°„ (ê°œì›”)
            max_videos: ìµœëŒ€ ê²€ìƒ‰ ì˜ìƒ ìˆ˜
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜

        Returns:
            TrendAnalysisResult
        """
        def update_progress(msg):
            if progress_callback:
                progress_callback(msg)
            print(f"[ChannelTrend] {msg}")

        # ìºì‹œ í™•ì¸
        cache_key = self._get_cache_key(keyword, region, months)
        if use_cache:
            cached = self._get_cached_result(cache_key)
            if cached:
                update_progress("ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©")
                return self._dict_to_result(cached)

        # 1. ê¸°ì¤€ ë‚ ì§œ ì„¤ì •
        cutoff_date = datetime.now() - timedelta(days=months * 30)
        published_after = cutoff_date.isoformat() + "Z"

        # 2. ìµœê·¼ ì˜ìƒ ê²€ìƒ‰ (Step 1)
        update_progress(f"í‚¤ì›Œë“œ '{keyword}' ì˜ìƒ ê²€ìƒ‰ ì¤‘...")

        all_videos = []
        next_page_token = None

        while len(all_videos) < max_videos:
            try:
                search_response = self.youtube.search().list(
                    q=keyword,
                    part="snippet",
                    type="video",
                    order="date",  # ìµœì‹ ìˆœ
                    publishedAfter=published_after,
                    regionCode=region,
                    maxResults=min(50, max_videos - len(all_videos)),
                    pageToken=next_page_token
                ).execute()

                # í• ë‹¹ëŸ‰ ê¸°ë¡
                self._cache.log_api_call("search")

                all_videos.extend(search_response.get('items', []))
                next_page_token = search_response.get('nextPageToken')

                if not next_page_token:
                    break

            except Exception as e:
                update_progress(f"ì˜ìƒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                break

        update_progress(f"ì´ {len(all_videos)}ê°œ ì˜ìƒ ê²€ìƒ‰ë¨")

        if not all_videos:
            return TrendAnalysisResult(
                keyword=keyword,
                region=region,
                period_months=months,
                analysis_date=datetime.now().strftime("%Y-%m-%d %H:%M"),
                total_videos_searched=0,
                unique_channels_found=0,
                new_channels_count=0,
                new_channels=[],
                monthly_trend={}
            )

        # 3. ì±„ë„ ID ì¶”ì¶œ (Step 2)
        channel_ids = list(set([
            item['snippet']['channelId']
            for item in all_videos
            if 'channelId' in item['snippet']
        ]))

        update_progress(f"ê³ ìœ  ì±„ë„ {len(channel_ids)}ê°œ ë°œê²¬")

        # 4. ì±„ë„ ìƒì„¸ ì •ë³´ ì¡°íšŒ (Step 3)
        update_progress("ì±„ë„ ì •ë³´ ì¡°íšŒ ì¤‘...")
        all_channel_data = []

        for i in range(0, len(channel_ids), 50):
            batch_ids = channel_ids[i:i+50]

            try:
                channels_response = self.youtube.channels().list(
                    part="snippet,statistics",
                    id=",".join(batch_ids)
                ).execute()

                # í• ë‹¹ëŸ‰ ê¸°ë¡
                self._cache.log_api_call("channels")

                all_channel_data.extend(channels_response.get('items', []))

            except Exception as e:
                update_progress(f"ì±„ë„ ì¡°íšŒ ì˜¤ë¥˜: {e}")

        # 5. ì±„ë„ ìƒì„±ì¼ í•„í„°ë§ (Step 4) - í•µì‹¬!
        update_progress("ì‹ ê·œ ì±„ë„ í•„í„°ë§ ì¤‘...")
        new_channels: List[NewChannel] = []
        monthly_counter = Counter()

        for ch in all_channel_data:
            try:
                # ì±„ë„ ìƒì„±ì¼ íŒŒì‹±
                created_at_str = ch['snippet']['publishedAt']
                created_at = parser.parse(created_at_str).replace(tzinfo=None)

                # ì‹ ê·œ ì±„ë„ í•„í„°ë§ (ê¸°ì¤€ì¼ ì´í›„ ìƒì„±)
                if created_at > cutoff_date:
                    stats = ch.get('statistics', {})

                    # ë¹„ê³µê°œ í†µê³„ ì²˜ë¦¬
                    subscribers = int(stats.get('subscriberCount', 0))
                    video_count = int(stats.get('videoCount', 0))
                    view_count = int(stats.get('viewCount', 0))

                    new_channel = NewChannel(
                        channel_id=ch['id'],
                        title=ch['snippet']['title'],
                        description=ch['snippet'].get('description', ''),
                        created_at=created_at.strftime('%Y-%m-%d'),
                        created_at_dt=created_at,
                        subscribers=subscribers,
                        video_count=video_count,
                        view_count=view_count,
                        thumbnail_url=ch['snippet']['thumbnails']['default']['url'],
                        channel_url=f"https://youtube.com/channel/{ch['id']}"
                    )

                    new_channel.calculate_metrics()
                    new_channels.append(new_channel)

                    # ì›”ë³„ ì¹´ìš´íŠ¸
                    month_key = created_at.strftime('%Y-%m')
                    monthly_counter[month_key] += 1

            except Exception as e:
                print(f"[ChannelTrend] ì±„ë„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue

        # 6. ê²°ê³¼ ì •ë ¬ (ìµœì‹ ìˆœ)
        new_channels.sort(key=lambda x: x.created_at_dt, reverse=True)

        # ì›”ë³„ íŠ¸ë Œë“œ ì •ë ¬
        monthly_trend = dict(sorted(monthly_counter.items()))

        update_progress(f"ì‹ ê·œ ì±„ë„ {len(new_channels)}ê°œ ë°œê²¬")

        # 7. ê²°ê³¼ ìƒì„±
        result = TrendAnalysisResult(
            keyword=keyword,
            region=region,
            period_months=months,
            analysis_date=datetime.now().strftime("%Y-%m-%d %H:%M"),
            total_videos_searched=len(all_videos),
            unique_channels_found=len(channel_ids),
            new_channels_count=len(new_channels),
            new_channels=new_channels,
            monthly_trend=monthly_trend
        )

        result.calculate_summary()

        # ìºì‹±
        self._save_cache(cache_key, self._result_to_dict(result))

        return result

    def _result_to_dict(self, result: TrendAnalysisResult) -> dict:
        """ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ìºì‹±ìš©)"""
        return {
            "keyword": result.keyword,
            "region": result.region,
            "period_months": result.period_months,
            "analysis_date": result.analysis_date,
            "total_videos_searched": result.total_videos_searched,
            "unique_channels_found": result.unique_channels_found,
            "new_channels_count": result.new_channels_count,
            "new_channels": [c.to_dict() for c in result.new_channels],
            "monthly_trend": result.monthly_trend,
            "avg_subscribers": result.avg_subscribers,
            "avg_video_count": result.avg_video_count,
            "avg_views": result.avg_views,
            "ai_insight": result.ai_insight
        }

    def _dict_to_result(self, data: dict) -> TrendAnalysisResult:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ ê²°ê³¼ ê°ì²´ë¡œ ë³€í™˜"""
        new_channels = []
        for ch_data in data.get("new_channels", []):
            try:
                ch = NewChannel(
                    channel_id=ch_data["channel_id"],
                    title=ch_data["title"],
                    description=ch_data.get("description", ""),
                    created_at=ch_data["created_at"],
                    created_at_dt=datetime.strptime(ch_data["created_at"], "%Y-%m-%d"),
                    subscribers=ch_data["subscribers"],
                    video_count=ch_data["video_count"],
                    view_count=ch_data["view_count"],
                    thumbnail_url=ch_data.get("thumbnail_url", ""),
                    channel_url=ch_data.get("channel_url", ""),
                    avg_views_per_video=ch_data.get("avg_views_per_video", 0),
                    subscribers_per_video=ch_data.get("subscribers_per_video", 0),
                    days_since_creation=ch_data.get("days_since_creation", 0),
                    growth_rate=ch_data.get("growth_rate", "ë³´í†µ")
                )
                new_channels.append(ch)
            except Exception as e:
                print(f"[ChannelTrend] ì±„ë„ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue

        result = TrendAnalysisResult(
            keyword=data["keyword"],
            region=data["region"],
            period_months=data["period_months"],
            analysis_date=data["analysis_date"],
            total_videos_searched=data["total_videos_searched"],
            unique_channels_found=data["unique_channels_found"],
            new_channels_count=data["new_channels_count"],
            new_channels=new_channels,
            monthly_trend=data["monthly_trend"],
            avg_subscribers=data.get("avg_subscribers", 0),
            avg_video_count=data.get("avg_video_count", 0),
            avg_views=data.get("avg_views", 0),
            ai_insight=data.get("ai_insight", "")
        )

        return result

    def generate_ai_insight(
        self,
        result: TrendAnalysisResult,
        ai_client=None
    ) -> str:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ìƒì„±

        Args:
            result: íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼
            ai_client: AI í´ë¼ì´ì–¸íŠ¸ (Gemini ë˜ëŠ” Claude)
        """
        if not result.new_channels:
            return "ë¶„ì„ ê¸°ê°„ ë‚´ ì‹ ê·œ ì±„ë„ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        channel_summaries = []
        for ch in result.new_channels[:10]:  # ìƒìœ„ 10ê°œë§Œ
            channel_summaries.append(
                f"- {ch.title}: êµ¬ë…ì {ch.subscribers:,}ëª…, "
                f"ì˜ìƒ {ch.video_count}ê°œ, í‰ê· ì¡°íšŒìˆ˜ {ch.avg_views_per_video:,.0f}"
            )

        prompt = f"""
ë‹¤ìŒì€ '{result.keyword}' í‚¤ì›Œë“œë¡œ ìµœê·¼ {result.period_months}ê°œì›” ë‚´ì— ìƒì„±ëœ ì‹ ê·œ YouTube ì±„ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

## ë¶„ì„ ê°œìš”
- ë¶„ì„ ê¸°ê°„: ìµœê·¼ {result.period_months}ê°œì›”
- ê²€ìƒ‰ëœ ì˜ìƒ ìˆ˜: {result.total_videos_searched}ê°œ
- ë°œê²¬ëœ ì‹ ê·œ ì±„ë„: {result.new_channels_count}ê°œ
- í‰ê·  êµ¬ë…ì: {result.avg_subscribers:,.0f}ëª…
- í‰ê·  ì˜ìƒ ìˆ˜: {result.avg_video_count:.1f}ê°œ

## ì£¼ìš” ì‹ ê·œ ì±„ë„
{chr(10).join(channel_summaries)}

## ì›”ë³„ ì±„ë„ ìƒì„± ì¶”ì´
{json.dumps(result.monthly_trend, ensure_ascii=False)}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì´ ë¶„ì•¼ì˜ ì‹œì¥ ì§„ì… ê°•ë„ (ë ˆë“œì˜¤ì…˜/ë¸”ë£¨ì˜¤ì…˜ íŒë‹¨)
2. ì‹ ê·œ ì±„ë„ë“¤ì˜ ê³µí†µì ì¸ íŠ¹ì§•ì´ë‚˜ ì „ëµ
3. ì‹ ê·œ ì§„ì…ìì—ê²Œ ì¶”ì²œí•˜ëŠ” ì°¨ë³„í™” ì „ëµ

3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""

        if ai_client:
            try:
                # AI API í˜¸ì¶œ
                response = ai_client.generate_content(prompt)
                return response.text if hasattr(response, 'text') else str(response)
            except Exception as e:
                print(f"[ChannelTrend] AI ë¶„ì„ ì˜¤ë¥˜: {e}")

        # AI ì—†ì„ ê²½ìš° ê¸°ë³¸ ë¶„ì„
        return self._generate_basic_insight(result)

    def _generate_basic_insight(self, result: TrendAnalysisResult) -> str:
        """ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± (AI ì—†ì„ ë•Œ)"""
        if result.new_channels_count == 0:
            return f"ìµœê·¼ {result.period_months}ê°œì›”ê°„ '{result.keyword}' ë¶„ì•¼ì— ì‹ ê·œ ì±„ë„ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ë¸”ë£¨ì˜¤ì…˜ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."

        # ì›” í‰ê·  ì‹ ê·œ ì±„ë„ ìˆ˜
        monthly_avg = result.new_channels_count / result.period_months

        # ì„±ì¥ ì±„ë„ ë¹„ìœ¨
        growing = len([c for c in result.new_channels if "ê¸‰ì„±ì¥" in c.growth_rate or "ì–‘í˜¸" in c.growth_rate])
        growing_ratio = growing / result.new_channels_count * 100 if result.new_channels_count > 0 else 0

        insights = []

        # ì§„ì… ê°•ë„ íŒë‹¨
        if monthly_avg >= 5:
            insights.append(f"ğŸ”´ ì›” í‰ê·  {monthly_avg:.1f}ê°œì˜ ì‹ ê·œ ì±„ë„ì´ ìƒì„±ë˜ê³  ìˆì–´ ê²½ìŸì´ ì¹˜ì—´í•œ ë ˆë“œì˜¤ì…˜ì…ë‹ˆë‹¤.")
        elif monthly_avg >= 2:
            insights.append(f"ğŸŸ¡ ì›” í‰ê·  {monthly_avg:.1f}ê°œì˜ ì‹ ê·œ ì±„ë„ì´ ìƒì„±ë˜ë©° ì ë‹¹í•œ ê²½ìŸì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            insights.append(f"ğŸŸ¢ ì›” í‰ê·  {monthly_avg:.1f}ê°œì˜ ì‹ ê·œ ì±„ë„ë§Œ ìƒì„±ë˜ì–´ ì§„ì… ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤.")

        # ì„±ì¥ ê°€ëŠ¥ì„±
        if growing_ratio >= 30:
            insights.append(f"ì‹ ê·œ ì±„ë„ ì¤‘ {growing_ratio:.0f}%ê°€ ì–‘í˜¸í•œ ì„±ì¥ì„ ë³´ì—¬ ì‹œì¥ ì ì¬ë ¥ì´ ë†’ìŠµë‹ˆë‹¤.")
        else:
            insights.append(f"ì‹ ê·œ ì±„ë„ ì¤‘ {growing_ratio:.0f}%ë§Œ ì„±ì¥í•˜ê³  ìˆì–´ ì°¨ë³„í™” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì¶”ì²œ
        if result.avg_subscribers > 1000:
            insights.append("í‰ê·  êµ¬ë…ìê°€ ë†’ì•„ ì–‘ì§ˆì˜ ì½˜í…ì¸ ë¡œ ì¶©ë¶„íˆ ì„±ì¥ ê°€ëŠ¥í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.")

        return " ".join(insights)


# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_channel_trend_analyzer(api_key: str = None) -> ChannelTrendAnalyzer:
    """ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„ê¸° ìƒì„±"""
    return ChannelTrendAnalyzer(api_key=api_key)
