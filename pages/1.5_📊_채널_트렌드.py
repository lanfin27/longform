# -*- coding: utf-8 -*-
"""
ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„ í˜ì´ì§€

íŠ¹ì • í‚¤ì›Œë“œ ë¶„ì•¼ì˜ ì‹ ê·œ ì±„ë„ íƒì§€ ë° ì‹œì¥ ì§„ì… ê°•ë„ ë¶„ì„
- AI í‚¤ì›Œë“œ í™•ì¥ ê¸°ëŠ¥ ì¶”ê°€
- ê·¸ë˜í”„ ìˆ˜ì • (Xì¶• ë‚ ì§œ í˜•ì‹, Yì¶• ì •ìˆ˜ í˜•ì‹)
- ì±„ë„ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
- íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¼ê´„ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import time
import os
import sys

# ê²½ë¡œ ì„¤ì •
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.youtube.channel_trend_analyzer import (
    ChannelTrendAnalyzer,
    TrendAnalysisResult,
    create_channel_trend_analyzer
)

# AI í‚¤ì›Œë“œ í™•ì¥ ë° ì°¨íŠ¸ ëª¨ë“ˆ
try:
    from utils.ai_keyword_suggester import AIKeywordSuggester, get_ai_keyword_suggester
    AI_KEYWORD_AVAILABLE = True
except ImportError:
    AI_KEYWORD_AVAILABLE = False

try:
    from utils.trend_chart import create_monthly_channel_chart, get_trend_interpretation
    TREND_CHART_AVAILABLE = True
except ImportError:
    TREND_CHART_AVAILABLE = False

# ì±„ë„ ê²€ìƒ‰ ëª¨ë“ˆ
try:
    from utils.channel_searcher import YouTubeChannelSearcher, get_channel_searcher
    CHANNEL_SEARCHER_AVAILABLE = True
except ImportError:
    CHANNEL_SEARCHER_AVAILABLE = False

# íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë” ëª¨ë“ˆ
try:
    from utils.transcript_downloader import (
        YouTubeTranscriptDownloader,
        get_transcript_downloader,
        TranscriptResult,
        DownloadProgress,
        DownloadMethod  # â­ ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì¶”ê°€
    )
    TRANSCRIPT_DOWNLOADER_AVAILABLE = True
except ImportError:
    TRANSCRIPT_DOWNLOADER_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.trend-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px;
    border-radius: 12px;
    margin-bottom: 20px;
}

.metric-card {
    background: white;
    padding: 20px;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    text-align: center;
}

.metric-value {
    font-size: 32px;
    font-weight: bold;
    color: #667eea;
}

.metric-label {
    color: #666;
    font-size: 14px;
}

.channel-card {
    background: white;
    padding: 15px;
    border-radius: 10px;
    border-left: 4px solid #667eea;
    margin-bottom: 10px;
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}

.growth-badge {
    display: inline-block;
    padding: 4px 12px;
    border-radius: 20px;
    font-size: 12px;
    font-weight: bold;
}

.growth-rapid { background: #d4edda; color: #155724; }
.growth-good { background: #cce5ff; color: #004085; }
.growth-normal { background: #fff3cd; color: #856404; }
.growth-slow { background: #f8d7da; color: #721c24; }

.insight-box {
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    padding: 20px;
    border-radius: 12px;
    border-left: 4px solid #667eea;
}

.search-result-card {
    background: white;
    padding: 20px;
    border-radius: 12px;
    border-left: 4px solid #28a745;
    margin-bottom: 15px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.08);
}

.queue-item {
    background: #f8f9fa;
    padding: 10px 15px;
    border-radius: 8px;
    margin: 5px 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.transcript-stats {
    background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    padding: 15px;
    border-radius: 10px;
    text-align: center;
}

.download-complete {
    background: #d4edda;
    border: 1px solid #c3e6cb;
    padding: 15px;
    border-radius: 10px;
}
</style>
""", unsafe_allow_html=True)


def get_api_key():
    """API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # ì„¸ì…˜ì—ì„œ ë¨¼ì € í™•ì¸
    if "youtube_api_key" in st.session_state and st.session_state.youtube_api_key:
        return st.session_state.youtube_api_key

    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    from config.settings import YOUTUBE_API_KEY
    if YOUTUBE_API_KEY:
        return YOUTUBE_API_KEY

    return None


def render_header():
    """í—¤ë” ë Œë”ë§"""
    st.markdown("""
    <div class="trend-header">
        <h1>ğŸ“Š ì±„ë„ íŠ¸ë Œë“œ ë¶„ì„</h1>
        <p>íŠ¹ì • í‚¤ì›Œë“œ ë¶„ì•¼ì—ì„œ ìµœê·¼ ìƒì„±ëœ ì‹ ê·œ ì±„ë„ë“¤ì„ ë°œêµ´í•˜ê³  ì‹œì¥ ì§„ì… ê°•ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.</p>
    </div>
    """, unsafe_allow_html=True)


def render_search_form():
    """ê²€ìƒ‰ í¼ ë Œë”ë§"""
    st.markdown("### ğŸ” ë¶„ì„ ì„¤ì •")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Row 1: í‚¤ì›Œë“œ + AI í™•ì¥ ì˜µì…˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    col1, col2, col3 = st.columns([3, 1, 1])

    with col1:
        keyword = st.text_input(
            "í‚¤ì›Œë“œ",
            placeholder="ì˜ˆ: ì¼ë³¸ ì‹œë‹ˆì–´ ë¸Œì´ë¡œê·¸, ì€í‡´ í›„ ì´ë¯¼, ì—°ê¸ˆ",
            help="ë¶„ì„í•  ì£¼ì œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )

    with col2:
        region = st.selectbox(
            "êµ­ê°€",
            options=["KR", "JP", "US", "GB", "AU"],
            format_func=lambda x: {
                "KR": "ğŸ‡°ğŸ‡· í•œêµ­",
                "JP": "ğŸ‡¯ğŸ‡µ ì¼ë³¸",
                "US": "ğŸ‡ºğŸ‡¸ ë¯¸êµ­",
                "GB": "ğŸ‡¬ğŸ‡§ ì˜êµ­",
                "AU": "ğŸ‡¦ğŸ‡º í˜¸ì£¼"
            }.get(x, x)
        )

    with col3:
        months = st.selectbox(
            "ë¶„ì„ ê¸°ê°„",
            options=[1, 3, 6, 12],
            index=2,
            format_func=lambda x: f"ìµœê·¼ {x}ê°œì›”"
        )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Row 2: AI í‚¤ì›Œë“œ í™•ì¥ ì„¤ì •
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    expanded_keywords = []

    if AI_KEYWORD_AVAILABLE:
        with st.expander("ğŸ¤– AI í‚¤ì›Œë“œ í™•ì¥ (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)", expanded=False):
            st.caption("AIê°€ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì²œí•˜ì—¬ ë” ë„“ì€ ë²”ìœ„ì˜ ì±„ë„ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

            col_ai1, col_ai2, col_ai3 = st.columns([1, 1, 1])

            with col_ai1:
                use_ai_expansion = st.checkbox(
                    "AI í‚¤ì›Œë“œ í™•ì¥ ì‚¬ìš©",
                    value=False,
                    key="use_ai_expansion",
                    help="ì²´í¬í•˜ë©´ AIê°€ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤"
                )

            with col_ai2:
                ai_provider = st.selectbox(
                    "AI API",
                    options=["gemini", "claude"],
                    format_func=lambda x: {
                        "gemini": "ğŸ”· Google Gemini",
                        "claude": "ğŸŸ£ Anthropic Claude"
                    }.get(x, x),
                    disabled=not use_ai_expansion,
                    key="ai_provider"
                )

            with col_ai3:
                keyword_count = st.slider(
                    "ì¶”ì²œ í‚¤ì›Œë“œ ìˆ˜",
                    min_value=5,
                    max_value=25,
                    value=15,
                    disabled=not use_ai_expansion,
                    key="keyword_count"
                )

            # AI í‚¤ì›Œë“œ ì¶”ì²œ ì‹¤í–‰
            if use_ai_expansion and keyword:
                if st.button("ğŸ” ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì²œë°›ê¸°", type="secondary"):
                    with st.spinner(f"{ai_provider}ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
                        suggester = get_ai_keyword_suggester(api_provider=ai_provider)

                        if not suggester.check_api_key():
                            st.error(f"âŒ {ai_provider.upper()} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        else:
                            result = suggester.suggest_keywords(
                                keyword=keyword,
                                count=keyword_count
                            )

                            if result.get("success"):
                                st.session_state.ai_keywords = result
                                st.success(f"âœ… {result['total_count']}ê°œ í‚¤ì›Œë“œ ì¶”ì²œ ì™„ë£Œ! (API: {result['api_used']})")
                            else:
                                st.warning("í‚¤ì›Œë“œ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í´ë°± ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                                st.session_state.ai_keywords = result

                # ì¶”ì²œëœ í‚¤ì›Œë“œ í‘œì‹œ ë° ì„ íƒ
                if "ai_keywords" in st.session_state and st.session_state.ai_keywords.get("success"):
                    ai_result = st.session_state.ai_keywords
                    categories = ai_result.get("categories", {})

                    if categories:
                        st.markdown("#### ğŸ“‹ ì¶”ì²œ í‚¤ì›Œë“œ (ë¶„ì„ì— í¬í•¨í•  í‚¤ì›Œë“œ ì„ íƒ)")

                        # ì¹´í…Œê³ ë¦¬ í‘œì‹œ ì´ë¦„
                        cat_display_map = {
                            "ì§ì ‘_ê´€ë ¨": "ğŸ¯ ì§ì ‘ ê´€ë ¨",
                            "ë™ì˜ì–´_ìœ ì‚¬ì–´": "ğŸ”„ ë™ì˜ì–´/ìœ ì‚¬ì–´",
                            "ê´€ë ¨_ì£¼ì œ": "ğŸ“š ê´€ë ¨ ì£¼ì œ",
                            "ë¡±í…Œì¼_í‚¤ì›Œë“œ": "ğŸ” ë¡±í…Œì¼ í‚¤ì›Œë“œ",
                            "íŠ¸ë Œë“œ_í‚¤ì›Œë“œ": "ğŸ“ˆ íŠ¸ë Œë“œ í‚¤ì›Œë“œ"
                        }

                        # ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ
                        for cat_name, keywords in categories.items():
                            if not keywords or not isinstance(keywords, list):
                                continue

                            cat_display = cat_display_map.get(cat_name, cat_name)
                            st.markdown(f"**{cat_display}**")

                            # í‚¤ì›Œë“œ ì¹© í˜•íƒœë¡œ í‘œì‹œ (í•œ ì¤„ì— ìµœëŒ€ 4ê°œ)
                            cols = st.columns(min(len(keywords), 4))
                            for i, kw in enumerate(keywords):
                                if isinstance(kw, str):
                                    with cols[i % 4]:
                                        # ê¸°ë³¸ê°’ì€ ì§ì ‘ ê´€ë ¨ë§Œ ì²´í¬
                                        default_checked = cat_name == "ì§ì ‘_ê´€ë ¨"
                                        if st.checkbox(kw, value=default_checked, key=f"kw_{cat_name}_{i}"):
                                            if kw not in expanded_keywords:
                                                expanded_keywords.append(kw)

                        # ì„ íƒëœ í‚¤ì›Œë“œ ìˆ˜ í‘œì‹œ
                        st.info(f"ğŸ“Š ì„ íƒëœ í™•ì¥ í‚¤ì›Œë“œ: {len(expanded_keywords)}ê°œ")

        # ì„¸ì…˜ì— í™•ì¥ í‚¤ì›Œë“œ ì €ì¥
        st.session_state.expanded_keywords = expanded_keywords

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Row 3: ê¸°ì¡´ ì„¤ì • (ì˜ìƒ ìˆ˜, ìºì‹œ)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    col1, col2, col3 = st.columns([1, 1, 3])

    with col1:
        max_videos = st.number_input(
            "ê²€ìƒ‰ ì˜ìƒ ìˆ˜",
            min_value=50,
            max_value=200,
            value=100,
            step=50,
            help="ë” ë§ì€ ì˜ìƒì„ ê²€ìƒ‰í•˜ë©´ ë” ë§ì€ ì±„ë„ì„ ë°œê²¬í•  ìˆ˜ ìˆì§€ë§Œ, API í• ë‹¹ëŸ‰ì´ ë” ì†Œëª¨ë©ë‹ˆë‹¤."
        )

    with col2:
        use_cache = st.checkbox("ìºì‹œ ì‚¬ìš©", value=True, help="7ì¼ ì´ë‚´ ë™ì¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")

    return keyword, region, months, max_videos, use_cache, expanded_keywords


def render_metrics(result: TrendAnalysisResult):
    """ì£¼ìš” ì§€í‘œ ë Œë”ë§"""
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric(
            "ê²€ìƒ‰ëœ ì˜ìƒ",
            f"{result.total_videos_searched:,}ê°œ"
        )

    with col2:
        st.metric(
            "ê³ ìœ  ì±„ë„",
            f"{result.unique_channels_found:,}ê°œ"
        )

    with col3:
        st.metric(
            "ğŸ†• ì‹ ê·œ ì±„ë„",
            f"{result.new_channels_count:,}ê°œ",
            help=f"ìµœê·¼ {result.period_months}ê°œì›” ë‚´ ìƒì„±ëœ ì±„ë„"
        )

    with col4:
        # í‚¤ì›Œë“œ ê´€ë ¨ ì±„ë„ ìˆ˜
        relevant_count = len([c for c in result.new_channels if c.keyword_relevant])
        st.metric(
            "ğŸ¯ í‚¤ì›Œë“œ ê´€ë ¨",
            f"{relevant_count}ê°œ",
            help="ì±„ë„ëª…/ì„¤ëª…ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì±„ë„"
        )

    with col5:
        # ì‹œì¥ íŒì • (Market Verdict)
        if result.market_verdict_label:
            st.metric(
                "ì‹œì¥ íŒì •",
                result.market_verdict_label,
                help="ê¸°íšŒì§€ìˆ˜ + ê²½ìŸê°•ë„ ê¸°ë°˜ ì‹œì¥ íŒì •"
            )
        else:
            # ì§„ì… ê°•ë„ ê³„ì‚° (fallback)
            monthly_avg = result.new_channels_count / result.period_months if result.period_months > 0 else 0
            if monthly_avg >= 5:
                intensity = "ğŸ”´ ë†’ìŒ"
            elif monthly_avg >= 2:
                intensity = "ğŸŸ¡ ì¤‘ê°„"
            else:
                intensity = "ğŸŸ¢ ë‚®ìŒ"
            st.metric(
                "ì§„ì… ê°•ë„",
                intensity,
                help="ì›” í‰ê·  ì‹ ê·œ ì±„ë„ ìˆ˜ ê¸°ì¤€"
            )


def render_market_opportunity(result: TrendAnalysisResult):
    """ì‹œì¥ ê¸°íšŒ ë¶„ì„ ì„¹ì…˜"""
    st.markdown("### â­ ì‹œì¥ ê¸°íšŒ ë¶„ì„")

    # ê¸°íšŒ ì§€ìˆ˜ ì„¤ëª…
    with st.expander("â„¹ï¸ ê¸°íšŒ ì§€ìˆ˜ë€?", expanded=False):
        st.markdown("""
        **ê¸°íšŒ ì§€ìˆ˜ (Opportunity Score)** = í‰ê·  ì¡°íšŒìˆ˜ / êµ¬ë…ì ìˆ˜

        - ğŸŒŸ **í™©ê¸ˆ ê¸°íšŒ (100+)**: êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ ë§¤ìš° ë†’ìŒ = ì•Œê³ ë¦¬ì¦˜ì´ ë°€ì–´ì£¼ëŠ” í‚¤ì›Œë“œ
        - âœ… **ì¢‹ì€ ê¸°íšŒ (50-100)**: ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¶„ì•¼
        - ğŸŸ¡ **ë³´í†µ (10-50)**: ì¼ë°˜ì ì¸ ê²½ìŸ ìˆ˜ì¤€
        - ğŸ”´ **í¬í™” (<10)**: êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ ë‚®ìŒ = ë ˆë“œì˜¤ì…˜
        """)

    # ì£¼ìš” ì§€í‘œ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        score = result.avg_opportunity_score
        if score >= 100:
            score_emoji = "ğŸŒŸ"
        elif score >= 50:
            score_emoji = "âœ…"
        elif score >= 10:
            score_emoji = "ğŸŸ¡"
        else:
            score_emoji = "ğŸ”´"
        st.metric(
            "í‰ê·  ê¸°íšŒì§€ìˆ˜",
            f"{score_emoji} {score:.1f}",
            help="ê´€ë ¨ ì±„ë„ë“¤ì˜ í‰ê·  ê¸°íšŒ ì§€ìˆ˜"
        )

    with col2:
        st.metric(
            "ê²½ìŸ ê°•ë„",
            f"{result.supply_index:.1f}",
            help="ì›” í‰ê·  ì‹ ê·œ ì±„ë„ ìˆ˜"
        )

    with col3:
        st.metric(
            "ìˆ˜ìš” ì§€ìˆ˜",
            f"{result.demand_index:.1f}",
            help="í‰ê·  ì¡°íšŒìˆ˜ ê¸°ë°˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)"
        )

    with col4:
        st.metric(
            "ì‹œì¥ íŒì •",
            result.market_verdict_label or "ë¶„ì„ ì¤‘",
            help="ê¸°íšŒì§€ìˆ˜ + ê²½ìŸê°•ë„ ê¸°ë°˜ ì¢…í•© íŒì •"
        )

    # ì‹œì¥ íŒì • ìƒì„¸ ì„¤ëª…
    if result.market_verdict == "blue_ocean":
        st.success("ğŸ”µ **ë¸”ë£¨ì˜¤ì…˜**: ê¸°íšŒì§€ìˆ˜ê°€ ë†’ê³  ê²½ìŸì´ ì ìŠµë‹ˆë‹¤. ì§€ê¸ˆì´ ì§„ì… ì ê¸°!")
    elif result.market_verdict == "growing":
        st.info("ğŸŸ¢ **ì„±ì¥ì‹œì¥**: ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìœ¼ë©° ì•„ì§ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤.")
    elif result.market_verdict == "competitive":
        st.warning("ğŸŸ¡ **ê²½ìŸì‹œì¥**: ì ì ˆí•œ ì°¨ë³„í™” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.")
    elif result.market_verdict == "red_ocean":
        st.error("ğŸ”´ **ë ˆë“œì˜¤ì…˜**: ê²½ìŸì´ ì¹˜ì—´í•©ë‹ˆë‹¤. í‹ˆìƒˆ ì‹œì¥ì„ ê³µëµí•˜ì„¸ìš”.")

    # ë¼ì´ì§• ìŠ¤íƒ€ (í™©ê¸ˆ ê¸°íšŒ ì±„ë„)
    golden = result.get_golden_opportunities()
    if golden:
        st.markdown("#### ğŸŒŸ í™©ê¸ˆ ê¸°íšŒ ì±„ë„")
        st.caption("êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ ë§¤ìš° ë†’ì€ ì±„ë„ë“¤ (ê¸°íšŒì§€ìˆ˜ 100+)")

        for ch in golden[:3]:
            col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
            with col1:
                st.markdown(f"**[{ch.title}]({ch.channel_url})**")
            with col2:
                st.caption(f"êµ¬ë…ì: {ch.subscribers:,}")
            with col3:
                st.caption(f"í‰ê· ì¡°íšŒ: {ch.avg_views_per_video:,.0f}")
            with col4:
                st.markdown(f"**{ch.opportunity_label}**")
    else:
        # í™©ê¸ˆ ê¸°íšŒê°€ ì—†ìœ¼ë©´ ë¼ì´ì§• ìŠ¤íƒ€ í‘œì‹œ
        rising = result.get_rising_stars(3)
        if rising:
            st.markdown("#### ğŸ“ˆ ì£¼ëª©í•  ì±„ë„ (ë¼ì´ì§• ìŠ¤íƒ€)")
            st.caption("ê¸°íšŒ ì§€ìˆ˜ê°€ ë†’ì€ ìƒìœ„ ì±„ë„")

            for ch in rising:
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                with col1:
                    st.markdown(f"**[{ch.title}]({ch.channel_url})**")
                with col2:
                    st.caption(f"êµ¬ë…ì: {ch.subscribers:,}")
                with col3:
                    st.caption(f"í‰ê· ì¡°íšŒ: {ch.avg_views_per_video:,.0f}")
                with col4:
                    st.markdown(f"**{ch.opportunity_label}**")


def render_monthly_trend(result: TrendAnalysisResult):
    """ì›”ë³„ íŠ¸ë Œë“œ ì°¨íŠ¸"""
    st.markdown("### ğŸ“ˆ ì›”ë³„ ì‹ ê·œ ì±„ë„ ìƒì„± ì¶”ì´")

    if not result.monthly_trend:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìˆ˜ì •ëœ ì°¨íŠ¸ í•¨ìˆ˜ ì‚¬ìš© (Xì¶• ë‚ ì§œ í˜•ì‹, Yì¶• ì •ìˆ˜ í˜•ì‹)
    if TREND_CHART_AVAILABLE:
        fig = create_monthly_channel_chart(
            monthly_data=result.monthly_trend,
            title=""
        )
        st.plotly_chart(fig, use_container_width=True)

        # íŠ¸ë Œë“œ í•´ì„ ë¬¸êµ¬
        interpretation = get_trend_interpretation(result.monthly_trend)
        if interpretation:
            st.markdown(interpretation)
    else:
        # í´ë°±: ê¸°ì¡´ ì°¨íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
        sorted_months = sorted(result.monthly_trend.keys())

        # Xì¶• ë ˆì´ë¸” ë³€í™˜ (2024-10 â†’ 2024ë…„ 10ì›”)
        x_labels = []
        for month in sorted_months:
            try:
                dt = datetime.strptime(month, "%Y-%m")
                x_labels.append(dt.strftime("%Yë…„ %mì›”"))
            except ValueError:
                x_labels.append(month)

        y_values = [result.monthly_trend[m] for m in sorted_months]
        max_value = max(y_values) if y_values else 1

        # Plotly Graph Objectsë¡œ ì§ì ‘ ìƒì„±
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=x_labels,
            y=y_values,
            marker_color='#667eea',
            text=y_values,
            textposition='outside',
            textfont=dict(size=14, color='#333'),
            hovertemplate='%{x}<br>ì‹ ê·œ ì±„ë„: %{y}ê°œ<extra></extra>'
        ))

        fig.update_layout(
            xaxis=dict(
                title="",
                tickfont=dict(size=12),
                tickangle=-45 if len(x_labels) > 6 else 0,
                type='category'  # ì¹´í…Œê³ ë¦¬ë¡œ ì„¤ì • (ì‹œê°„ ì¶• ì•„ë‹˜!)
            ),
            yaxis=dict(
                title="ì±„ë„ ìˆ˜",
                tickfont=dict(size=12),
                dtick=max(1, max_value // 5) if max_value > 5 else 1,
                rangemode='tozero',
                tickformat='d',  # ì •ìˆ˜ í˜•ì‹
                range=[0, max_value * 1.2]
            ),
            height=350,
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )

        fig.update_xaxes(showgrid=False)
        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='rgba(0,0,0,0.1)')

        st.plotly_chart(fig, use_container_width=True)

        # íŠ¸ë Œë“œ ë¶„ì„ ë©”ì‹œì§€
        if len(result.monthly_trend) >= 2:
            values = list(result.monthly_trend.values())

            recent_avg = sum(values[-2:]) / 2 if len(values) >= 2 else values[-1]
            older_avg = sum(values[:-2]) / max(1, len(values) - 2) if len(values) > 2 else values[0]

            if recent_avg > older_avg * 1.5:
                st.warning("âš ï¸ ìµœê·¼ ì‹ ê·œ ì±„ë„ ìƒì„±ì´ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²½ìŸì´ ì‹¬í™”ë˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤.")
            elif recent_avg < older_avg * 0.5:
                st.success("âœ… ìµœê·¼ ì‹ ê·œ ì±„ë„ ìƒì„±ì´ ê°ì†Œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§„ì… ê¸°íšŒê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


def render_channel_list(result: TrendAnalysisResult):
    """ì‹ ê·œ ì±„ë„ ë¦¬ìŠ¤íŠ¸"""
    st.markdown("### ğŸ† ì£¼ëª©í•  ë§Œí•œ ì‹ ê·œ ì±„ë„")

    if not result.new_channels:
        st.info("ë°œê²¬ëœ ì‹ ê·œ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê´€ë ¨ ì±„ë„ê³¼ ê¸°íƒ€ ì±„ë„ ë¶„ë¦¬
    relevant_channels = [c for c in result.new_channels if c.keyword_relevant]
    other_channels = [c for c in result.new_channels if not c.keyword_relevant]

    # í•„í„° ë° ì •ë ¬ ì˜µì…˜
    col1, col2 = st.columns(2)

    with col1:
        filter_option = st.selectbox(
            "í‘œì‹œ í•„í„°",
            options=["all", "relevant", "other"],
            format_func=lambda x: {
                "all": f"ğŸ” ì „ì²´ ({len(result.new_channels)}ê°œ)",
                "relevant": f"ğŸ¯ í‚¤ì›Œë“œ ê´€ë ¨ ({len(relevant_channels)}ê°œ)",
                "other": f"ğŸ“‹ ê¸°íƒ€ ({len(other_channels)}ê°œ)"
            }.get(x)
        )

    with col2:
        sort_option = st.selectbox(
            "ì •ë ¬ ê¸°ì¤€",
            options=["opportunity", "relevance", "created_at", "subscribers", "avg_views", "efficiency"],
            format_func=lambda x: {
                "opportunity": "â­ ê¸°íšŒì§€ìˆ˜ìˆœ",
                "relevance": "ğŸ¯ ê´€ë ¨ì„±ìˆœ",
                "created_at": "ğŸ“… ìµœì‹ ìˆœ",
                "subscribers": "ğŸ‘¥ êµ¬ë…ììˆœ",
                "avg_views": "ğŸ‘ï¸ í‰ê· ì¡°íšŒìˆ˜ìˆœ",
                "efficiency": "ğŸ“ˆ ì„±ì¥íš¨ìœ¨ìˆœ"
            }.get(x)
        )

    # í•„í„°ë§
    if filter_option == "relevant":
        channels = relevant_channels.copy()
    elif filter_option == "other":
        channels = other_channels.copy()
    else:
        channels = result.new_channels.copy()

    # ì •ë ¬
    if sort_option == "opportunity":
        channels.sort(key=lambda x: x.opportunity_score, reverse=True)
    elif sort_option == "relevance":
        channels.sort(key=lambda x: (-x.relevance_score, -x.subscribers))
    elif sort_option == "subscribers":
        channels.sort(key=lambda x: x.subscribers, reverse=True)
    elif sort_option == "avg_views":
        channels.sort(key=lambda x: x.avg_views_per_video, reverse=True)
    elif sort_option == "efficiency":
        channels.sort(key=lambda x: x.subscribers_per_video, reverse=True)
    elif sort_option == "created_at":
        channels.sort(key=lambda x: x.created_at_dt, reverse=True)

    if not channels:
        st.info("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì±„ë„ ì¹´ë“œ í‘œì‹œ
    for i, channel in enumerate(channels[:20]):  # ìµœëŒ€ 20ê°œ
        with st.container():
            col1, col2, col3, col4, col5, col6 = st.columns([3, 1, 1, 1, 1, 1])

            with col1:
                # ê´€ë ¨ì„± ë°°ì§€ + ì±„ë„ëª…
                relevance_badge = ""
                if channel.keyword_relevant:
                    relevance_badge = "ğŸ¯ "
                elif channel.relevance_score > 0:
                    relevance_badge = "ğŸ”¸ "

                st.markdown(f"**{relevance_badge}[{channel.title}]({channel.channel_url})**")
                st.caption(f"ğŸ“… {channel.created_at} ìƒì„± ({channel.days_since_creation}ì¼ ì „)")

                # ê´€ë ¨ì„± ì´ìœ  í‘œì‹œ (ìˆìœ¼ë©´)
                if channel.relevance_reason and channel.relevance_reason != "ê´€ë ¨ì„± ë‚®ìŒ":
                    st.caption(f"ğŸ’¡ {channel.relevance_reason}")

            with col2:
                st.metric("êµ¬ë…ì", f"{channel.subscribers:,}")

            with col3:
                st.metric("ì˜ìƒ", f"{channel.video_count}")

            with col4:
                st.metric("í‰ê· ì¡°íšŒ", f"{channel.avg_views_per_video:,.0f}")

            with col5:
                # ê¸°íšŒ ì§€ìˆ˜ (í•µì‹¬ ì§€í‘œ!)
                opp_score = channel.opportunity_score
                if opp_score >= 100:
                    opp_display = f"ğŸŒŸ {opp_score:.0f}"
                elif opp_score >= 50:
                    opp_display = f"âœ… {opp_score:.0f}"
                elif opp_score >= 10:
                    opp_display = f"ğŸŸ¡ {opp_score:.1f}"
                else:
                    opp_display = f"ğŸ”´ {opp_score:.1f}"
                st.markdown(f"**ê¸°íšŒì§€ìˆ˜**\n{opp_display}")

            with col6:
                # ê´€ë ¨ì„± ì ìˆ˜
                score = channel.relevance_score
                if score >= 5:
                    score_display = f"ğŸŸ¢ {score}/10"
                elif score >= 3:
                    score_display = f"ğŸŸ¡ {score}/10"
                else:
                    score_display = f"âšª {score}/10"
                st.markdown(f"**ê´€ë ¨ì„±**\n{score_display}")

            st.divider()


def render_ai_insight(result: TrendAnalysisResult):
    """AI ì¸ì‚¬ì´íŠ¸"""
    st.markdown("### ğŸ¤– AI ë¶„ì„ ë¦¬í¬íŠ¸")

    if result.ai_insight:
        st.markdown(f"""
        <div class="insight-box">
            {result.ai_insight}
        </div>
        """, unsafe_allow_html=True)
    else:
        if st.button("ğŸ§  AI ì¸ì‚¬ì´íŠ¸ ìƒì„±", type="secondary"):
            with st.spinner("AIê°€ ë¶„ì„ ì¤‘..."):
                try:
                    analyzer = create_channel_trend_analyzer()

                    # Gemini í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    ai_client = None
                    try:
                        import google.generativeai as genai
                        gemini_key = os.getenv("GEMINI_API_KEY")
                        if gemini_key:
                            genai.configure(api_key=gemini_key)
                            ai_client = genai.GenerativeModel('gemini-pro')
                    except ImportError:
                        pass

                    insight = analyzer.generate_ai_insight(result, ai_client)
                    result.ai_insight = insight
                    st.session_state["trend_result"] = result

                    st.markdown(f"""
                    <div class="insight-box">
                        {insight}
                    </div>
                    """, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {e}")


def render_download(result: TrendAnalysisResult):
    """ë‹¤ìš´ë¡œë“œ ë²„íŠ¼"""
    st.markdown("### ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

    if not result.new_channels:
        return

    # DataFrame ìƒì„±
    df = pd.DataFrame([
        {
            "ì±„ë„ëª…": ch.title,
            "ì±„ë„ URL": ch.channel_url,
            "ìƒì„±ì¼": ch.created_at,
            "êµ¬ë…ì": ch.subscribers,
            "ì˜ìƒ ìˆ˜": ch.video_count,
            "ì´ ì¡°íšŒìˆ˜": ch.view_count,
            "í‰ê·  ì¡°íšŒìˆ˜": round(ch.avg_views_per_video),
            "ê¸°íšŒ ì§€ìˆ˜": round(ch.opportunity_score, 1),
            "ê¸°íšŒ ë ˆë²¨": ch.opportunity_label,
            "ì˜ìƒë‹¹ êµ¬ë…ì": round(ch.subscribers_per_video, 1),
            "ì„±ì¥ ë“±ê¸‰": ch.growth_rate,
            "ê´€ë ¨ì„± ì ìˆ˜": ch.relevance_score,
            "í‚¤ì›Œë“œ ê´€ë ¨": "O" if ch.keyword_relevant else "",
            "ê´€ë ¨ì„± ì´ìœ ": ch.relevance_reason
        }
        for ch in result.new_channels
    ])

    col1, col2 = st.columns(2)

    with col1:
        # CSV
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            "ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"channel_trend_{result.keyword}_{result.analysis_date[:10]}.csv",
            mime="text/csv",
            use_container_width=True
        )

    with col2:
        # Excel
        try:
            import io
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='ì‹ ê·œì±„ë„')

            st.download_button(
                "ğŸ“Š Excel ë‹¤ìš´ë¡œë“œ",
                data=buffer.getvalue(),
                file_name=f"channel_trend_{result.keyword}_{result.analysis_date[:10]}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        except ImportError:
            st.caption("Excel ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ openpyxl ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")


def _merge_trend_results(
    results: list,
    main_keyword: str,
    expanded_keywords: list
) -> TrendAnalysisResult:
    """
    ì—¬ëŸ¬ í‚¤ì›Œë“œì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©

    Args:
        results: TrendAnalysisResult ëª©ë¡
        main_keyword: ì›ë³¸ í‚¤ì›Œë“œ
        expanded_keywords: í™•ì¥ í‚¤ì›Œë“œ ëª©ë¡

    Returns:
        í†µí•©ëœ TrendAnalysisResult
    """
    from collections import Counter

    if not results:
        return None

    # ê¸°ë³¸ ì •ë³´ëŠ” ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜´
    first = results[0]

    # ì±„ë„ í†µí•© (ì¤‘ë³µ ì œê±°)
    all_channels = {}
    total_videos = 0
    unique_channel_ids = set()

    for r in results:
        total_videos += r.total_videos_searched
        for ch in r.new_channels:
            if ch.channel_id not in all_channels:
                all_channels[ch.channel_id] = ch
            unique_channel_ids.add(ch.channel_id)

    # ì›”ë³„ íŠ¸ë Œë“œ í†µí•©
    monthly_counter = Counter()
    for r in results:
        for month, count in r.monthly_trend.items():
            # ì¤‘ë³µ ì±„ë„ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€ê°’ ì‚¬ìš©
            monthly_counter[month] = max(monthly_counter.get(month, 0), count)

    # í†µí•© ê²°ê³¼ ìƒì„±
    merged = TrendAnalysisResult(
        keyword=main_keyword,
        region=first.region,
        period_months=first.period_months,
        analysis_date=first.analysis_date,
        total_videos_searched=total_videos,
        unique_channels_found=len(unique_channel_ids),
        new_channels_count=len(all_channels),
        new_channels=list(all_channels.values()),
        monthly_trend=dict(sorted(monthly_counter.items()))
    )

    # ìš”ì•½ í†µê³„ ë° ì‹œì¥ ê¸°íšŒ ì§€í‘œ ê³„ì‚°
    merged.calculate_summary()

    return merged


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì±„ë„ ê²€ìƒ‰ íƒ­
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render_channel_search_tab():
    """ì±„ë„ ê²€ìƒ‰ íƒ­ ë Œë”ë§"""
    st.markdown("### ğŸ“º ì±„ë„ ê²€ìƒ‰")
    st.caption("YouTube ì±„ë„ì„ URL, @handle, ì±„ë„ ID, ë˜ëŠ” ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

    if not CHANNEL_SEARCHER_AVAILABLE:
        st.error("âŒ ì±„ë„ ê²€ìƒ‰ ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    api_key = get_api_key()
    if not api_key:
        st.warning("âš ï¸ YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìƒë‹¨ì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # ê²€ìƒ‰ ì…ë ¥
    col1, col2 = st.columns([4, 1])

    with col1:
        search_query = st.text_input(
            "ì±„ë„ ê²€ìƒ‰",
            placeholder="ì˜ˆ: https://youtube.com/@ì±„ë„ëª…, UCì±„ë„ID, ì±„ë„ì´ë¦„",
            help="URL, @handle, ì±„ë„ ID(UCë¡œ ì‹œì‘), ë˜ëŠ” ì±„ë„ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
        )

    with col2:
        search_type = st.selectbox(
            "ê²€ìƒ‰ íƒ€ì…",
            options=["auto", "url", "id", "name"],
            format_func=lambda x: {
                "auto": "ğŸ”„ ìë™ ê°ì§€",
                "url": "ğŸ”— URL",
                "id": "ğŸ†” ì±„ë„ ID",
                "name": "ğŸ“ ì±„ë„ëª…"
            }.get(x, x)
        )

    # ê²€ìƒ‰ ì‹¤í–‰
    if st.button("ğŸ” ì±„ë„ ê²€ìƒ‰", type="primary", disabled=not search_query):
        with st.spinner("ì±„ë„ ê²€ìƒ‰ ì¤‘..."):
            try:
                searcher = get_channel_searcher(api_key)
                result = searcher.search_channel(search_query, search_type)

                if result:
                    st.session_state["channel_search_result"] = result
                    st.success(f"âœ… ì±„ë„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {result['channel_name']}")
                else:
                    st.warning("ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if "channel_search_result" in st.session_state:
        result = st.session_state["channel_search_result"]
        render_channel_info_card(result)

        # ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´ì— ì¶”ê°€ ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([2, 2, 2])

        with col1:
            if st.button("ğŸ“¥ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ëŒ€ê¸°ì—´ì— ì¶”ê°€", use_container_width=True):
                add_to_transcript_queue(result)

        with col2:
            max_videos = st.number_input(
                "ì˜ìƒ ìˆ˜ ì œí•œ",
                min_value=10,
                max_value=500,
                value=50,
                step=10,
                help="ê°€ì ¸ì˜¬ ìµœëŒ€ ì˜ìƒ ìˆ˜"
            )

        with col3:
            if st.button("ğŸ“‹ ì˜ìƒ ëª©ë¡ ë³´ê¸°", use_container_width=True):
                with st.spinner(f"ì˜ìƒ ëª©ë¡ ë¡œë”© ì¤‘... (ìµœëŒ€ {max_videos}ê°œ)"):
                    try:
                        searcher = get_channel_searcher(api_key)
                        videos = searcher.get_channel_videos(
                            result["channel_id"],
                            max_results=max_videos
                        )
                        st.session_state["channel_videos"] = videos
                        st.success(f"âœ… {len(videos)}ê°œ ì˜ìƒì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ì˜ìƒ ëª©ë¡ ë¡œë”© ì˜¤ë¥˜: {e}")

        # ì˜ìƒ ëª©ë¡ í‘œì‹œ
        if "channel_videos" in st.session_state:
            videos = st.session_state["channel_videos"]
            render_video_list(videos)


def render_channel_info_card(channel: dict):
    """ì±„ë„ ì •ë³´ ì¹´ë“œ ë Œë”ë§"""
    st.markdown(f"""
    <div class="search-result-card">
        <h3>ğŸ“º {channel.get('channel_name', 'Unknown')}</h3>
        <p><a href="{channel.get('channel_url', '#')}" target="_blank">{channel.get('custom_url', channel.get('channel_url', ''))}</a></p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        subs = channel.get('subscriber_count', 0)
        if isinstance(subs, str):
            st.metric("ğŸ‘¥ êµ¬ë…ì", subs)
        else:
            st.metric("ğŸ‘¥ êµ¬ë…ì", f"{subs:,}")

    with col2:
        st.metric("ğŸ¬ ì˜ìƒ ìˆ˜", f"{channel.get('video_count', 0):,}")

    with col3:
        st.metric("ğŸ‘ï¸ ì´ ì¡°íšŒìˆ˜", f"{channel.get('view_count', 0):,}")

    with col4:
        created = channel.get('created_at', '')[:10] if channel.get('created_at') else 'N/A'
        st.metric("ğŸ“… ìƒì„±ì¼", created)

    # ì„¤ëª…
    if channel.get('description'):
        with st.expander("ğŸ“ ì±„ë„ ì„¤ëª…"):
            st.write(channel['description'][:500] + "..." if len(channel.get('description', '')) > 500 else channel['description'])


def render_video_list(videos: list):
    """ì˜ìƒ ëª©ë¡ ë Œë”ë§"""
    st.markdown("#### ğŸ“‹ ì˜ìƒ ëª©ë¡")

    if not videos:
        st.info("ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df = pd.DataFrame([
        {
            "ì œëª©": v.get("title", "")[:50] + "..." if len(v.get("title", "")) > 50 else v.get("title", ""),
            "ê²Œì‹œì¼": v.get("published_at", "")[:10],
            "ì˜ìƒ ID": v.get("video_id", "")
        }
        for v in videos[:50]  # ìµœëŒ€ 50ê°œë§Œ í‘œì‹œ
    ])

    st.dataframe(df, use_container_width=True, height=300)

    st.caption(f"ì´ {len(videos)}ê°œ ì˜ìƒ ì¤‘ ìƒìœ„ 50ê°œ í‘œì‹œ")


def add_to_transcript_queue(channel: dict):
    """ì±„ë„ì„ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´ì— ì¶”ê°€"""
    if "transcript_queue" not in st.session_state:
        st.session_state["transcript_queue"] = []

    # ì¤‘ë³µ í™•ì¸
    existing_ids = [c["channel_id"] for c in st.session_state["transcript_queue"]]
    if channel["channel_id"] in existing_ids:
        st.warning("ì´ë¯¸ ëŒ€ê¸°ì—´ì— ìˆëŠ” ì±„ë„ì…ë‹ˆë‹¤.")
        return

    st.session_state["transcript_queue"].append({
        "channel_id": channel["channel_id"],
        "channel_name": channel["channel_name"],
        "video_count": channel.get("video_count", 0),
        "added_at": datetime.now().isoformat()
    })

    st.success(f"âœ… '{channel['channel_name']}' ì±„ë„ì´ ëŒ€ê¸°ì—´ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ íƒ­
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render_transcript_tab():
    """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ íƒ­ ë Œë”ë§"""
    st.markdown("### ğŸ“¥ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ")
    st.caption("ì±„ë„ì˜ ëª¨ë“  ì˜ìƒì—ì„œ ìë§‰ì„ ì¼ê´„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

    if not TRANSCRIPT_DOWNLOADER_AVAILABLE:
        st.error("âŒ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë” ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.code("pip install youtube-transcript-api")
        return

    api_key = get_api_key()
    if not api_key:
        st.warning("âš ï¸ YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìƒë‹¨ì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # ëŒ€ê¸°ì—´ í‘œì‹œ
    render_transcript_queue()

    queue = st.session_state.get("transcript_queue", [])
    if not queue:
        return

    st.markdown("---")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ë‹¤ìš´ë¡œë“œ ì„¤ì •
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("#### âš™ï¸ ë‹¤ìš´ë¡œë“œ ì„¤ì •")

    col1, col2, col3 = st.columns(3)

    with col1:
        # â­ ì–¸ì–´ ì„¤ì • ê°œì„  - autoë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
        language = st.selectbox(
            "ìë§‰ ì–¸ì–´",
            options=["auto", "en", "ko", "ja", "zh-Hans", "es"],
            index=0,  # autoê°€ ê¸°ë³¸ê°’
            format_func=lambda x: {
                "auto": "ğŸŒ ìë™ ê°ì§€ (ê¶Œì¥)",
                "en": "ğŸ‡ºğŸ‡¸ ì˜ì–´",
                "ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´",
                "ja": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´",
                "zh-Hans": "ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ (ê°„ì²´)",
                "es": "ğŸ‡ªğŸ‡¸ ìŠ¤í˜ì¸ì–´"
            }.get(x, x),
            help="'ìë™ ê°ì§€'ë¥¼ ì„ íƒí•˜ë©´ ì˜ìƒì—ì„œ ê°€ì¥ ì í•©í•œ ìë§‰ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."
        )

        # ìë™ ê°ì§€ ì„¤ëª…
        if language == "auto":
            st.caption("ğŸ’¡ ìˆ˜ë™ ìë§‰ ìš°ì„  â†’ ìë™ìƒì„± ìë§‰ ìˆœìœ¼ë¡œ íƒìƒ‰")

    with col2:
        output_format = st.selectbox(
            "ì¶œë ¥ í˜•ì‹",
            options=["json", "txt", "srt", "csv"],
            format_func=lambda x: {
                "json": "ğŸ“„ JSON (ìƒì„¸)",
                "txt": "ğŸ“ TXT (í…ìŠ¤íŠ¸)",
                "srt": "ğŸ¬ SRT (ìë§‰ íŒŒì¼)",
                "csv": "ğŸ“Š CSV (ìŠ¤í”„ë ˆë“œì‹œíŠ¸)"
            }.get(x, x)
        )

    with col3:
        include_auto = st.checkbox(
            "ìë™ìƒì„± ìë§‰ í¬í•¨",
            value=True,
            help="ìë™ìƒì„± ìë§‰ë„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤"
        )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì„ íƒ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("#### ğŸ“¡ ë‹¤ìš´ë¡œë“œ ë°©ì‹")

    download_method = st.radio(
        "ë°©ì‹ ì„ íƒ",
        options=["auto", "api", "yt-dlp"],
        format_func=lambda x: {
            "auto": "ğŸ”„ ìë™ (API ì‹¤íŒ¨ ì‹œ yt-dlp ì „í™˜) - ê¶Œì¥",
            "api": "âš¡ API (ë¹ ë¦„, Rate Limit ì·¨ì•½)",
            "yt-dlp": "ğŸ›¡ï¸ yt-dlp (ì•ˆì •ì , ì¡°ê¸ˆ ëŠë¦¼)"
        }[x],
        index=0,
        horizontal=True,
        help="ìë™: APIë¡œ ì‹œì‘, 429 ì—ëŸ¬ 3íšŒ ë°œìƒ ì‹œ yt-dlpë¡œ ì „í™˜"
    )

    # ë°©ì‹ë³„ ì•ˆë‚´
    if download_method == "auto":
        st.info("ğŸ’¡ **ìë™ ëª¨ë“œ**: APIë¡œ ì‹œì‘í•˜ê³ , Rate Limit(429) ì—ëŸ¬ê°€ 3íšŒ ì—°ì† ë°œìƒí•˜ë©´ yt-dlpë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤.")
    elif download_method == "api":
        st.warning("âš ï¸ **API ëª¨ë“œ**: ë¹ ë¥´ì§€ë§Œ YouTube Rate Limitì— ì·¨ì•½í•©ë‹ˆë‹¤. 429 ì—ëŸ¬ ë°œìƒ ì‹œ 'ìë™' ë˜ëŠ” 'yt-dlp' ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    else:
        st.success("âœ… **yt-dlp ëª¨ë“œ**: ì•ˆì •ì ì…ë‹ˆë‹¤. Rate Limit ê±±ì • ì—†ì´ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    col1, col2 = st.columns(2)

    with col1:
        # â­ ìµœëŒ€ ì˜ìƒ ìˆ˜
        max_videos_per_channel = st.number_input(
            "ì±„ë„ë‹¹ ìµœëŒ€ ì˜ìƒ ìˆ˜",
            min_value=10,
            max_value=2000,
            value=100,  # â­ ê¸°ë³¸ê°’ ë‚®ì¶¤
            step=10,
            help="ì±„ë„ë‹¹ ë‹¤ìš´ë¡œë“œí•  ìµœëŒ€ ì˜ìƒ ìˆ˜ (ë§ìœ¼ë©´ Rate Limit ìœ„í—˜)"
        )

    with col2:
        # â­ ìš”ì²­ ê°„ê²© - ê¸°ë³¸ê°’ 2ì´ˆ, ìµœëŒ€ 5ì´ˆ
        request_delay = st.slider(
            "ìš”ì²­ ê°„ê²© (ì´ˆ)",
            min_value=1.0,  # â­ ìµœì†Œ 1ì´ˆ
            max_value=5.0,  # â­ ìµœëŒ€ 5ì´ˆ
            value=2.0,      # â­ ê¸°ë³¸ê°’ 2ì´ˆ
            step=0.5,
            help="ê° ì˜ìƒ ìë§‰ ìš”ì²­ ì‚¬ì´ì˜ ëŒ€ê¸° ì‹œê°„. 429 ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì´ ê°’ì„ ë†’ì´ì„¸ìš”."
        )

    # â­ ë°°ì¹˜ ì„¤ì • ì¶”ê°€
    col3, col4 = st.columns(2)

    with col3:
        batch_size = st.number_input(
            "ë°°ì¹˜ í¬ê¸°",
            min_value=5,
            max_value=50,
            value=10,
            step=5,
            help="Nê°œ ì˜ìƒë§ˆë‹¤ ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„ë§Œí¼ ì¶”ê°€ ëŒ€ê¸°í•©ë‹ˆë‹¤."
        )

    with col4:
        batch_delay = st.number_input(
            "ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)",
            min_value=10,
            max_value=120,
            value=30,
            step=10,
            help="ë°°ì¹˜ ì‚¬ì´ì— ëŒ€ê¸°í•˜ëŠ” ì‹œê°„ (Rate Limit ë°©ì§€)"
        )

    st.markdown("---")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì˜ìƒ ì„ íƒ ëª¨ë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("#### ğŸ“º ì˜ìƒ ì„ íƒ")

    selection_mode = st.radio(
        "ì„ íƒ ëª¨ë“œ",
        options=["all", "manual"],
        format_func=lambda x: {
            "all": "ğŸ“‹ ì „ì²´ ë‹¤ìš´ë¡œë“œ (ì„¤ì •ëœ ìµœëŒ€ ì˜ìƒ ìˆ˜ê¹Œì§€)",
            "manual": "â˜‘ï¸ ìˆ˜ë™ ì„ íƒ (ì˜ìƒ ëª©ë¡ì—ì„œ ì„ íƒ)"
        }[x],
        horizontal=True,
        key="transcript_selection_mode"
    )

    selected_videos_by_channel = {}

    if selection_mode == "manual":
        # ì±„ë„ë³„ ì˜ìƒ ì„ íƒ UI
        for channel in queue:
            channel_id = channel["channel_id"]
            channel_name = channel["channel_name"]

            with st.expander(f"ğŸ“º {channel_name}", expanded=True):
                selected = render_video_selection_section(
                    channel=channel,
                    max_videos=max_videos_per_channel,
                    api_key=api_key
                )
                selected_videos_by_channel[channel_id] = selected
    else:
        # ì „ì²´ ë‹¤ìš´ë¡œë“œ ëª¨ë“œ - Noneì€ ì „ì²´ë¥¼ ì˜ë¯¸
        for channel in queue:
            selected_videos_by_channel[channel["channel_id"]] = None

    st.markdown("---")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("#### ğŸš€ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰")

    # ì˜ˆìƒ ì˜ìƒ ìˆ˜ ê³„ì‚°
    total_estimated = 0
    for channel in queue:
        cid = channel["channel_id"]
        if selection_mode == "manual" and selected_videos_by_channel.get(cid):
            total_estimated += len(selected_videos_by_channel[cid])
        else:
            channel_videos = min(channel.get("video_count", 0), max_videos_per_channel)
            total_estimated += channel_videos

    # â­ ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ë°°ì¹˜ ëŒ€ê¸° í¬í•¨)
    request_time = total_estimated * request_delay
    batch_count = max(0, (total_estimated - 1) // batch_size)
    batch_wait_time = batch_count * batch_delay
    total_time = request_time + batch_wait_time

    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“Š ì˜ˆìƒ ë‹¤ìš´ë¡œë“œ", f"{total_estimated:,}ê°œ ì˜ìƒ")
    col2.metric("â±ï¸ ìš”ì²­ ì‹œê°„", f"ì•½ {request_time/60:.1f}ë¶„")
    col3.metric("â±ï¸ ì´ ì˜ˆìƒ ì‹œê°„", f"ì•½ {total_time/60:.1f}ë¶„")

    st.caption(f"ğŸ’¡ ë°°ì¹˜ ëŒ€ê¸°: {batch_count}íšŒ Ã— {batch_delay}ì´ˆ = {batch_wait_time/60:.1f}ë¶„")

    # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ë²„íŠ¼
    if st.button("ğŸ“¥ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True, disabled=total_estimated == 0):
        run_transcript_download_v2(
            queue=queue,
            language=language,
            output_format=output_format,
            include_auto=include_auto,
            max_videos=max_videos_per_channel,
            delay=request_delay,
            batch_size=batch_size,
            batch_delay=batch_delay,
            download_method=download_method,  # â­ ë°©ì‹ ì¶”ê°€
            api_key=api_key,
            selection_mode=selection_mode,
            selected_videos_by_channel=selected_videos_by_channel
        )


def render_video_selection_section(channel: dict, max_videos: int, api_key: str) -> list:
    """ì˜ìƒ ì„ íƒ UI ì„¹ì…˜"""
    channel_id = channel["channel_id"]
    channel_name = channel["channel_name"]

    # ì˜ìƒ ëª©ë¡ ë¡œë“œ (ìºì‹œ)
    cache_key = f"channel_videos_{channel_id}"

    if cache_key not in st.session_state:
        with st.spinner(f"'{channel_name}' ì˜ìƒ ëª©ë¡ ë¡œë”© ì¤‘..."):
            try:
                searcher = get_channel_searcher(api_key)
                videos = searcher.get_channel_videos(channel_id, max_results=max_videos)

                # ì˜ìƒ ìƒì„¸ ì •ë³´ ì¶”ê°€ (ì¡°íšŒìˆ˜)
                if videos:
                    video_ids = [v["video_id"] for v in videos[:100]]  # ì²˜ìŒ 100ê°œë§Œ
                    details = searcher.get_video_details(video_ids)
                    details_map = {d["video_id"]: d for d in details}
                    for v in videos:
                        if v["video_id"] in details_map:
                            v.update(details_map[v["video_id"]])

                st.session_state[cache_key] = videos
            except Exception as e:
                st.error(f"ì˜ìƒ ëª©ë¡ ë¡œë”© ì‹¤íŒ¨: {e}")
                return []

    videos = st.session_state.get(cache_key, [])

    if not videos:
        st.warning("ì˜ìƒ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    st.info(f"ğŸ“º ì´ {len(videos)}ê°œ ì˜ìƒ")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # í•„í„° ì˜µì…˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ” í•„í„° ì˜µì…˜", expanded=False):
        col1, col2, col3 = st.columns(3)

        with col1:
            sort_by = st.selectbox(
                "ì •ë ¬",
                options=["latest", "oldest", "popular"],
                format_func=lambda x: {
                    "latest": "ğŸ“… ìµœì‹ ìˆœ",
                    "oldest": "ğŸ“… ì˜¤ë˜ëœìˆœ",
                    "popular": "ğŸ”¥ ì¡°íšŒìˆ˜ìˆœ"
                }[x],
                key=f"sort_{channel_id}"
            )

        with col2:
            filter_keyword = st.text_input(
                "ì œëª© í•„í„°",
                placeholder="í‚¤ì›Œë“œë¡œ í•„í„°ë§",
                key=f"filter_{channel_id}"
            )

        with col3:
            date_range = st.selectbox(
                "ê¸°ê°„",
                options=["all", "1month", "3months", "6months", "1year"],
                format_func=lambda x: {
                    "all": "ì „ì²´ ê¸°ê°„",
                    "1month": "ìµœê·¼ 1ê°œì›”",
                    "3months": "ìµœê·¼ 3ê°œì›”",
                    "6months": "ìµœê·¼ 6ê°œì›”",
                    "1year": "ìµœê·¼ 1ë…„"
                }[x],
                key=f"date_{channel_id}"
            )

    # í•„í„° ì ìš©
    filtered_videos = apply_video_filters(videos, sort_by, filter_keyword, date_range)

    st.write(f"ğŸ“‹ í•„í„° ì ìš© í›„: {len(filtered_videos)}ê°œ")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        if st.button("âœ… ì „ì²´ ì„ íƒ", key=f"select_all_{channel_id}"):
            for i in range(len(filtered_videos)):
                st.session_state[f"video_sel_{channel_id}_{i}"] = True
            st.rerun()

    with col2:
        if st.button("â ì „ì²´ í•´ì œ", key=f"deselect_all_{channel_id}"):
            for i in range(len(filtered_videos)):
                st.session_state[f"video_sel_{channel_id}_{i}"] = False
            st.rerun()

    # ì„ íƒëœ ì˜ìƒ ìˆ˜ ê³„ì‚°
    selected_count = sum(
        1 for i in range(len(filtered_videos))
        if st.session_state.get(f"video_sel_{channel_id}_{i}", True)
    )

    with col3:
        st.markdown(f"**ì„ íƒë¨: {selected_count}ê°œ** / {len(filtered_videos)}ê°œ")

    st.divider()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì˜ìƒ ëª©ë¡ (í˜ì´ì§€ë„¤ì´ì…˜)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    videos_per_page = 50
    total_pages = max(1, (len(filtered_videos) - 1) // videos_per_page + 1)

    if total_pages > 1:
        current_page = st.selectbox(
            "í˜ì´ì§€",
            options=list(range(1, total_pages + 1)),
            format_func=lambda x: f"í˜ì´ì§€ {x}/{total_pages}",
            key=f"page_{channel_id}"
        )
    else:
        current_page = 1

    start_idx = (current_page - 1) * videos_per_page
    end_idx = min(start_idx + videos_per_page, len(filtered_videos))
    page_videos = filtered_videos[start_idx:end_idx]

    # ì˜ìƒ ëª©ë¡ í…Œì´ë¸”
    for i, video in enumerate(page_videos):
        idx = start_idx + i
        cols = st.columns([0.5, 4, 1.5, 1.5])

        with cols[0]:
            is_selected = st.checkbox(
                label="ì„ íƒ",
                value=st.session_state.get(f"video_sel_{channel_id}_{idx}", True),
                key=f"video_sel_{channel_id}_{idx}",
                label_visibility="collapsed"
            )

        with cols[1]:
            title = video.get("title", "ì œëª© ì—†ìŒ")
            display_title = title[:55] + "..." if len(title) > 55 else title
            if is_selected:
                st.markdown(f"**{display_title}**")
            else:
                st.caption(display_title)

        with cols[2]:
            published = video.get("published_at", "")[:10]
            st.caption(published)

        with cols[3]:
            views = video.get("view_count", 0)
            if views >= 1000000:
                st.caption(f"{views/1000000:.1f}M")
            elif views >= 1000:
                st.caption(f"{views/1000:.1f}K")
            elif views > 0:
                st.caption(str(views))
            else:
                st.caption("-")

    # ì„ íƒëœ ì˜ìƒ ëª©ë¡ ë°˜í™˜
    selected_videos = [
        filtered_videos[i] for i in range(len(filtered_videos))
        if st.session_state.get(f"video_sel_{channel_id}_{i}", True)
    ]

    return selected_videos


def apply_video_filters(videos: list, sort_by: str, keyword: str, date_range: str) -> list:
    """ì˜ìƒ í•„í„° ì ìš©"""
    from datetime import timedelta

    filtered = videos.copy()

    # í‚¤ì›Œë“œ í•„í„°
    if keyword:
        keyword_lower = keyword.lower()
        filtered = [v for v in filtered if keyword_lower in v.get("title", "").lower()]

    # ê¸°ê°„ í•„í„°
    if date_range != "all":
        days_map = {"1month": 30, "3months": 90, "6months": 180, "1year": 365}
        days = days_map.get(date_range, 0)

        if days > 0:
            cutoff = datetime.now() - timedelta(days=days)
            cutoff_str = cutoff.isoformat()
            filtered = [v for v in filtered if v.get("published_at", "") >= cutoff_str]

    # ì •ë ¬
    if sort_by == "latest":
        filtered.sort(key=lambda x: x.get("published_at", ""), reverse=True)
    elif sort_by == "oldest":
        filtered.sort(key=lambda x: x.get("published_at", ""))
    elif sort_by == "popular":
        filtered.sort(key=lambda x: x.get("view_count", 0), reverse=True)

    return filtered


def render_transcript_queue():
    """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´ í‘œì‹œ"""
    st.markdown("#### ğŸ“‹ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´")

    queue = st.session_state.get("transcript_queue", [])

    if not queue:
        st.info("ëŒ€ê¸°ì—´ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. 'ì±„ë„ ê²€ìƒ‰' íƒ­ì—ì„œ ì±„ë„ì„ ì¶”ê°€í•˜ì„¸ìš”.")
        return

    for i, item in enumerate(queue):
        col1, col2, col3 = st.columns([3, 1, 1])

        with col1:
            st.markdown(f"**{i+1}. {item['channel_name']}**")
            st.caption(f"ì˜ìƒ ìˆ˜: {item.get('video_count', 'N/A')}")

        with col2:
            st.caption(f"ì¶”ê°€: {item['added_at'][:10]}")

        with col3:
            if st.button("âŒ", key=f"remove_queue_{i}", help="ëŒ€ê¸°ì—´ì—ì„œ ì œê±°"):
                st.session_state["transcript_queue"].pop(i)
                st.rerun()

    # ì „ì²´ ì‚­ì œ
    if st.button("ğŸ—‘ï¸ ëŒ€ê¸°ì—´ ë¹„ìš°ê¸°", type="secondary"):
        st.session_state["transcript_queue"] = []
        st.rerun()


def run_transcript_download(
    queue: list,
    language: str,
    output_format: str,
    include_auto: bool,
    max_videos: int,
    delay: float,
    api_key: str
):
    """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
    st.markdown("---")
    st.markdown("### ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì§„í–‰ ì¤‘...")

    total_channels = len(queue)
    overall_progress = st.progress(0)
    overall_status = st.empty()

    # ì±„ë„ ê²€ìƒ‰ê¸°
    searcher = get_channel_searcher(api_key)

    # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë”
    downloader = get_transcript_downloader("data/transcripts")

    all_results = []
    total_stats = {
        "channels": 0,
        "videos_processed": 0,
        "success": 0,
        "no_captions": 0,
        "failed": 0,
        "total_words": 0
    }

    for ch_idx, channel_info in enumerate(queue):
        channel_name = channel_info["channel_name"]
        channel_id = channel_info["channel_id"]

        overall_status.markdown(f"**[{ch_idx+1}/{total_channels}]** ì±„ë„: {channel_name}")

        # ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        st.caption(f"ğŸ“‹ '{channel_name}' ì˜ìƒ ëª©ë¡ ë¡œë”© ì¤‘...")
        try:
            videos = searcher.get_channel_videos(channel_id, max_results=max_videos)
        except Exception as e:
            st.error(f"ì˜ìƒ ëª©ë¡ ë¡œë”© ì‹¤íŒ¨: {e}")
            continue

        if not videos:
            st.warning(f"'{channel_name}' ì±„ë„ì— ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            continue

        st.caption(f"ğŸ¬ {len(videos)}ê°œ ì˜ìƒ ë°œê²¬")

        # ì§„í–‰ë¥  í‘œì‹œ
        channel_progress = st.progress(0)
        channel_status = st.empty()

        def progress_callback(progress: DownloadProgress):
            pct = progress.completed / progress.total if progress.total > 0 else 0
            channel_progress.progress(pct)
            channel_status.caption(
                f"ğŸ“¥ {progress.completed}/{progress.total} | "
                f"âœ… {progress.success} | âŒ {progress.no_captions} | "
                f"í˜„ì¬: {progress.current_video[:30]}..."
            )

        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        results, stats = downloader.download_batch(
            videos=videos,
            language=language,
            include_auto_generated=include_auto,
            delay=delay,
            progress_callback=progress_callback
        )

        # ê²°ê³¼ ì €ì¥
        if results:
            saved_path = downloader.save_results(
                results=results,
                channel_name=channel_name,
                output_format=output_format
            )
            st.success(f"âœ… '{channel_name}' ì €ì¥ ì™„ë£Œ: {saved_path}")

        # í†µê³„ ì—…ë°ì´íŠ¸
        total_stats["channels"] += 1
        total_stats["videos_processed"] += stats.get("total", 0)
        total_stats["success"] += stats.get("success", 0)
        total_stats["no_captions"] += stats.get("no_captions", 0)
        total_stats["failed"] += stats.get("failed", 0)
        total_stats["total_words"] += stats.get("total_words", 0)

        all_results.extend(results)

        # ì „ì²´ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        overall_progress.progress((ch_idx + 1) / total_channels)

    # ì™„ë£Œ ë©”ì‹œì§€
    st.markdown("---")
    st.markdown(f"""
    <div class="download-complete">
        <h3>âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!</h3>
        <p>
            ğŸ“º ì²˜ë¦¬ëœ ì±„ë„: {total_stats['channels']}ê°œ<br>
            ğŸ¬ ì²˜ë¦¬ëœ ì˜ìƒ: {total_stats['videos_processed']}ê°œ<br>
            âœ… ì„±ê³µ: {total_stats['success']}ê°œ<br>
            âŒ ìë§‰ ì—†ìŒ: {total_stats['no_captions']}ê°œ<br>
            âš ï¸ ì‹¤íŒ¨: {total_stats['failed']}ê°œ<br>
            ğŸ“ ì´ ë‹¨ì–´ ìˆ˜: {total_stats['total_words']:,}ê°œ
        </p>
    </div>
    """, unsafe_allow_html=True)

    # ëŒ€ê¸°ì—´ ë¹„ìš°ê¸°
    st.session_state["transcript_queue"] = []


def run_transcript_download_v2(
    queue: list,
    language: str,
    output_format: str,
    include_auto: bool,
    max_videos: int,
    delay: float,
    batch_size: int,
    batch_delay: float,
    download_method: str,  # â­ ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì¶”ê°€
    api_key: str,
    selection_mode: str,
    selected_videos_by_channel: dict
):
    """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ë²„ì „)"""
    st.markdown("---")
    st.markdown("### ğŸ“Š ë‹¤ìš´ë¡œë“œ ì§„í–‰ ì¤‘...")

    # í”„ë¡œê·¸ë ˆìŠ¤ UI
    overall_progress = st.progress(0)

    status_cols = st.columns(4)
    total_metric = status_cols[0].empty()
    success_metric = status_cols[1].empty()
    no_caption_metric = status_cols[2].empty()
    failed_metric = status_cols[3].empty()

    current_status = st.empty()
    log_expander = st.expander("ğŸ“‹ ìƒì„¸ ë¡œê·¸", expanded=False)
    log_area = log_expander.empty()

    logs = []
    output_files = []

    searcher = get_channel_searcher(api_key)
    downloader = get_transcript_downloader("data/transcripts")

    # â­ ë‹¤ìš´ë¡œë“œ ë°©ì‹ ë³€í™˜
    method_map = {
        "auto": DownloadMethod.AUTO,
        "api": DownloadMethod.API,
        "yt-dlp": DownloadMethod.YTDLP
    }
    method = method_map.get(download_method, DownloadMethod.AUTO)

    # ë°©ì‹ í‘œì‹œ
    method_name = {"auto": "ìë™", "api": "API", "yt-dlp": "yt-dlp"}.get(download_method, download_method)
    logs.append(f"[ì„¤ì •] ë‹¤ìš´ë¡œë“œ ë°©ì‹: {method_name}")

    total_videos_to_download = 0
    videos_downloaded = 0
    total_success = 0
    total_no_caption = 0
    total_failed = 0
    method_api_count = 0
    method_ytdlp_count = 0

    # ë¨¼ì € ì´ ë‹¤ìš´ë¡œë“œ ì˜ìƒ ìˆ˜ ê³„ì‚°
    for channel in queue:
        cid = channel["channel_id"]
        if selection_mode == "manual" and selected_videos_by_channel.get(cid):
            total_videos_to_download += len(selected_videos_by_channel[cid])
        else:
            total_videos_to_download += min(channel.get("video_count", 0), max_videos)

    total_metric.metric("ğŸ“Š ì´ ì˜ìƒ", f"0/{total_videos_to_download}")
    success_metric.metric("âœ… ì„±ê³µ", 0)
    no_caption_metric.metric("âš ï¸ ìë§‰ì—†ìŒ", 0)
    failed_metric.metric("âŒ ì‹¤íŒ¨", 0)

    # ì±„ë„ë³„ ë‹¤ìš´ë¡œë“œ
    for ch_idx, channel in enumerate(queue):
        channel_name = channel["channel_name"]
        channel_id = channel["channel_id"]

        logs.append(f"[{channel_name}] ì²˜ë¦¬ ì‹œì‘...")
        log_area.code("\n".join(logs[-20:]))

        # ë‹¤ìš´ë¡œë“œí•  ì˜ìƒ ëª©ë¡ ê²°ì •
        if selection_mode == "manual" and selected_videos_by_channel.get(channel_id):
            # ìˆ˜ë™ ì„ íƒëœ ì˜ìƒ
            videos_to_download = selected_videos_by_channel[channel_id]
            logs.append(f"[{channel_name}] ì„ íƒëœ {len(videos_to_download)}ê°œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ")
        else:
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ (ìµœëŒ€ ì˜ìƒ ìˆ˜ ì œí•œ ì ìš©)
            logs.append(f"[{channel_name}] ì˜ìƒ ëª©ë¡ ì¡°íšŒ ì¤‘...")
            log_area.code("\n".join(logs[-20:]))

            # ìºì‹œëœ ì˜ìƒ ëª©ë¡ í™•ì¸
            cache_key = f"channel_videos_{channel_id}"
            if cache_key in st.session_state:
                videos_to_download = st.session_state[cache_key][:max_videos]
            else:
                videos_to_download = searcher.get_channel_videos(
                    channel_id=channel_id,
                    max_results=max_videos
                )
            logs.append(f"[{channel_name}] {len(videos_to_download)}ê°œ ì˜ìƒ ë°œê²¬")

        if not videos_to_download:
            logs.append(f"[{channel_name}] âš ï¸ ë‹¤ìš´ë¡œë“œí•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            log_area.code("\n".join(logs[-20:]))
            continue

        # ì˜ìƒë³„ ë‹¤ìš´ë¡œë“œ
        channel_results = []

        for vid_idx, video in enumerate(videos_to_download):
            video_id = video.get("video_id")
            video_title = video.get("title", video_id)

            current_status.text(f"ğŸ“º [{channel_name}] {video_title[:50]}...")

            # â­ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
            result = downloader.download_single(
                video_id=video_id,
                video_title=video_title,
                language=language,
                include_auto_generated=include_auto,
                method=method  # â­ ì„ íƒí•œ ë°©ì‹ ì „ë‹¬
            )

            channel_results.append(result)
            videos_downloaded += 1

            # í†µê³„ ì—…ë°ì´íŠ¸
            if result.success:
                total_success += 1
            elif result.error_type == "no_caption" or "ìë§‰" in result.error:
                total_no_caption += 1
            elif result.error_type == "rate_limit":
                total_failed += 1
                logs.append(f"âš ï¸ Rate Limit ê°ì§€: {video_title[:30]}...")
                log_area.code("\n".join(logs[-20:]))
            else:
                total_failed += 1

            # â­ ë°©ì‹ë³„ ì¹´ìš´íŠ¸
            if result.method_used == "api":
                method_api_count += 1
            elif result.method_used == "yt-dlp":
                method_ytdlp_count += 1

            # UI ì—…ë°ì´íŠ¸
            progress = videos_downloaded / total_videos_to_download if total_videos_to_download > 0 else 0
            overall_progress.progress(progress)

            total_metric.metric("ğŸ“Š ì´ ì˜ìƒ", f"{videos_downloaded}/{total_videos_to_download}")
            success_metric.metric("âœ… ì„±ê³µ", total_success)
            no_caption_metric.metric("âš ï¸ ìë§‰ì—†ìŒ", total_no_caption)
            failed_metric.metric("âŒ ì‹¤íŒ¨", total_failed)

            # ë¡œê·¸ (10ê°œë§ˆë‹¤)
            if (vid_idx + 1) % 10 == 0:
                logs.append(f"[{channel_name}] {vid_idx+1}/{len(videos_to_download)} ì™„ë£Œ")
                log_area.code("\n".join(logs[-20:]))

            # â­ Rate limit ëŒ€ê¸° (ë°°ì¹˜ ì²˜ë¦¬ í¬í•¨)
            if vid_idx < len(videos_to_download) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°
                time.sleep(delay)

                # ë°°ì¹˜ ëŒ€ê¸° (Nê°œë§ˆë‹¤ ì¶”ê°€ ëŒ€ê¸°)
                if (vid_idx + 1) % batch_size == 0:
                    logs.append(f"[{channel_name}] ë°°ì¹˜ ì™„ë£Œ, {batch_delay}ì´ˆ ëŒ€ê¸°...")
                    log_area.code("\n".join(logs[-20:]))
                    current_status.text(f"â³ Rate Limit ë°©ì§€ ëŒ€ê¸° ì¤‘... ({batch_delay}ì´ˆ)")
                    time.sleep(batch_delay)

        # ì±„ë„ë³„ ê²°ê³¼ ì €ì¥
        if channel_results:
            try:
                output_path = downloader.save_results(
                    results=channel_results,
                    channel_name=channel_name,
                    output_format=output_format
                )
                output_files.append(output_path)
                logs.append(f"[{channel_name}] âœ… ì €ì¥: {output_path}")
            except Exception as e:
                logs.append(f"[{channel_name}] âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

        logs.append(f"[{channel_name}] ì™„ë£Œ!")
        log_area.code("\n".join(logs[-20:]))

    # ì™„ë£Œ
    overall_progress.progress(1.0)
    current_status.empty()

    st.divider()

    # ê²°ê³¼ ìš”ì•½
    method_summary = f"API {method_api_count}ê°œ, yt-dlp {method_ytdlp_count}ê°œ" if (method_api_count + method_ytdlp_count) > 0 else "N/A"

    st.success(f"""
    ### âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!

    - ğŸ“º ì²˜ë¦¬ëœ ì±„ë„: {len(queue)}ê°œ
    - ğŸ“º ì²˜ë¦¬ëœ ì˜ìƒ: {videos_downloaded}ê°œ
    - âœ… ì„±ê³µ: {total_success}ê°œ
    - âš ï¸ ìë§‰ ì—†ìŒ: {total_no_caption}ê°œ
    - âŒ ì‹¤íŒ¨: {total_failed}ê°œ
    - ğŸ“¡ ë°©ì‹: {method_summary}
    """)

    # ë‹¤ìš´ë¡œë“œ íŒŒì¼ ëª©ë¡
    if output_files:
        st.markdown("### ğŸ“ ì €ì¥ëœ íŒŒì¼")

        for filepath in output_files:
            filename = os.path.basename(filepath)

            try:
                with open(filepath, "rb") as f:
                    file_data = f.read()

                st.download_button(
                    label=f"ğŸ“¥ {filename}",
                    data=file_data,
                    file_name=filename,
                    mime="application/octet-stream",
                    key=f"dl_{filename}"
                )
            except Exception as e:
                st.caption(f"ğŸ“„ {filename} (íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨)")

    # ëŒ€ê¸°ì—´ ë¹„ìš°ê¸°
    st.session_state["transcript_queue"] = []


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    render_header()

    # API í‚¤ í™•ì¸
    api_key = get_api_key()

    if not api_key:
        st.error("âš ï¸ YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # API í‚¤ ì…ë ¥
        with st.expander("API í‚¤ ì„¤ì •", expanded=True):
            input_key = st.text_input("YouTube API í‚¤ ì…ë ¥", type="password")
            if st.button("ì €ì¥"):
                if input_key:
                    st.session_state["youtube_api_key"] = input_key
                    st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
        return

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # íƒ­ êµ¬ì¡°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    tab1, tab2, tab3 = st.tabs([
        "ğŸ” í‚¤ì›Œë“œ ë¶„ì„",
        "ğŸ“º ì±„ë„ ê²€ìƒ‰",
        "ğŸ“¥ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸"
    ])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Tab 1: í‚¤ì›Œë“œ ë¶„ì„ (ê¸°ì¡´ ê¸°ëŠ¥)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab1:
        render_keyword_analysis_tab()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Tab 2: ì±„ë„ ê²€ìƒ‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab2:
        render_channel_search_tab()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Tab 3: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab3:
        render_transcript_tab()


def render_keyword_analysis_tab():
    """í‚¤ì›Œë“œ ë¶„ì„ íƒ­ (ê¸°ì¡´ ê¸°ëŠ¥)"""
    api_key = get_api_key()

    # ê²€ìƒ‰ í¼
    keyword, region, months, max_videos, use_cache, expanded_keywords = render_search_form()

    st.markdown("---")

    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True, disabled=not keyword):
        if not keyword:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        # ë¶„ì„ ì‹¤í–‰
        progress_text = st.empty()
        progress_bar = st.progress(0)

        def update_progress(msg):
            progress_text.text(msg)

        try:
            analyzer = create_channel_trend_analyzer(api_key=api_key)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # í™•ì¥ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¶„ì„
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            all_keywords = [keyword]
            if expanded_keywords:
                all_keywords.extend(expanded_keywords)
                all_keywords = list(set(all_keywords))  # ì¤‘ë³µ ì œê±°

            # í™•ì¥ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê° í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ í›„ í†µí•©
            all_results = []

            if len(all_keywords) > 1:
                progress_text.text(f"ğŸ” {len(all_keywords)}ê°œ í‚¤ì›Œë“œë¡œ í™•ì¥ ë¶„ì„ ì¤‘...")

                # í‚¤ì›Œë“œë‹¹ ì˜ìƒ ìˆ˜ í• ë‹¹
                videos_per_keyword = max(20, max_videos // len(all_keywords))

                for i, kw in enumerate(all_keywords):
                    progress_bar.progress(int(20 + (i / len(all_keywords)) * 60))
                    progress_text.text(f"ë¶„ì„ ì¤‘: {kw} ({i+1}/{len(all_keywords)})")

                    try:
                        partial_result = analyzer.analyze_channel_trend(
                            keyword=kw,
                            region=region,
                            months=months,
                            max_videos=videos_per_keyword,
                            use_cache=use_cache,
                            progress_callback=None  # ê°œë³„ ì§„í–‰ ì½œë°± ë¹„í™œì„±í™”
                        )
                        all_results.append(partial_result)
                    except Exception as e:
                        print(f"[TrendAnalysis] í‚¤ì›Œë“œ '{kw}' ë¶„ì„ ì˜¤ë¥˜: {e}")
                        continue

                # ê²°ê³¼ í†µí•©
                if all_results:
                    result = _merge_trend_results(all_results, keyword, expanded_keywords)
                else:
                    result = analyzer.analyze_channel_trend(
                        keyword=keyword,
                        region=region,
                        months=months,
                        max_videos=max_videos,
                        use_cache=use_cache,
                        progress_callback=update_progress
                    )
            else:
                # ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„
                progress_bar.progress(20)
                result = analyzer.analyze_channel_trend(
                    keyword=keyword,
                    region=region,
                    months=months,
                    max_videos=max_videos,
                    use_cache=use_cache,
                    progress_callback=update_progress
                )

            progress_bar.progress(100)
            progress_text.empty()

            # ì‚¬ìš©ëœ í‚¤ì›Œë“œ ì •ë³´ ì €ì¥
            result.keywords_used = all_keywords if len(all_keywords) > 1 else [keyword]

            st.session_state["trend_result"] = result

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
                st.code(traceback.format_exc())
            return

    # ê²°ê³¼ í‘œì‹œ
    if "trend_result" in st.session_state:
        result = st.session_state["trend_result"]

        st.markdown("---")

        # ìš”ì•½ ë©”ì‹œì§€
        # ì‚¬ìš©ëœ í‚¤ì›Œë“œ ì •ë³´ í™•ì¸
        keywords_used = getattr(result, 'keywords_used', [result.keyword])

        if len(keywords_used) > 1:
            st.success(f"""
            âœ… **í™•ì¥ ë¶„ì„ ì™„ë£Œ!**
            **{len(keywords_used)}ê°œ í‚¤ì›Œë“œ**ë¡œ ìµœê·¼ {result.period_months}ê°œì›”ê°„ ì´ {result.total_videos_searched:,}ê°œì˜ ì˜ìƒì„ ë¶„ì„í•˜ì—¬
            **{result.new_channels_count}ê°œì˜ ì‹ ê·œ ì±„ë„**ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
            """)
        else:
            st.success(f"""
            âœ… **ë¶„ì„ ì™„ë£Œ!**
            ìµœê·¼ {result.period_months}ê°œì›”ê°„ ì´ {result.total_videos_searched:,}ê°œì˜ ì˜ìƒì„ ë¶„ì„í•˜ì—¬
            **{result.new_channels_count}ê°œì˜ ì‹ ê·œ ì±„ë„**ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
            """)

        # ì‚¬ìš©ëœ í‚¤ì›Œë“œ í‘œì‹œ (í™•ì¥ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°)
        if len(keywords_used) > 1:
            with st.expander(f"ğŸ” ë¶„ì„ì— ì‚¬ìš©ëœ í‚¤ì›Œë“œ ({len(keywords_used)}ê°œ)", expanded=False):
                # ì¹© í˜•íƒœë¡œ í‘œì‹œ
                keyword_html = " ".join([
                    f'<span style="background:#667eea20;color:#667eea;padding:4px 12px;border-radius:16px;margin:2px;display:inline-block;">{kw}</span>'
                    for kw in keywords_used
                ])
                st.markdown(keyword_html, unsafe_allow_html=True)

        # í‚¤ì›Œë“œ ê´€ë ¨ì„± ë¶„ì„ì— ì‚¬ìš©ëœ ë³€í˜• í‘œì‹œ
        with st.expander("ğŸ” ê´€ë ¨ì„± ë¶„ì„ì— ì‚¬ìš©ëœ í‚¤ì›Œë“œ ë³€í˜•", expanded=False):
            # ë¶„ì„ê¸°ì—ì„œ í‚¤ì›Œë“œ ë³€í˜• ê°€ì ¸ì˜¤ê¸°
            try:
                from core.youtube.channel_trend_analyzer import ChannelTrendAnalyzer
                temp_analyzer = ChannelTrendAnalyzer.__new__(ChannelTrendAnalyzer)
                variants = temp_analyzer._get_keyword_variants(result.keyword)
                st.caption(f"'{result.keyword}' ê²€ìƒ‰ ì‹œ ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì´ ê´€ë ¨ì„± íŒë‹¨ì— ì‚¬ìš©ë©ë‹ˆë‹¤:")
                st.code(", ".join(variants[:20]))  # ìƒìœ„ 20ê°œë§Œ í‘œì‹œ
                if len(variants) > 20:
                    st.caption(f"... ì™¸ {len(variants) - 20}ê°œ ë”")
            except:
                st.caption("í‚¤ì›Œë“œ ë³€í˜• ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì§€í‘œ
        render_metrics(result)

        st.markdown("---")

        # â­ ì‹œì¥ ê¸°íšŒ ë¶„ì„ (í•µì‹¬ ì„¹ì…˜!)
        render_market_opportunity(result)

        st.markdown("---")

        # ì›”ë³„ íŠ¸ë Œë“œ
        render_monthly_trend(result)

        st.markdown("---")

        # ì±„ë„ ë¦¬ìŠ¤íŠ¸
        render_channel_list(result)

        st.markdown("---")

        # AI ì¸ì‚¬ì´íŠ¸
        render_ai_insight(result)

        st.markdown("---")

        # ë‹¤ìš´ë¡œë“œ
        render_download(result)


if __name__ == "__main__":
    main()
