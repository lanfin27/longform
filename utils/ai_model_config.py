# -*- coding: utf-8 -*-
"""
AI ëª¨ë¸ ì„¤ì • ë° ê´€ë¦¬ ëª¨ë“ˆ v1.0

ê¸°ëŠ¥:
- AI ëª¨ë¸ ì •ë³´ ê´€ë¦¬
- ëª¨ë¸ ì„ íƒ UI ë Œë”ë§
- ì‘ì—…ë³„ ê¸°ë³¸/ê¶Œì¥ ëª¨ë¸ ì„¤ì •
"""

from typing import Dict, Optional
from dataclasses import dataclass
import streamlit as st


@dataclass
class AIModel:
    """AI ëª¨ë¸ ì •ë³´"""
    id: str
    name: str
    provider: str
    speed: str  # "fast", "medium", "slow"
    quality: str  # "standard", "high", "best"
    cost: str  # "low", "medium", "high"
    description: str
    max_tokens: int = 4096


# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
AVAILABLE_MODELS: Dict[str, AIModel] = {
    # Anthropic ëª¨ë¸
    "claude-3-5-haiku-20241022": AIModel(
        id="claude-3-5-haiku-20241022",
        name="Claude 3.5 Haiku",
        provider="anthropic",
        speed="fast",
        quality="standard",
        cost="low",
        description="âš¡ ë¹ ë¥¸ ì†ë„, ê°„ë‹¨í•œ ì‘ì—…ì— ì í•©",
        max_tokens=4096
    ),
    "claude-sonnet-4-20250514": AIModel(
        id="claude-sonnet-4-20250514",
        name="Claude Sonnet 4",
        provider="anthropic",
        speed="medium",
        quality="high",
        cost="medium",
        description="âš–ï¸ ì†ë„ì™€ í’ˆì§ˆì˜ ê· í˜•",
        max_tokens=8192
    ),
    "claude-opus-4-20250514": AIModel(
        id="claude-opus-4-20250514",
        name="Claude Opus 4",
        provider="anthropic",
        speed="slow",
        quality="best",
        cost="high",
        description="ğŸ¯ ìµœê³  í’ˆì§ˆ, ë³µì¡í•œ ì‘ì—…ì— ì í•©",
        max_tokens=8192
    ),
}

# ì‘ì—…ë³„ ê¸°ë³¸ ëª¨ë¸
DEFAULT_MODELS = {
    "scene_analysis": "claude-sonnet-4-20250514",
    "character_extraction": "claude-3-5-haiku-20241022",
    "image_prompt": "claude-sonnet-4-20250514",
    "script_generation": "claude-sonnet-4-20250514",
    "visual_prompt": "claude-3-5-haiku-20241022",
}

# ì²˜ë¦¬ ëª¨ë“œ
PROCESSING_MODES = {
    "sequential": {
        "name": "ğŸ”„ ìˆœì°¨ ì²˜ë¦¬",
        "description": "ì”¬ì„ í•˜ë‚˜ì”© ì²˜ë¦¬ (ì•ˆì •ì )",
        "speed": "slow"
    },
    "batch": {
        "name": "ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬",
        "description": "ì—¬ëŸ¬ ì”¬ì„ í•œ ë²ˆì— ì²˜ë¦¬ (ë¹ ë¦„)",
        "speed": "medium"
    },
    "parallel": {
        "name": "âš¡ ë³‘ë ¬ ì²˜ë¦¬",
        "description": "ë™ì‹œì— ì—¬ëŸ¬ ì”¬ ì²˜ë¦¬ (ê°€ì¥ ë¹ ë¦„)",
        "speed": "fast"
    }
}


def get_model_info(model_id: str) -> Optional[AIModel]:
    """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    return AVAILABLE_MODELS.get(model_id)


def get_default_model(task: str) -> str:
    """ì‘ì—…ë³„ ê¸°ë³¸ ëª¨ë¸ ë°˜í™˜"""
    return DEFAULT_MODELS.get(task, "claude-sonnet-4-20250514")


def render_model_selector(
    task: str,
    key: str = None,
    show_info: bool = True,
    compact: bool = False
) -> str:
    """
    AI ëª¨ë¸ ì„ íƒ UI ë Œë”ë§

    Args:
        task: ì‘ì—… ìœ í˜• (scene_analysis, character_extraction ë“±)
        key: Streamlit ìœ„ì ¯ í‚¤
        show_info: ëª¨ë¸ ì •ë³´ í‘œì‹œ ì—¬ë¶€
        compact: ì»´íŒ©íŠ¸ ëª¨ë“œ

    Returns:
        ì„ íƒëœ ëª¨ë¸ ID
    """

    # ì„¸ì…˜ ìƒíƒœì—ì„œ ì´ì „ ì„ íƒ ë³µì›
    session_key = f"ai_model_{task}"
    if session_key not in st.session_state:
        st.session_state[session_key] = get_default_model(task)

    # ëª¨ë¸ ì„ íƒ ì˜µì…˜
    model_options = {
        "âš¡ ë¹ ë¦„ (Haiku)": "claude-3-5-haiku-20241022",
        "âš–ï¸ ê· í˜• (Sonnet)": "claude-sonnet-4-20250514",
        "ğŸ¯ ê³ í’ˆì§ˆ (Opus)": "claude-opus-4-20250514"
    }

    # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì˜ ë ˆì´ë¸” ì°¾ê¸°
    current_label = "âš–ï¸ ê· í˜• (Sonnet)"
    for label, model_id in model_options.items():
        if model_id == st.session_state[session_key]:
            current_label = label
            break

    # UI ë Œë”ë§
    if compact:
        selected_label = st.selectbox(
            "ğŸ¤– AI ëª¨ë¸",
            options=list(model_options.keys()),
            index=list(model_options.keys()).index(current_label),
            key=key or f"model_select_{task}",
            help="ë¹ ë¥¸ ëª¨ë¸ì€ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        selected_model = model_options[selected_label]
        st.session_state[session_key] = selected_model
    else:
        col1, col2 = st.columns([2, 3])

        with col1:
            selected_label = st.selectbox(
                "ğŸ¤– AI ëª¨ë¸",
                options=list(model_options.keys()),
                index=list(model_options.keys()).index(current_label),
                key=key or f"model_select_{task}",
                help="ë¹ ë¥¸ ëª¨ë¸ì€ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )

        selected_model = model_options[selected_label]
        st.session_state[session_key] = selected_model

        # ëª¨ë¸ ì •ë³´ í‘œì‹œ
        if show_info:
            with col2:
                model_info = get_model_info(selected_model)
                if model_info:
                    st.caption(f"{model_info.description}")

    return selected_model


def render_processing_mode_selector(key: str = None) -> str:
    """
    ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ UI ë Œë”ë§

    Returns:
        ì„ íƒëœ ì²˜ë¦¬ ëª¨ë“œ ("sequential", "batch", "parallel")
    """

    session_key = "processing_mode"
    if session_key not in st.session_state:
        st.session_state[session_key] = "batch"

    mode_options = {
        "ğŸ”„ ìˆœì°¨ ì²˜ë¦¬ (ì•ˆì •)": "sequential",
        "ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)": "batch",
        "âš¡ ë³‘ë ¬ ì²˜ë¦¬ (ê°€ì¥ ë¹ ë¦„)": "parallel"
    }

    # í˜„ì¬ ì„ íƒëœ ëª¨ë“œì˜ ë ˆì´ë¸” ì°¾ê¸°
    current_label = "ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)"
    for label, mode in mode_options.items():
        if mode == st.session_state[session_key]:
            current_label = label
            break

    selected_label = st.radio(
        "ì²˜ë¦¬ ëª¨ë“œ",
        options=list(mode_options.keys()),
        index=list(mode_options.keys()).index(current_label),
        key=key or "processing_mode_select",
        horizontal=True,
        help="ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ì¥ ë¹ ë¥´ì§€ë§Œ API ì œí•œì— ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )

    selected_mode = mode_options[selected_label]
    st.session_state[session_key] = selected_mode

    return selected_mode


def render_model_badge(model_id: str):
    """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ë°°ì§€ í‘œì‹œ"""

    model_info = get_model_info(model_id)
    if model_info:
        speed_emoji = {"fast": "âš¡", "medium": "âš–ï¸", "slow": "ğŸ¯"}.get(model_info.speed, "")
        st.caption(f"{speed_emoji} í˜„ì¬ ëª¨ë¸: **{model_info.name}**")


def get_model_max_tokens(model_id: str) -> int:
    """ëª¨ë¸ì˜ ìµœëŒ€ í† í° ìˆ˜ ë°˜í™˜"""
    model_info = get_model_info(model_id)
    return model_info.max_tokens if model_info else 4096
