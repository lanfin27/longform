# -*- coding: utf-8 -*-
"""
AI ëª¨ë¸ ì„ íƒ UI ì»´í¬ë„ŒíŠ¸ v1.0

Streamlitìš© ë©€í‹° í”„ë¡œë°”ì´ë” ëª¨ë¸ ì„ íƒ ìœ„ì ¯

ê¸°ëŠ¥:
- í”„ë¡œë°”ì´ë” í•„í„° (Anthropic/Google/OpenAI)
- ì†ë„ í•„í„° (ë¹ ë¦„/ê· í˜•/ê³ í’ˆì§ˆ)
- í†µí•© ëª¨ë¸ ë“œë¡­ë‹¤ìš´
- API í‚¤ ìƒíƒœ í‘œì‹œ
"""

import streamlit as st
from typing import Optional
from .ai_providers import (
    AIProvider, AIModel, ALL_MODELS,
    get_available_models, get_available_providers,
    get_model, get_provider_display, PROVIDER_INFO,
    check_api_key, get_default_model
)


def render_model_selector(
    key: str = "ai_model",
    task: str = "scene_analysis",
    show_provider_filter: bool = True,
    show_speed_filter: bool = True,
    show_details: bool = True,
    compact: bool = False
) -> str:
    """
    AI ëª¨ë¸ ì„ íƒ UI ë Œë”ë§

    Args:
        key: Streamlit ìœ„ì ¯ í‚¤
        task: ì‘ì—… ìœ í˜• (ê¸°ë³¸ ëª¨ë¸ ê²°ì •ìš©)
        show_provider_filter: í”„ë¡œë°”ì´ë” í•„í„° í‘œì‹œ
        show_speed_filter: ì†ë„ í•„í„° í‘œì‹œ
        show_details: ëª¨ë¸ ìƒì„¸ ì •ë³´ í‘œì‹œ
        compact: ì»´íŒ©íŠ¸ ëª¨ë“œ

    Returns:
        ì„ íƒëœ ëª¨ë¸ ID
    """

    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ (API í‚¤ ìˆëŠ” ê²ƒë§Œ)
    available_models = get_available_models()

    if not available_models:
        st.error("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        with st.expander("ğŸ”‘ API í‚¤ ì„¤ì • ë°©ë²•"):
            st.markdown("""
            í™˜ê²½ ë³€ìˆ˜ì— ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì„¤ì •í•˜ì„¸ìš”:
            - `ANTHROPIC_API_KEY`: Claude ëª¨ë¸ ì‚¬ìš©
            - `GOOGLE_API_KEY`: Gemini ëª¨ë¸ ì‚¬ìš©
            - `OPENAI_API_KEY`: GPT ëª¨ë¸ ì‚¬ìš©
            """)
        return None

    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    default_model = get_default_model(task)
    if default_model not in available_models:
        default_model = list(available_models.keys())[0]

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if f"{key}_model" not in st.session_state:
        st.session_state[f"{key}_model"] = default_model

    # ì»´íŒ©íŠ¸ ëª¨ë“œ
    if compact:
        return _render_compact_selector(key, available_models)

    # í•„í„°ë§ëœ ëª¨ë¸
    filtered_models = available_models.copy()

    # í•„í„° UI
    if show_provider_filter or show_speed_filter:
        filter_cols = st.columns(2)

        # í”„ë¡œë°”ì´ë” í•„í„°
        if show_provider_filter:
            with filter_cols[0]:
                available_providers = get_available_providers()
                provider_options = ["ğŸŒ ì „ì²´"]
                for p in available_providers:
                    provider_options.append(get_provider_display(p))

                selected_provider = st.selectbox(
                    "í”„ë¡œë°”ì´ë”",
                    options=provider_options,
                    key=f"{key}_provider_filter",
                    help="API í‚¤ê°€ ì„¤ì •ëœ í”„ë¡œë°”ì´ë”ë§Œ í‘œì‹œë©ë‹ˆë‹¤"
                )

                if selected_provider != "ğŸŒ ì „ì²´":
                    # ì„ íƒëœ í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ë§Œ í•„í„°ë§
                    for p in AIProvider:
                        if get_provider_display(p) == selected_provider:
                            filtered_models = {
                                k: v for k, v in filtered_models.items()
                                if v.provider == p
                            }
                            break

        # ì†ë„ í•„í„°
        if show_speed_filter:
            with filter_cols[1]:
                speed_options = {
                    "ğŸŒ ì „ì²´": "all",
                    "âš¡ ë¹ ë¦„": "fast",
                    "âš–ï¸ ê· í˜•": "medium",
                    "ğŸ¯ ê³ í’ˆì§ˆ": "slow"
                }

                selected_speed = st.selectbox(
                    "ì†ë„/í’ˆì§ˆ",
                    options=list(speed_options.keys()),
                    key=f"{key}_speed_filter",
                    help="ë¹ ë¥¸ ëª¨ë¸ì€ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
                )

                speed_value = speed_options[selected_speed]
                if speed_value != "all":
                    filtered_models = {
                        k: v for k, v in filtered_models.items()
                        if v.speed == speed_value
                    }

    # í•„í„° ê²°ê³¼ í™•ì¸
    if not filtered_models:
        st.warning("ì„ íƒí•œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
        return st.session_state.get(f"{key}_model", default_model)

    # ëª¨ë¸ ì˜µì…˜ ìƒì„±
    model_options = _create_model_options(filtered_models)

    # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì´ í•„í„°ë§ëœ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
    current_model = st.session_state.get(f"{key}_model", default_model)
    if current_model not in filtered_models:
        current_model = list(filtered_models.keys())[0]

    # í˜„ì¬ ëª¨ë¸ì˜ ë ˆì´ë¸” ì°¾ê¸°
    current_label = None
    for label, model_id in model_options.items():
        if model_id == current_model:
            current_label = label
            break

    if not current_label:
        current_label = list(model_options.keys())[0]

    # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
    selected_label = st.selectbox(
        "ğŸ¤– AI ëª¨ë¸",
        options=list(model_options.keys()),
        index=list(model_options.keys()).index(current_label) if current_label in model_options else 0,
        key=f"{key}_model_select"
    )

    selected_model_id = model_options[selected_label]
    st.session_state[f"{key}_model"] = selected_model_id

    # ëª¨ë¸ ìƒì„¸ ì •ë³´ í‘œì‹œ
    if show_details:
        model_info = get_model(selected_model_id)
        if model_info:
            st.caption(f"{model_info.description}")

    return selected_model_id


def _create_model_options(models: dict) -> dict:
    """ëª¨ë¸ ë“œë¡­ë‹¤ìš´ ì˜µì…˜ ìƒì„±"""
    options = {}
    for model_id, model in models.items():
        provider_icon = PROVIDER_INFO.get(model.provider, {}).get("icon", "")
        speed_icon = {"fast": "âš¡", "medium": "âš–ï¸", "slow": "ğŸ¯"}.get(model.speed, "")
        label = f"{provider_icon} {model.name} {speed_icon}"
        options[label] = model_id
    return options


def _render_compact_selector(key: str, models: dict) -> str:
    """ì»´íŒ©íŠ¸ ëª¨ë“œ ì„ íƒê¸°"""

    options = _create_model_options(models)

    current = st.session_state.get(f"{key}_model", list(models.keys())[0])
    current_label = None
    for label, mid in options.items():
        if mid == current:
            current_label = label
            break

    if not current_label:
        current_label = list(options.keys())[0]

    selected = st.selectbox(
        "ğŸ¤– AI ëª¨ë¸",
        options=list(options.keys()),
        index=list(options.keys()).index(current_label) if current_label in options else 0,
        key=f"{key}_compact"
    )

    selected_model = options[selected]
    st.session_state[f"{key}_model"] = selected_model

    return selected_model


def render_api_key_status():
    """API í‚¤ ìƒíƒœ í‘œì‹œ"""

    st.markdown("##### ğŸ”‘ API í‚¤ ìƒíƒœ")

    cols = st.columns(3)

    providers = [
        (AIProvider.ANTHROPIC, "ANTHROPIC_API_KEY", "Claude"),
        (AIProvider.GOOGLE, "GOOGLE_API_KEY", "Gemini"),
        (AIProvider.OPENAI, "OPENAI_API_KEY", "GPT")
    ]

    for i, (provider, env_var, name) in enumerate(providers):
        with cols[i]:
            has_key = check_api_key(provider)
            icon = PROVIDER_INFO.get(provider, {}).get("icon", "")

            if has_key:
                st.success(f"{icon} {name} âœ…")
            else:
                st.error(f"{icon} {name} âŒ")
                st.caption(f"`{env_var}` í•„ìš”")


def render_model_badge(model_id: str):
    """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ë°°ì§€ í‘œì‹œ"""

    model = get_model(model_id)
    if model:
        icon = PROVIDER_INFO.get(model.provider, {}).get("icon", "")
        speed_icon = {"fast": "âš¡", "medium": "âš–ï¸", "slow": "ğŸ¯"}.get(model.speed, "")
        st.caption(f"{icon} **{model.name}** {speed_icon}")


def render_processing_mode_selector(key: str = "processing_mode") -> str:
    """
    ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ UI ë Œë”ë§

    Returns:
        ì„ íƒëœ ì²˜ë¦¬ ëª¨ë“œ ("sequential", "batch", "parallel")
    """

    if f"{key}" not in st.session_state:
        st.session_state[f"{key}"] = "batch"

    mode_options = {
        "ğŸ”„ ìˆœì°¨ ì²˜ë¦¬ (ì•ˆì •)": "sequential",
        "ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)": "batch",
        "âš¡ ë³‘ë ¬ ì²˜ë¦¬ (ê°€ì¥ ë¹ ë¦„)": "parallel"
    }

    # í˜„ì¬ ì„ íƒëœ ëª¨ë“œì˜ ë ˆì´ë¸” ì°¾ê¸°
    current_mode = st.session_state.get(f"{key}", "batch")
    current_label = "ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)"
    for label, mode in mode_options.items():
        if mode == current_mode:
            current_label = label
            break

    selected_label = st.radio(
        "ì²˜ë¦¬ ëª¨ë“œ",
        options=list(mode_options.keys()),
        index=list(mode_options.keys()).index(current_label),
        key=f"{key}_select",
        horizontal=True,
        help="ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ì¥ ë¹ ë¥´ì§€ë§Œ API ì œí•œì— ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )

    selected_mode = mode_options[selected_label]
    st.session_state[f"{key}"] = selected_mode

    return selected_mode


def get_selected_model(key: str = "ai_model") -> Optional[str]:
    """ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ëª¨ë¸ ID ë°˜í™˜"""
    return st.session_state.get(f"{key}_model")


def set_selected_model(key: str, model_id: str):
    """ì„¸ì…˜ ìƒíƒœì— ëª¨ë¸ ID ì„¤ì •"""
    st.session_state[f"{key}_model"] = model_id
