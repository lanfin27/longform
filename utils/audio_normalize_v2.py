# -*- coding: utf-8 -*-
"""
ì˜¤ë””ì˜¤ ì •ê·œí™” V2 - ì •ë°€ ì¼ê´€ì„± ë²„ì „

ëª©í‘œ:
- ë°œí™”ì†ë„ í¸ì°¨: Â±3% ì´ë‚´
- ìŒëŸ‰ í¸ì°¨: Â±2dB ì´ë‚´
"""

import os
import io
import tempfile
import subprocess
from typing import List, Dict, Tuple, Optional, Callable
import numpy as np

try:
    from pydub import AudioSegment
    from pydub.effects import normalize
    from pydub.silence import detect_leading_silence
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("[AudioNormalizer] Warning: pydub not installed")


def _check_ffmpeg():
    """FFmpeg ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        result = subprocess.run(
            ["ffmpeg", "-version"],
            capture_output=True,
            text=True
        )
        return result.returncode == 0
    except FileNotFoundError:
        return False


class AudioNormalizer:
    """
    ì™„ì „í•œ ì˜¤ë””ì˜¤ ì •ê·œí™” í´ë˜ìŠ¤

    ê¸°ëŠ¥:
    - ë°œí™”ì†ë„ ë¶„ì„ ë° ì¡°ì • (FFmpeg atempo)
    - ìŒëŸ‰ ì •ê·œí™” (RMS/LUFS)
    - ë¬´ìŒ í‘œì¤€í™”
    - í”¼í¬ ë¦¬ë¯¸íŒ…
    """

    def __init__(
        self,
        target_rate: Optional[float] = None,
        target_dbfs: float = -20.0,
        max_speed_adjust: float = 0.12,
        silence_ms: Tuple[int, int] = (80, 80)
    ):
        """
        Args:
            target_rate: ëª©í‘œ ë°œí™”ì†ë„ (ê¸€ì/ì´ˆ). Noneì´ë©´ ìë™ ê³„ì‚°
            target_dbfs: ëª©í‘œ ìŒëŸ‰ (dBFS)
            max_speed_adjust: ìµœëŒ€ ì†ë„ ì¡°ì • ë¹„ìœ¨ (0.12 = Â±12%)
            silence_ms: (ì• ë¬´ìŒ, ë’¤ ë¬´ìŒ) ë°€ë¦¬ì´ˆ
        """
        self.target_rate = target_rate
        self.target_dbfs = target_dbfs
        self.max_speed_adjust = max_speed_adjust
        self.silence_ms = silence_ms
        self.ffmpeg_available = _check_ffmpeg()

    def normalize_all(
        self,
        scenes: List[Dict],
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """
        ëª¨ë“  ì”¬ ì¼ê´„ ì •ê·œí™”

        Args:
            scenes: ì”¬ ë¦¬ìŠ¤íŠ¸ (audio_data í¬í•¨)
            progress_callback: (current, total, message) ì½œë°±

        Returns:
            ì •ê·œí™”ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
        """

        if not PYDUB_AVAILABLE:
            print("[Normalizer] pydub ë¯¸ì„¤ì¹˜ - ì •ê·œí™” ìŠ¤í‚µ")
            return scenes

        print("\n" + "=" * 60)
        print("[Normalizer] ì™„ì „ ì •ê·œí™” ì‹œì‘")
        print("=" * 60)

        # 1ë‹¨ê³„: ë¶„ì„
        print("\n[Step 1] ì”¬ ë¶„ì„")
        analysis = self._analyze_scenes(scenes)

        if not analysis:
            print("[Normalizer] ë¶„ì„í•  ì”¬ ì—†ìŒ")
            return scenes

        # 2ë‹¨ê³„: ëª©í‘œê°’ ê³„ì‚°
        print("\n[Step 2] ëª©í‘œê°’ ê³„ì‚°")
        target_rate = self._calculate_target_rate(analysis)

        # 3ë‹¨ê³„: ì •ê·œí™” ì ìš©
        print("\n[Step 3] ì •ê·œí™” ì ìš©")
        normalized = self._apply_normalization(analysis, target_rate, progress_callback)

        # 4ë‹¨ê³„: ê²°ê³¼ ê²€ì¦
        print("\n[Step 4] ê²°ê³¼ ê²€ì¦")
        self._verify_results(normalized)

        # ì›ë³¸ scenesì— ê²°ê³¼ ë°˜ì˜
        result_map = {n["scene_id"]: n for n in normalized}
        for scene in scenes:
            scene_id = scene.get("scene_id")
            if scene_id in result_map:
                norm_data = result_map[scene_id]
                scene["audio_data"] = norm_data.get("audio_data", scene.get("audio_data"))
                scene["final_duration"] = norm_data.get("final_duration")
                scene["final_rate"] = norm_data.get("final_rate")
                scene["final_dbfs"] = norm_data.get("final_dbfs")
                scene["speed_adjusted"] = norm_data.get("speed_adjusted", False)
                scene["volume_change"] = norm_data.get("volume_change", 0)
                scene["normalized"] = True

        print("\n" + "=" * 60)
        print("[Normalizer] ì •ê·œí™” ì™„ë£Œ")
        print("=" * 60)

        return scenes

    def _analyze_scenes(self, scenes: List[Dict]) -> List[Dict]:
        """ì”¬ ë¶„ì„"""

        analysis = []

        for scene in scenes:
            if not scene.get("success") or not scene.get("audio_data"):
                continue

            audio_data = scene.get("audio_data")
            if not audio_data:
                continue

            try:
                audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
                duration = len(audio) / 1000
                text = scene.get("text", "")
                char_count = len(text.replace(" ", "").replace("\n", ""))

                rate = char_count / duration if duration > 0 else 0
                dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

                analysis.append({
                    **scene,
                    "audio": audio,
                    "original_duration": duration,
                    "char_count": char_count,
                    "rate": rate,
                    "dbfs": dbfs
                })

                print(f"  ì”¬ {scene['scene_id']}: {rate:.2f} ê¸€ì/ì´ˆ, {dbfs:.1f} dBFS, {duration:.2f}ì´ˆ")

            except Exception as e:
                print(f"  ì”¬ {scene.get('scene_id', '?')}: ë¶„ì„ ì‹¤íŒ¨ - {e}")

        return analysis

    def _calculate_target_rate(self, analysis: List[Dict]) -> float:
        """ëª©í‘œ ë°œí™”ì†ë„ ê³„ì‚° (ì¤‘ê°„ê°’ ì‚¬ìš©)"""

        rates = [a["rate"] for a in analysis if a["rate"] > 0]

        if not rates:
            return 9.0  # ê¸°ë³¸ê°’

        if self.target_rate:
            target = self.target_rate
        else:
            # ì¤‘ê°„ê°’ ì‚¬ìš© (ì´ìƒì¹˜ ì˜í–¥ ìµœì†Œí™”)
            target = float(np.median(rates))

        rate_range = max(rates) - min(rates)
        rate_mean = np.mean(rates)
        current_deviation = (rate_range / 2 / rate_mean * 100) if rate_mean > 0 else 0

        print(f"  í˜„ì¬ ë²”ìœ„: {min(rates):.2f} ~ {max(rates):.2f} ê¸€ì/ì´ˆ")
        print(f"  í˜„ì¬ í¸ì°¨: Â±{current_deviation:.1f}%")
        print(f"  ëª©í‘œ ì†ë„: {target:.2f} ê¸€ì/ì´ˆ")
        print(f"  ëª©í‘œ í¸ì°¨: Â±3% ì´ë‚´")

        return target

    def _apply_normalization(
        self,
        analysis: List[Dict],
        target_rate: float,
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """ì •ê·œí™” ì ìš©"""

        results = []
        total = len(analysis)

        for idx, item in enumerate(analysis):
            scene_id = item["scene_id"]

            if progress_callback:
                progress_callback(idx, total, f"ì”¬ {scene_id} ì •ê·œí™” ì¤‘...")

            print(f"\n  [ì”¬ {scene_id}]")

            audio = item["audio"]
            current_rate = item["rate"]
            char_count = item["char_count"]

            speed_adjusted = False
            volume_change = 0.0

            # 1. ì†ë„ ì¡°ì •
            if current_rate > 0 and target_rate > 0:
                audio, speed_adjusted = self._adjust_speed(
                    audio, current_rate, target_rate
                )

            # 2. ë¬´ìŒ í‘œì¤€í™”
            audio = self._standardize_silence(audio)

            # 3. ìŒëŸ‰ ì •ê·œí™”
            audio, volume_change = self._normalize_volume(audio)

            # 4. í”¼í¬ ì œí•œ
            audio = normalize(audio, headroom=1.0)

            # ìµœì¢… ë¶„ì„
            final_duration = len(audio) / 1000
            final_rate = char_count / final_duration if final_duration > 0 else 0
            final_dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

            print(f"    â†’ {final_rate:.2f} ê¸€ì/ì´ˆ, {final_dbfs:.1f} dBFS, {final_duration:.2f}ì´ˆ")

            # ë°”ì´íŠ¸ë¡œ ë³€í™˜
            output = io.BytesIO()
            audio.export(output, format="wav")
            output.seek(0)

            results.append({
                **item,
                "audio_data": output.read(),
                "audio": None,  # ë©”ëª¨ë¦¬ í•´ì œ
                "final_duration": final_duration,
                "final_rate": final_rate,
                "final_dbfs": final_dbfs,
                "speed_adjusted": speed_adjusted,
                "volume_change": volume_change
            })

        if progress_callback:
            progress_callback(total, total, "ì •ê·œí™” ì™„ë£Œ")

        return results

    def _adjust_speed(
        self,
        audio: AudioSegment,
        current_rate: float,
        target_rate: float
    ) -> Tuple[AudioSegment, bool]:
        """ì†ë„ ì¡°ì • (FFmpeg atempo)"""

        ratio = current_rate / target_rate

        # ì¡°ì • ë²”ìœ„ ì œí•œ
        ratio = max(1 - self.max_speed_adjust, min(1 + self.max_speed_adjust, ratio))

        # 3% ë¯¸ë§Œ ì°¨ì´ëŠ” ë¬´ì‹œ
        if abs(ratio - 1.0) < 0.03:
            print(f"    ì†ë„: ì¡°ì • ë¶ˆí•„ìš” (ì°¨ì´ {abs(ratio-1)*100:.1f}%)")
            return audio, False

        print(f"    ì†ë„: {ratio:.3f}x ì¡°ì • ({current_rate:.2f} â†’ {target_rate:.2f} ê¸€ì/ì´ˆ)")

        if not self.ffmpeg_available:
            print(f"    âš ï¸ FFmpeg ë¯¸ì„¤ì¹˜ - ì†ë„ ì¡°ì • ìŠ¤í‚µ")
            return audio, False

        # FFmpegë¡œ ì†ë„ ì¡°ì • (í”¼ì¹˜ ìœ ì§€)
        try:
            temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
            temp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

            audio.export(temp_in, format="wav")

            # atempo ë²”ìœ„: 0.5 ~ 2.0
            atempo = max(0.5, min(2.0, ratio))

            cmd = [
                "ffmpeg", "-y", "-i", temp_in,
                "-af", f"atempo={atempo}",
                "-ar", "24000",
                temp_out
            ]

            subprocess.run(cmd, check=True, capture_output=True)

            result = AudioSegment.from_file(temp_out)

            # ì •ë¦¬
            for f in [temp_in, temp_out]:
                try:
                    os.remove(f)
                except:
                    pass

            return result, True

        except Exception as e:
            print(f"    âš ï¸ ì†ë„ ì¡°ì • ì‹¤íŒ¨: {e}")
            return audio, False

    def _standardize_silence(self, audio: AudioSegment) -> AudioSegment:
        """ë¬´ìŒ í‘œì¤€í™”"""

        try:
            # ì•ìª½ ë¬´ìŒ ê°ì§€ ë° ì œê±°
            start_trim = detect_leading_silence(audio, silence_threshold=-50)
            start_trim = min(start_trim, 500)  # ìµœëŒ€ 500ms

            # ë’¤ìª½ ë¬´ìŒ ê°ì§€ ë° ì œê±°
            end_trim = detect_leading_silence(audio.reverse(), silence_threshold=-50)
            end_trim = min(end_trim, 500)

            # íŠ¸ë¦¬ë° (ì•ˆì „ ì²´í¬)
            if start_trim + end_trim < len(audio) - 100:
                audio = audio[start_trim:len(audio) - end_trim]

            # í‘œì¤€ ë¬´ìŒ ì¶”ê°€
            leading = AudioSegment.silent(duration=self.silence_ms[0], frame_rate=audio.frame_rate)
            trailing = AudioSegment.silent(duration=self.silence_ms[1], frame_rate=audio.frame_rate)

            return leading + audio + trailing

        except Exception as e:
            print(f"    âš ï¸ ë¬´ìŒ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            return audio

    def _normalize_volume(self, audio: AudioSegment) -> Tuple[AudioSegment, float]:
        """ìŒëŸ‰ ì •ê·œí™”"""

        current_dbfs = audio.dBFS

        if current_dbfs == float('-inf'):
            return audio, 0.0

        change = self.target_dbfs - current_dbfs

        # ìµœëŒ€ ì¡°ì • ë²”ìœ„ ì œí•œ (Â±15dB)
        change = max(-15, min(15, change))

        if abs(change) > 0.5:
            audio = audio.apply_gain(change)
            print(f"    ìŒëŸ‰: {change:+.1f} dB ì¡°ì • ({current_dbfs:.1f} â†’ {audio.dBFS:.1f} dBFS)")

        return audio, change

    def _verify_results(self, results: List[Dict]):
        """ê²°ê³¼ ê²€ì¦"""

        rates = [r["final_rate"] for r in results if r.get("final_rate")]
        dbfs_values = [r["final_dbfs"] for r in results if r.get("final_dbfs")]

        if rates:
            rate_min, rate_max = min(rates), max(rates)
            rate_mean = np.mean(rates)
            rate_deviation = (rate_max - rate_min) / 2 / rate_mean * 100 if rate_mean > 0 else 0

            print(f"\n  ğŸ“Š ë°œí™”ì†ë„ ê²°ê³¼:")
            print(f"     ë²”ìœ„: {rate_min:.2f} ~ {rate_max:.2f} ê¸€ì/ì´ˆ")
            print(f"     í¸ì°¨: Â±{rate_deviation:.1f}%")

            if rate_deviation <= 3:
                print(f"     âœ… ëª©í‘œ ë‹¬ì„±! (Â±3% ì´ë‚´)")
            elif rate_deviation <= 5:
                print(f"     âš ï¸ ì–‘í˜¸ (Â±5% ì´ë‚´)")
            else:
                print(f"     âŒ ì¶”ê°€ ì¡°ì • í•„ìš”")

        if dbfs_values:
            dbfs_min, dbfs_max = min(dbfs_values), max(dbfs_values)
            dbfs_range = dbfs_max - dbfs_min

            print(f"\n  ğŸ“Š ìŒëŸ‰ ê²°ê³¼:")
            print(f"     ë²”ìœ„: {dbfs_min:.1f} ~ {dbfs_max:.1f} dBFS")
            print(f"     í¸ì°¨: {dbfs_range:.1f} dB")

            if dbfs_range <= 4:
                print(f"     âœ… ëª©í‘œ ë‹¬ì„±! (Â±2dB ì´ë‚´)")
            else:
                print(f"     âš ï¸ ì¶”ê°€ ì¡°ì • í•„ìš”")


# ============================================================
# í¸ì˜ í•¨ìˆ˜
# ============================================================

def normalize_scenes_v2(
    scenes: List[Dict],
    target_rate: Optional[float] = None,
    target_dbfs: float = -20.0,
    max_speed_adjust: float = 0.12,
    progress_callback: Optional[Callable] = None
) -> List[Dict]:
    """
    ì”¬ ì •ê·œí™” í¸ì˜ í•¨ìˆ˜

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸
        target_rate: ëª©í‘œ ë°œí™”ì†ë„ (Noneì´ë©´ ìë™)
        target_dbfs: ëª©í‘œ ìŒëŸ‰
        max_speed_adjust: ìµœëŒ€ ì†ë„ ì¡°ì •
        progress_callback: ì§„í–‰ ì½œë°±

    Returns:
        ì •ê·œí™”ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
    """

    normalizer = AudioNormalizer(
        target_rate=target_rate,
        target_dbfs=target_dbfs,
        max_speed_adjust=max_speed_adjust
    )

    return normalizer.normalize_all(scenes, progress_callback)


def analyze_scenes_stats(scenes: List[Dict]) -> Dict:
    """
    ì”¬ í†µê³„ ë¶„ì„

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        í†µê³„ ì •ë³´ dict
    """

    if not PYDUB_AVAILABLE:
        return {"error": "pydub not installed"}

    rates = []
    dbfs_values = []
    durations = []

    for scene in scenes:
        if not scene.get("audio_data"):
            continue

        try:
            audio = AudioSegment.from_file(
                io.BytesIO(scene["audio_data"]), format="wav"
            )
            duration = len(audio) / 1000
            text = scene.get("text", "")
            char_count = len(text.replace(" ", ""))

            rate = char_count / duration if duration > 0 else 0
            dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

            rates.append(rate)
            dbfs_values.append(dbfs)
            durations.append(duration)

        except:
            pass

    if not rates:
        return {"error": "no valid scenes"}

    return {
        "scene_count": len(rates),
        "rate_min": min(rates),
        "rate_max": max(rates),
        "rate_mean": np.mean(rates),
        "rate_std": np.std(rates),
        "rate_deviation_pct": (max(rates) - min(rates)) / 2 / np.mean(rates) * 100,
        "dbfs_min": min(dbfs_values),
        "dbfs_max": max(dbfs_values),
        "dbfs_range": max(dbfs_values) - min(dbfs_values),
        "total_duration": sum(durations)
    }
