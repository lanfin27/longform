# -*- coding: utf-8 -*-
"""
ê°•ì œ ì˜¤ë””ì˜¤ ì •ê·œí™” ëª¨ë“ˆ

í•µì‹¬ ëª©í‘œ:
- ì •ê·œí™”ê°€ ë°˜ë“œì‹œ ì‹¤í–‰ë˜ë„ë¡ ë³´ì¥
- ë°œí™”ì†ë„ í¸ì°¨: Â±5% ì´ë‚´ (8.075 ~ 8.925 ê¸€ì/ì´ˆ)
- ìŒëŸ‰ í¸ì°¨: Â±2dB ì´ë‚´
"""

import os
import io
import tempfile
import subprocess
from typing import List, Dict, Tuple, Optional, Callable
import numpy as np

try:
    from pydub import AudioSegment
    from pydub.effects import normalize as pydub_normalize
    from pydub.silence import detect_leading_silence
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("[ForcedNormalizer] âš ï¸ pydub ë¯¸ì„¤ì¹˜")


def _check_ffmpeg() -> bool:
    """FFmpeg ì„¤ì¹˜ í™•ì¸"""
    try:
        result = subprocess.run(
            ["ffmpeg", "-version"],
            capture_output=True,
            text=True,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )
        return result.returncode == 0
    except FileNotFoundError:
        return False


class ForcedAudioNormalizer:
    """
    ê°•ì œ ì˜¤ë””ì˜¤ ì •ê·œí™” í´ë˜ìŠ¤

    ê¸°ì¡´ AudioNormalizerì™€ ë‹¬ë¦¬ ì¡°ê±´ ì—†ì´ í•­ìƒ ì‹¤í–‰ë¨
    """

    def __init__(
        self,
        target_rate: float = 8.5,
        target_dbfs: float = -20.0,
        max_speed_adjust: float = 0.15,
        silence_ms: Tuple[int, int] = (80, 80)
    ):
        """
        Args:
            target_rate: ëª©í‘œ ë°œí™”ì†ë„ (ê¸€ì/ì´ˆ)
            target_dbfs: ëª©í‘œ ìŒëŸ‰ (dBFS)
            max_speed_adjust: ìµœëŒ€ ì†ë„ ì¡°ì • ë¹„ìœ¨ (0.15 = Â±15%)
            silence_ms: (ì• ë¬´ìŒ, ë’¤ ë¬´ìŒ) ë°€ë¦¬ì´ˆ
        """
        self.target_rate = target_rate
        self.target_dbfs = target_dbfs
        self.max_speed_adjust = max_speed_adjust
        self.silence_ms = silence_ms
        self.ffmpeg_available = _check_ffmpeg()

        print(f"\n{'='*60}")
        print("[ForcedNormalizer] ì´ˆê¸°í™”")
        print(f"  ëª©í‘œ ë°œí™”ì†ë„: {target_rate} ê¸€ì/ì´ˆ (Â±5% = {target_rate*0.95:.2f} ~ {target_rate*1.05:.2f})")
        print(f"  ëª©í‘œ ìŒëŸ‰: {target_dbfs} dBFS")
        print(f"  FFmpeg: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if self.ffmpeg_available else 'âŒ ë¯¸ì„¤ì¹˜'}")
        print(f"{'='*60}\n")

    def normalize_all_scenes(
        self,
        scenes: List[Dict],
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """
        ëª¨ë“  ì”¬ ê°•ì œ ì •ê·œí™”

        Args:
            scenes: ì”¬ ë¦¬ìŠ¤íŠ¸ (audio_data í•„ìˆ˜)
            progress_callback: (current, total, message) ì½œë°±

        Returns:
            ì •ê·œí™”ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
        """

        if not PYDUB_AVAILABLE:
            print("[ForcedNormalizer] âŒ pydub ë¯¸ì„¤ì¹˜ - ì •ê·œí™” ë¶ˆê°€")
            return scenes

        print("\n" + "=" * 60)
        print("[ForcedNormalizer] ğŸ”§ ê°•ì œ ì •ê·œí™” ì‹œì‘")
        print("=" * 60)

        # 1ë‹¨ê³„: ë¶„ì„
        print("\n[Step 1/4] ğŸ“Š ì”¬ ë¶„ì„")
        analysis = self._analyze_all(scenes)

        if not analysis:
            print("[ForcedNormalizer] âš ï¸ ë¶„ì„í•  ì”¬ ì—†ìŒ")
            return scenes

        self._print_analysis_summary(analysis, "ì •ê·œí™” ì „")

        # 2ë‹¨ê³„: ê°œë³„ ì •ê·œí™”
        print("\n[Step 2/4] ğŸ”„ ê°œë³„ ì”¬ ì •ê·œí™”")
        normalized = self._normalize_each(analysis, progress_callback)

        # 3ë‹¨ê³„: ê²°ê³¼ ê²€ì¦
        print("\n[Step 3/4] âœ… ê²°ê³¼ ê²€ì¦")
        self._verify_results(normalized)

        # 4ë‹¨ê³„: ì›ë³¸ì— ë°˜ì˜
        print("\n[Step 4/4] ğŸ’¾ ê²°ê³¼ ë°˜ì˜")
        result_map = {n["scene_id"]: n for n in normalized}

        for scene in scenes:
            scene_id = scene.get("scene_id")
            if scene_id in result_map:
                norm = result_map[scene_id]
                scene["audio_data"] = norm.get("audio_data", scene.get("audio_data"))
                scene["final_duration"] = norm.get("final_duration")
                scene["final_rate"] = norm.get("final_rate")
                scene["final_dbfs"] = norm.get("final_dbfs")
                scene["speed_ratio"] = norm.get("speed_ratio", 1.0)
                scene["volume_change"] = norm.get("volume_change", 0)
                scene["normalized"] = True
                scene["normalizer_version"] = "forced_v1"

        print("\n" + "=" * 60)
        print("[ForcedNormalizer] âœ… ê°•ì œ ì •ê·œí™” ì™„ë£Œ")
        print("=" * 60 + "\n")

        return scenes

    def _analyze_all(self, scenes: List[Dict]) -> List[Dict]:
        """ëª¨ë“  ì”¬ ë¶„ì„"""

        analysis = []

        for scene in scenes:
            audio_data = scene.get("audio_data")
            if not audio_data:
                continue

            try:
                audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
                duration = len(audio) / 1000

                text = scene.get("text", "")
                # ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ê¸€ì ìˆ˜ ê³„ì‚°
                char_count = len(text.replace(" ", "").replace("\n", "").replace("\t", ""))

                if duration <= 0 or char_count == 0:
                    continue

                rate = char_count / duration
                dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

                analysis.append({
                    **scene,
                    "audio": audio,
                    "original_duration": duration,
                    "char_count": char_count,
                    "original_rate": rate,
                    "original_dbfs": dbfs
                })

                print(f"  ì”¬ {scene['scene_id']:02d}: {rate:.2f} ê¸€ì/ì´ˆ, {dbfs:.1f} dBFS, {duration:.2f}ì´ˆ, {char_count}ì")

            except Exception as e:
                print(f"  ì”¬ {scene.get('scene_id', '?')}: âŒ ë¶„ì„ ì‹¤íŒ¨ - {e}")

        return analysis

    def _print_analysis_summary(self, analysis: List[Dict], label: str):
        """ë¶„ì„ ìš”ì•½ ì¶œë ¥"""

        rates = [a["original_rate"] for a in analysis]
        dbfs_values = [a["original_dbfs"] for a in analysis]

        rate_min, rate_max = min(rates), max(rates)
        rate_mean = np.mean(rates)
        rate_deviation = (rate_max - rate_min) / 2 / rate_mean * 100 if rate_mean > 0 else 0

        dbfs_min, dbfs_max = min(dbfs_values), max(dbfs_values)
        dbfs_range = dbfs_max - dbfs_min

        print(f"\n  ğŸ“Š {label} í†µê³„:")
        print(f"     ë°œí™”ì†ë„: {rate_min:.2f} ~ {rate_max:.2f} ê¸€ì/ì´ˆ (í¸ì°¨ Â±{rate_deviation:.1f}%)")
        print(f"     ìŒëŸ‰: {dbfs_min:.1f} ~ {dbfs_max:.1f} dBFS (ë²”ìœ„ {dbfs_range:.1f}dB)")

    def _normalize_each(
        self,
        analysis: List[Dict],
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """ê° ì”¬ ì •ê·œí™”"""

        results = []
        total = len(analysis)

        for idx, item in enumerate(analysis):
            scene_id = item["scene_id"]

            if progress_callback:
                progress_callback(idx, total, f"ì”¬ {scene_id} ì •ê·œí™” ì¤‘...")

            print(f"\n  [ì”¬ {scene_id:02d}] ì •ê·œí™” ì‹œì‘")

            audio = item["audio"]
            current_rate = item["original_rate"]
            char_count = item["char_count"]

            speed_ratio = 1.0
            volume_change = 0.0

            # 1. ì†ë„ ì¡°ì • (ë°œí™”ì†ë„ ì¼ê´€ì„±)
            audio, speed_ratio = self._adjust_speed_forced(
                audio, current_rate, self.target_rate
            )

            # 2. ë¬´ìŒ í‘œì¤€í™”
            audio = self._standardize_silence(audio)

            # 3. ìŒëŸ‰ ì •ê·œí™”
            audio, volume_change = self._normalize_volume(audio)

            # 4. í”¼í¬ ì œí•œ
            audio = pydub_normalize(audio, headroom=1.0)

            # ìµœì¢… ë¶„ì„
            final_duration = len(audio) / 1000
            final_rate = char_count / final_duration if final_duration > 0 else 0
            final_dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

            print(f"     â†’ {final_rate:.2f} ê¸€ì/ì´ˆ, {final_dbfs:.1f} dBFS")

            # ë°”ì´íŠ¸ ë³€í™˜
            output = io.BytesIO()
            audio.export(output, format="wav")
            output.seek(0)

            results.append({
                **item,
                "audio_data": output.read(),
                "audio": None,
                "final_duration": final_duration,
                "final_rate": final_rate,
                "final_dbfs": final_dbfs,
                "speed_ratio": speed_ratio,
                "volume_change": volume_change
            })

        if progress_callback:
            progress_callback(total, total, "ì •ê·œí™” ì™„ë£Œ")

        return results

    def _adjust_speed_forced(
        self,
        audio: AudioSegment,
        current_rate: float,
        target_rate: float
    ) -> Tuple[AudioSegment, float]:
        """ì†ë„ ê°•ì œ ì¡°ì • (FFmpeg atempo) - ë°©í–¥ ìˆ˜ì •ë¨!"""

        # â­ í•µì‹¬ ìˆ˜ì •: atempo ê³„ì‚° ë°©í–¥!
        # atempo = target / current
        # - current < target (ë„ˆë¬´ ëŠë¦¼) â†’ atempo > 1 â†’ ì˜¤ë””ì˜¤ ë¹ ë¥´ê²Œ ì¬ìƒ â†’ ë°œí™”ì†ë„ ì¦ê°€
        # - current > target (ë„ˆë¬´ ë¹ ë¦„) â†’ atempo < 1 â†’ ì˜¤ë””ì˜¤ ëŠë¦¬ê²Œ ì¬ìƒ â†’ ë°œí™”ì†ë„ ê°ì†Œ
        #
        # ì˜ˆì‹œ: current=7.47, target=8.5
        #   atempo = 8.5 / 7.47 = 1.138
        #   ì˜¤ë””ì˜¤ë¥¼ 1.138ë°° ë¹ ë¥´ê²Œ ì¬ìƒ â†’ ë°œí™”ì†ë„ 7.47 * 1.138 = 8.5 ê¸€ì/ì´ˆ
        atempo = target_rate / current_rate

        # ë²”ìœ„ ì œí•œ (0.85 ~ 1.20, ì¦‰ Â±15~20% ì¡°ì •)
        atempo = max(0.85, min(1.20, atempo))

        deviation_pct = abs(atempo - 1.0) * 100

        # 3% ë¯¸ë§Œ ì°¨ì´ëŠ” ë¬´ì‹œ (ê±°ì˜ ëª©í‘œì— ë„ë‹¬)
        if deviation_pct < 3.0:
            print(f"     ì†ë„: ì¡°ì • ë¶ˆí•„ìš” (ì°¨ì´ {deviation_pct:.1f}%)")
            return audio, 1.0

        # ë°©í–¥ í‘œì‹œ
        direction = "â¬†ï¸ ë¹ ë¥´ê²Œ" if atempo > 1.0 else "â¬‡ï¸ ëŠë¦¬ê²Œ"
        expected_rate = current_rate * atempo
        print(f"     ì†ë„: {atempo:.3f}x ({direction})")
        print(f"            {current_rate:.2f} â†’ {expected_rate:.2f} ê¸€ì/ì´ˆ (ëª©í‘œ: {target_rate:.2f})")

        if not self.ffmpeg_available:
            print(f"     âš ï¸ FFmpeg ë¯¸ì„¤ì¹˜ - ì†ë„ ì¡°ì • ìŠ¤í‚µ")
            return audio, 1.0

        try:
            # ì„ì‹œ íŒŒì¼
            temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
            temp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

            audio.export(temp_in, format="wav")

            # atempo ë²”ìœ„: 0.5 ~ 2.0 (ì´ë¯¸ 0.85~1.20ìœ¼ë¡œ ì œí•œë¨)
            atempo_value = max(0.5, min(2.0, atempo))

            cmd = [
                "ffmpeg", "-y", "-i", temp_in,
                "-af", f"atempo={atempo_value}",
                "-ar", "24000",
                "-ac", "1",
                temp_out
            ]

            # Windowsì—ì„œ ì½˜ì†” ì°½ ìˆ¨ê¹€
            creationflags = subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0

            subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                creationflags=creationflags,
                timeout=30
            )

            result = AudioSegment.from_file(temp_out, format="wav")

            # ì •ë¦¬
            for f in [temp_in, temp_out]:
                try:
                    os.remove(f)
                except:
                    pass

            return result, atempo

        except subprocess.TimeoutExpired:
            print(f"     âš ï¸ FFmpeg íƒ€ì„ì•„ì›ƒ")
            return audio, 1.0
        except Exception as e:
            print(f"     âš ï¸ ì†ë„ ì¡°ì • ì‹¤íŒ¨: {e}")
            return audio, 1.0

    def _standardize_silence(self, audio: AudioSegment) -> AudioSegment:
        """ë¬´ìŒ í‘œì¤€í™”"""

        try:
            # ì•ìª½ ë¬´ìŒ ê°ì§€
            start_trim = detect_leading_silence(audio, silence_threshold=-50)
            start_trim = min(start_trim, 500)

            # ë’¤ìª½ ë¬´ìŒ ê°ì§€
            end_trim = detect_leading_silence(audio.reverse(), silence_threshold=-50)
            end_trim = min(end_trim, 500)

            # íŠ¸ë¦¬ë°
            if start_trim + end_trim < len(audio) - 100:
                audio = audio[start_trim:len(audio) - end_trim]

            # í‘œì¤€ ë¬´ìŒ ì¶”ê°€
            leading = AudioSegment.silent(duration=self.silence_ms[0], frame_rate=audio.frame_rate)
            trailing = AudioSegment.silent(duration=self.silence_ms[1], frame_rate=audio.frame_rate)

            return leading + audio + trailing

        except Exception as e:
            print(f"     âš ï¸ ë¬´ìŒ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            return audio

    def _normalize_volume(self, audio: AudioSegment) -> Tuple[AudioSegment, float]:
        """ìŒëŸ‰ ì •ê·œí™”"""

        current_dbfs = audio.dBFS

        if current_dbfs == float('-inf'):
            return audio, 0.0

        change = self.target_dbfs - current_dbfs

        # ìµœëŒ€ Â±15dB ì œí•œ
        change = max(-15, min(15, change))

        if abs(change) > 0.5:
            audio = audio.apply_gain(change)
            print(f"     ìŒëŸ‰: {change:+.1f} dB ({current_dbfs:.1f} â†’ {audio.dBFS:.1f} dBFS)")

        return audio, change

    def _verify_results(self, results: List[Dict]):
        """ê²°ê³¼ ê²€ì¦"""

        rates = [r["final_rate"] for r in results if r.get("final_rate")]
        dbfs_values = [r["final_dbfs"] for r in results if r.get("final_dbfs")]

        if rates:
            rate_min, rate_max = min(rates), max(rates)
            rate_mean = np.mean(rates)
            rate_deviation = (rate_max - rate_min) / 2 / rate_mean * 100 if rate_mean > 0 else 0

            print(f"\n  ğŸ“Š ë°œí™”ì†ë„ ê²°ê³¼:")
            print(f"     ë²”ìœ„: {rate_min:.2f} ~ {rate_max:.2f} ê¸€ì/ì´ˆ")
            print(f"     í‰ê· : {rate_mean:.2f} ê¸€ì/ì´ˆ")
            print(f"     í¸ì°¨: Â±{rate_deviation:.1f}%")

            if rate_deviation <= 5:
                print(f"     âœ… ëª©í‘œ ë‹¬ì„±! (Â±5% ì´ë‚´)")
            elif rate_deviation <= 8:
                print(f"     âš ï¸ ì–‘í˜¸ (Â±8% ì´ë‚´)")
            else:
                print(f"     âŒ ì¶”ê°€ ì¡°ì • í•„ìš” (Â±{rate_deviation:.1f}%)")

        if dbfs_values:
            dbfs_min, dbfs_max = min(dbfs_values), max(dbfs_values)
            dbfs_range = dbfs_max - dbfs_min

            print(f"\n  ğŸ“Š ìŒëŸ‰ ê²°ê³¼:")
            print(f"     ë²”ìœ„: {dbfs_min:.1f} ~ {dbfs_max:.1f} dBFS")
            print(f"     í¸ì°¨: {dbfs_range:.1f} dB")

            if dbfs_range <= 4:
                print(f"     âœ… ëª©í‘œ ë‹¬ì„±! (Â±2dB ì´ë‚´)")
            else:
                print(f"     âš ï¸ ì¶”ê°€ ì¡°ì • í•„ìš”")


# ============================================================
# í¸ì˜ í•¨ìˆ˜
# ============================================================

def normalize_scenes_forced(
    scenes: List[Dict],
    target_rate: float = 8.5,
    target_dbfs: float = -20.0,
    progress_callback: Optional[Callable] = None
) -> List[Dict]:
    """
    ê°•ì œ ì •ê·œí™” í¸ì˜ í•¨ìˆ˜

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸
        target_rate: ëª©í‘œ ë°œí™”ì†ë„ (ê¸°ë³¸ 8.5 ê¸€ì/ì´ˆ)
        target_dbfs: ëª©í‘œ ìŒëŸ‰ (ê¸°ë³¸ -20 dBFS)
        progress_callback: ì§„í–‰ ì½œë°±

    Returns:
        ì •ê·œí™”ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
    """

    normalizer = ForcedAudioNormalizer(
        target_rate=target_rate,
        target_dbfs=target_dbfs
    )

    return normalizer.normalize_all_scenes(scenes, progress_callback)


def analyze_normalization_stats(scenes: List[Dict]) -> Dict:
    """
    ì •ê·œí™” ìƒíƒœ ë¶„ì„

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        í†µê³„ ì •ë³´
    """

    if not PYDUB_AVAILABLE:
        return {"error": "pydub not installed"}

    rates = []
    dbfs_values = []
    durations = []

    for scene in scenes:
        audio_data = scene.get("audio_data")
        if not audio_data:
            continue

        try:
            audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
            duration = len(audio) / 1000

            text = scene.get("text", "")
            char_count = len(text.replace(" ", "").replace("\n", ""))

            if duration > 0 and char_count > 0:
                rate = char_count / duration
                dbfs = audio.dBFS if audio.dBFS != float('-inf') else -60

                rates.append(rate)
                dbfs_values.append(dbfs)
                durations.append(duration)
        except:
            pass

    if not rates:
        return {"error": "no valid scenes"}

    rate_mean = np.mean(rates)
    rate_deviation = (max(rates) - min(rates)) / 2 / rate_mean * 100 if rate_mean > 0 else 0

    return {
        "scene_count": len(rates),
        "rate_min": min(rates),
        "rate_max": max(rates),
        "rate_mean": rate_mean,
        "rate_std": np.std(rates),
        "rate_deviation_pct": rate_deviation,
        "dbfs_min": min(dbfs_values),
        "dbfs_max": max(dbfs_values),
        "dbfs_range": max(dbfs_values) - min(dbfs_values),
        "total_duration": sum(durations),
        "needs_normalization": rate_deviation > 5 or (max(dbfs_values) - min(dbfs_values)) > 4
    }
