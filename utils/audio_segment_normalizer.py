# -*- coding: utf-8 -*-
"""
êµ¬ê°„ë³„ ë°œí™”ì†ë„ ì •ê·œí™”

ë¬¸ì œ: TTS ëª¨ë¸ì´ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œ ë’¤ë¡œ ê°ˆìˆ˜ë¡ ë¹¨ë¼ì§
í•´ê²°: êµ¬ê°„ë³„ë¡œ ë¶„ì„í•˜ê³  ê°œë³„ ì •ê·œí™”í•˜ì—¬ ì¼ê´€ëœ ì†ë„ ìœ ì§€
"""

import os
import io
import subprocess
import tempfile
import warnings
from typing import List, Dict, Tuple, Optional
from pydub import AudioSegment
from pydub.silence import split_on_silence

warnings.filterwarnings("ignore")


class SegmentSpeedNormalizer:
    """
    êµ¬ê°„ë³„ ë°œí™”ì†ë„ ì •ê·œí™”

    ì²˜ë¦¬ ë°©ì‹:
    1. ì˜¤ë””ì˜¤ë¥¼ êµ¬ê°„ë³„ë¡œ ë¶„í•  (ë¬µìŒ ê¸°ì¤€)
    2. ê° êµ¬ê°„ì˜ ë°œí™”ì†ë„ ì¶”ì •
    3. ë¹ ë¥¸ êµ¬ê°„ì€ ëŠë¦¬ê²Œ, ëŠë¦° êµ¬ê°„ì€ ë¹ ë¥´ê²Œ ì¡°ì •
    4. ìì—°ìŠ¤ëŸ½ê²Œ í•©ì¹˜ê¸°
    """

    def __init__(
        self,
        target_rate: float = 8.5,
        tolerance: float = 0.10,  # Â±10%
        min_segment_ms: int = 300,  # ìµœì†Œ êµ¬ê°„ ê¸¸ì´
    ):
        self.target_rate = target_rate
        self.tolerance = tolerance
        self.min_segment_ms = min_segment_ms
        self.ffmpeg_available = self._check_ffmpeg()

        print(f"\n[SegmentNorm] ì´ˆê¸°í™”")
        print(f"  ëª©í‘œ ë°œí™”ì†ë„: {target_rate} ê¸€ì/ì´ˆ")
        print(f"  í—ˆìš© í¸ì°¨: Â±{tolerance*100:.0f}%")

    def _check_ffmpeg(self) -> bool:
        try:
            result = subprocess.run(
                ["ffmpeg", "-version"],
                capture_output=True,
                timeout=5
            )
            return result.returncode == 0
        except:
            return False

    def normalize_scene_bytes(
        self,
        audio_data: bytes,
        text: str,
        scene_id: int = 0
    ) -> Tuple[bytes, float]:
        """
        ë°”ì´íŠ¸ ë°ì´í„°ë¡œ ì”¬ ì •ê·œí™”

        Args:
            audio_data: WAV ë°”ì´íŠ¸ ë°ì´í„°
            text: ì”¬ í…ìŠ¤íŠ¸
            scene_id: ì”¬ ID

        Returns:
            (ì •ê·œí™”ëœ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸, ìƒˆ duration)
        """

        if not audio_data:
            return audio_data, 0

        try:
            audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
        except Exception as e:
            print(f"  [Scene {scene_id}] âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return audio_data, 0

        # ì „ì²´ ë¶„ì„
        total_duration = len(audio) / 1000
        char_count = len(text.replace(" ", "").replace("\n", ""))

        if total_duration <= 0 or char_count <= 0:
            return audio_data, total_duration

        overall_rate = char_count / total_duration

        print(f"\n[SegmentNorm] ì”¬ {scene_id}")
        print(f"  ì „ì²´: {char_count}ì, {total_duration:.2f}ì´ˆ, {overall_rate:.2f} ê¸€ì/ì´ˆ")

        # êµ¬ê°„ ë¶„í• 
        segments = self._split_into_segments(audio)

        if len(segments) < 2:
            # êµ¬ê°„ ë¶„í•  ë¶ˆê°€ ì‹œ ì „ì²´ ì •ê·œí™”ë§Œ
            normalized_audio = self._normalize_whole_audio(audio, overall_rate)
            output = io.BytesIO()
            normalized_audio.export(output, format="wav", parameters=["-ar", "24000", "-ac", "1"])
            output.seek(0)
            new_duration = len(normalized_audio) / 1000
            return output.read(), new_duration

        print(f"  {len(segments)}ê°œ êµ¬ê°„ ë¶„í• ")

        # êµ¬ê°„ë³„ ì†ë„ ë¶„ì„ (ë¹„ìœ¨ ê¸°ë°˜ ì¶”ì •)
        segment_analysis = self._analyze_segments(segments, text)

        # êµ¬ê°„ë³„ ì†ë„ í¸ì°¨ í™•ì¸
        rates = [s["estimated_rate"] for s in segment_analysis if s["estimated_rate"] > 0]

        if rates:
            min_rate = min(rates)
            max_rate = max(rates)
            rate_mean = sum(rates) / len(rates)
            rate_range = (max_rate - min_rate) / rate_mean if rate_mean > 0 else 0

            print(f"  êµ¬ê°„ë³„ ì†ë„: {min_rate:.2f} ~ {max_rate:.2f} (í‰ê· : {rate_mean:.2f})")

            # í¸ì°¨ê°€ í¬ë©´ êµ¬ê°„ë³„ ì •ê·œí™”
            if rate_range > 0.15:  # 15% ì´ìƒ í¸ì°¨
                print(f"  ğŸ”§ êµ¬ê°„ë³„ ì •ê·œí™” ì ìš© (í¸ì°¨: {rate_range*100:.1f}%)")
                normalized_segments = self._normalize_segments(segment_analysis)
                audio = self._merge_segments(normalized_segments)
            else:
                print(f"  âœ… í¸ì°¨ ì–‘í˜¸, ì „ì²´ ì •ê·œí™”ë§Œ")
                audio = self._normalize_whole_audio(audio, overall_rate)

        # ìµœì¢… ê²°ê³¼
        output = io.BytesIO()
        audio.export(output, format="wav", parameters=["-ar", "24000", "-ac", "1"])
        output.seek(0)

        new_duration = len(audio) / 1000
        new_rate = char_count / new_duration if new_duration > 0 else 0
        print(f"  â†’ ê²°ê³¼: {new_rate:.2f} ê¸€ì/ì´ˆ ({new_duration:.2f}ì´ˆ)")

        return output.read(), new_duration

    def _split_into_segments(self, audio: AudioSegment) -> List[AudioSegment]:
        """ë¬µìŒ ê¸°ì¤€ìœ¼ë¡œ êµ¬ê°„ ë¶„í• """

        try:
            # ë¬µìŒ ê¸°ì¤€ ë¶„í• 
            segments = split_on_silence(
                audio,
                min_silence_len=150,  # 150ms ì´ìƒ ë¬µìŒ
                silence_thresh=-40,   # -40dB ì´í•˜ë¥¼ ë¬µìŒìœ¼ë¡œ
                keep_silence=80       # ì•ë’¤ 80ms ìœ ì§€
            )

            if not segments:
                return [audio]

            # ë„ˆë¬´ ì§§ì€ êµ¬ê°„ ë³‘í•©
            merged = []
            current = None

            for seg in segments:
                if current is None:
                    current = seg
                elif len(current) < self.min_segment_ms:
                    current = current + seg
                else:
                    merged.append(current)
                    current = seg

            if current is not None:
                merged.append(current)

            return merged if merged else [audio]

        except Exception as e:
            print(f"  âš ï¸ êµ¬ê°„ ë¶„í•  ì˜¤ë¥˜: {e}")
            return [audio]

    def _analyze_segments(
        self,
        segments: List[AudioSegment],
        text: str
    ) -> List[Dict]:
        """êµ¬ê°„ë³„ ë¶„ì„ (ë¹„ìœ¨ ê¸°ë°˜ ì¶”ì •)"""

        analysis = []
        total_duration = sum(len(s) for s in segments) / 1000
        char_count = len(text.replace(" ", "").replace("\n", ""))

        for idx, seg in enumerate(segments):
            seg_duration = len(seg) / 1000
            seg_ratio = seg_duration / total_duration if total_duration > 0 else 0
            estimated_chars = int(char_count * seg_ratio)
            estimated_rate = estimated_chars / seg_duration if seg_duration > 0 else 0

            analysis.append({
                "index": idx,
                "segment": seg,
                "duration": seg_duration,
                "estimated_chars": estimated_chars,
                "estimated_rate": estimated_rate,
            })

        return analysis

    def _normalize_segments(self, segment_analysis: List[Dict]) -> List[AudioSegment]:
        """êµ¬ê°„ë³„ ì†ë„ ì •ê·œí™”"""

        normalized = []

        for item in segment_analysis:
            seg = item["segment"]
            current_rate = item["estimated_rate"]

            if current_rate <= 0:
                normalized.append(seg)
                continue

            # ëª©í‘œ ì†ë„ì™€ì˜ ë¹„ìœ¨
            atempo = self.target_rate / current_rate
            atempo = max(0.85, min(1.20, atempo))  # Â±20% ì œí•œ

            # 8% ì´ìƒ ì°¨ì´ë‚  ë•Œë§Œ ì¡°ì •
            if abs(atempo - 1.0) >= 0.08:
                direction = "â¬†ï¸" if atempo > 1.0 else "â¬‡ï¸"
                print(f"    êµ¬ê°„ {item['index']+1}: {direction} {atempo:.2f}x")
                seg = self._apply_atempo(seg, atempo)

            normalized.append(seg)

        return normalized

    def _normalize_whole_audio(self, audio: AudioSegment, current_rate: float) -> AudioSegment:
        """ì „ì²´ ì˜¤ë””ì˜¤ ì†ë„ ì •ê·œí™”"""

        if current_rate <= 0:
            return audio

        atempo = self.target_rate / current_rate
        atempo = max(0.85, min(1.20, atempo))

        if abs(atempo - 1.0) >= 0.05:
            direction = "â¬†ï¸ ë¹ ë¥´ê²Œ" if atempo > 1.0 else "â¬‡ï¸ ëŠë¦¬ê²Œ"
            print(f"  ì „ì²´ ì¡°ì •: {direction} ({atempo:.2f}x)")
            return self._apply_atempo(audio, atempo)

        return audio

    def _apply_atempo(self, audio: AudioSegment, atempo: float) -> AudioSegment:
        """FFmpeg atempo ì ìš©"""

        if not self.ffmpeg_available or abs(atempo - 1.0) < 0.01:
            return audio

        try:
            temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
            temp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

            audio.export(temp_in, format="wav")

            # atempo ì²´ì´ë‹ (ë²”ìœ„ ì œí•œ: 0.5~2.0)
            atempo_filters = []
            remaining = atempo

            while remaining > 2.0:
                atempo_filters.append("atempo=2.0")
                remaining /= 2.0
            while remaining < 0.5:
                atempo_filters.append("atempo=0.5")
                remaining /= 0.5

            atempo_filters.append(f"atempo={remaining:.4f}")
            filter_str = ",".join(atempo_filters)

            cmd = [
                "ffmpeg", "-y", "-i", temp_in,
                "-af", filter_str,
                "-ar", "24000", "-ac", "1",
                temp_out
            ]

            subprocess.run(cmd, capture_output=True, timeout=30)

            if os.path.exists(temp_out):
                result = AudioSegment.from_file(temp_out)
            else:
                result = audio

            for f in [temp_in, temp_out]:
                try:
                    os.remove(f)
                except:
                    pass

            return result

        except Exception as e:
            print(f"  âš ï¸ atempo ì ìš© ì‹¤íŒ¨: {e}")
            return audio

    def _merge_segments(self, segments: List[AudioSegment]) -> AudioSegment:
        """êµ¬ê°„ í•©ì¹˜ê¸° (í¬ë¡œìŠ¤í˜ì´ë“œ)"""

        if not segments:
            return AudioSegment.empty()

        result = segments[0]

        for seg in segments[1:]:
            # 15ms í¬ë¡œìŠ¤í˜ì´ë“œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
            if len(result) > 15 and len(seg) > 15:
                result = result.append(seg, crossfade=15)
            else:
                result = result + seg

        return result


# ============================================================
# ì „ì²´ ì”¬ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================

def normalize_segments_all(
    scenes: List[Dict],
    target_rate: float = 8.5,
    progress_callback: Optional[callable] = None
) -> List[Dict]:
    """
    ëª¨ë“  ì”¬ì˜ êµ¬ê°„ë³„ ì†ë„ ì •ê·œí™”

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸ [{scene_id, text, audio_data, ...}, ...]
        target_rate: ëª©í‘œ ë°œí™”ì†ë„ (ê¸€ì/ì´ˆ)
        progress_callback: ì§„í–‰ ì½œë°±

    Returns:
        ì •ê·œí™”ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
    """

    normalizer = SegmentSpeedNormalizer(
        target_rate=target_rate,
        tolerance=0.10
    )

    results = []
    total = len(scenes)
    valid_scenes = [s for s in scenes if s.get("audio_data") and s.get("success")]

    if not valid_scenes:
        print("[SegmentNorm] ì •ê·œí™”í•  ì”¬ ì—†ìŒ")
        return scenes

    print(f"\n{'='*60}")
    print(f"[SegmentNorm] {len(valid_scenes)}ê°œ ì”¬ êµ¬ê°„ë³„ ì •ê·œí™” ì‹œì‘")
    print(f"{'='*60}")

    for idx, scene in enumerate(scenes):
        if progress_callback:
            progress_callback(idx, total, f"êµ¬ê°„ ì •ê·œí™”: ì”¬ {scene.get('scene_id', idx+1)}")

        # ì˜¤ë””ì˜¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ì”¬ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        if not scene.get("audio_data") or not scene.get("success"):
            results.append(scene)
            continue

        text = scene.get("text", "")
        scene_id = scene.get("scene_id", idx + 1)

        # êµ¬ê°„ë³„ ì •ê·œí™”
        normalized_audio, new_duration = normalizer.normalize_scene_bytes(
            scene.get("audio_data"),
            text,
            scene_id
        )

        results.append({
            **scene,
            "audio_data": normalized_audio,
            "duration": new_duration,
            "segment_normalized": True
        })

    print(f"\n{'='*60}")
    print(f"[SegmentNorm] ì™„ë£Œ!")
    print(f"{'='*60}")

    if progress_callback:
        progress_callback(total, total, "êµ¬ê°„ ì •ê·œí™” ì™„ë£Œ")

    return results
