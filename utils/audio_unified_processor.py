# -*- coding: utf-8 -*-
"""
í†µí•© ë‹¨ì¼ íŒ¨ìŠ¤ ì˜¤ë””ì˜¤ ì²˜ë¦¬ê¸° v1.0

í•µì‹¬ ì›ë¦¬:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ê¸°ì¡´ ë¬¸ì œ:
  ì •ê·œí™” FFmpeg + ê°€ì†ë³´ì • FFmpeg Ã— 4êµ¬ê°„ + SegmentNorm FFmpeg
  = ì´ 6~8íšŒ FFmpeg í˜¸ì¶œ â†’ í’ˆì§ˆ ì €í•˜, ìš¸ë¦¼

í•´ê²°ì±…:
  ëª¨ë“  ì¡°ì •ê°’ì„ ë¯¸ë¦¬ ê³„ì‚° â†’ ë‹¨ 1íšŒ FFmpeg ì ìš©
  = í’ˆì§ˆ ìœ ì§€, ìš¸ë¦¼ ì—†ìŒ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì²˜ë¦¬ ë°©ì‹:
1. ë¶„ì„: í˜„ì¬ ì†ë„, ìŒëŸ‰, êµ¬ê°„ë³„ íŠ¹ì„±
2. ê³„ì‚°: ì •ê·œí™” ê³„ìˆ˜ + ì ì‘í˜• ê°€ì†ë³´ì • ê³„ìˆ˜
3. ë³‘í•©: êµ¬ê°„ë³„ ìµœì¢… atempo ê°’ ì‚°ì¶œ
4. ì ìš©: ë‹¨ 1íšŒ FFmpegìœ¼ë¡œ ëª¨ë“  ì²˜ë¦¬
"""

import os
import io
import subprocess
import tempfile
import numpy as np
import warnings
from typing import List, Dict, Tuple, Optional
from pydub import AudioSegment
from pydub.silence import detect_nonsilent

warnings.filterwarnings("ignore")


class UnifiedAudioProcessor:
    """
    í†µí•© ì˜¤ë””ì˜¤ ì²˜ë¦¬ê¸° - ë‹¨ì¼ íŒ¨ìŠ¤

    ëª¨ë“  ì²˜ë¦¬ë¥¼ í•œ ë²ˆì—:
    - ì†ë„ ì •ê·œí™”
    - ìŒëŸ‰ ì •ê·œí™”
    - ì ì‘í˜• ê°€ì† ë³´ì •
    - êµ¬ê°„ë³„ ë¯¸ì„¸ ì¡°ì •

    FFmpeg 1íšŒë§Œ í˜¸ì¶œ!
    """

    def __init__(
        self,
        target_speed: float = 8.5,        # ëª©í‘œ ë°œí™”ì†ë„
        target_lufs: float = -16.0,       # ëª©í‘œ ìŒëŸ‰
        accel_profile: str = "adaptive",  # adaptive, strong, moderate
        num_segments: int = 8,            # êµ¬ê°„ ìˆ˜ (ì •ë°€ë„)
        crossfade_ms: int = 30,           # í¬ë¡œìŠ¤í˜ì´ë“œ (ìš¸ë¦¼ ë°©ì§€)
    ):
        self.target_speed = target_speed
        self.target_lufs = target_lufs
        self.accel_profile = accel_profile
        self.num_segments = num_segments
        self.crossfade_ms = crossfade_ms

        # ì ì‘í˜• ê°€ì† ë³´ì • í”„ë¡œíŒŒì¼
        self.profiles = {
            "adaptive": {
                "analyze": True,       # ì‹¤ì œ ê°€ì† ë¶„ì„
                "max_slowdown": 0.18,  # ìµœëŒ€ 18% ê°ì†
                "curve": "adaptive"
            },
            "strong": {
                "analyze": False,
                "max_slowdown": 0.15,
                "curve": "exponential"  # í›„ë°˜ë¶€ ê¸‰ê²©íˆ
            },
            "moderate": {
                "analyze": False,
                "max_slowdown": 0.10,
                "curve": "linear"
            }
        }

        self.ffmpeg_available = self._check_ffmpeg()

        print(f"\n[UnifiedProcessor] ì´ˆê¸°í™”")
        print(f"  ëª©í‘œ ì†ë„: {target_speed} ê¸€ì/ì´ˆ")
        print(f"  ëª©í‘œ ìŒëŸ‰: {target_lufs} LUFS")
        print(f"  ê°€ì† ë³´ì •: {accel_profile}")
        print(f"  êµ¬ê°„ ìˆ˜: {num_segments}ê°œ")
        print(f"  â­ ë‹¨ì¼ íŒ¨ìŠ¤: FFmpeg 1íšŒë§Œ ì ìš©")

    def _check_ffmpeg(self) -> bool:
        try:
            result = subprocess.run(["ffmpeg", "-version"],
                                    capture_output=True, timeout=5)
            return result.returncode == 0
        except:
            return False

    def process_scene_bytes(
        self,
        audio_data: bytes,
        text: str,
        scene_id: int = 0
    ) -> Tuple[bytes, float]:
        """
        ì”¬ ì²˜ë¦¬ (ë‹¨ì¼ íŒ¨ìŠ¤) - ë°”ì´íŠ¸ ì…ì¶œë ¥

        ìˆœì„œ:
        1. ë¶„ì„: í˜„ì¬ ìƒíƒœ ì¸¡ì •
        2. ê³„ì‚°: ëª¨ë“  ì¡°ì •ê°’ ì‚°ì¶œ
        3. ë³‘í•©: êµ¬ê°„ë³„ ìµœì¢… atempo
        4. ì ìš©: ë‹¨ 1íšŒ FFmpeg

        Returns:
            (ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸, ìƒˆ duration)
        """

        if not audio_data:
            return audio_data, 0.0

        print(f"\n[Unified] ì”¬ {scene_id} ì²˜ë¦¬ ì‹œì‘")

        try:
            audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
        except Exception as e:
            print(f"  âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return audio_data, 0.0

        duration_sec = len(audio) / 1000
        char_count = len(text.replace(" ", "").replace("\n", ""))

        if duration_sec < 2.0 or char_count < 10:
            print(f"  â­ï¸ ë„ˆë¬´ ì§§ìŒ ({duration_sec:.1f}ì´ˆ), ìŒëŸ‰ë§Œ ì¡°ì •")
            adjusted = self._adjust_volume_only(audio)
            output = io.BytesIO()
            adjusted.export(output, format="wav", parameters=["-ar", "24000", "-ac", "1"])
            output.seek(0)
            return output.read(), len(adjusted) / 1000

        # ===== 1ë‹¨ê³„: ë¶„ì„ =====
        current_speed = char_count / duration_sec
        current_lufs = self._measure_lufs(audio)

        print(f"  í˜„ì¬: {current_speed:.2f} ê¸€ì/ì´ˆ, {current_lufs:.1f} LUFS")
        print(f"  ëª©í‘œ: {self.target_speed:.2f} ê¸€ì/ì´ˆ, {self.target_lufs:.1f} LUFS")

        # ===== 2ë‹¨ê³„: ì •ê·œí™” ê³„ìˆ˜ ê³„ì‚° =====
        # ì „ì²´ ì†ë„ ì¡°ì • ê³„ìˆ˜
        base_speed_factor = self.target_speed / current_speed if current_speed > 0 else 1.0
        base_speed_factor = max(0.80, min(1.25, base_speed_factor))

        # ìŒëŸ‰ ì¡°ì • (dB)
        volume_db = self.target_lufs - current_lufs
        volume_db = max(-12, min(15, volume_db))

        print(f"  ì •ê·œí™”: ì†ë„ {base_speed_factor:.3f}x, ìŒëŸ‰ {volume_db:+.1f}dB")

        # ===== 3ë‹¨ê³„: ì ì‘í˜• ê°€ì† ë³´ì • ê³„ìˆ˜ ê³„ì‚° =====
        profile = self.profiles.get(self.accel_profile, self.profiles["adaptive"])

        if profile["analyze"]:
            # ì‹¤ì œ ê°€ì† íŒ¨í„´ ë¶„ì„
            accel_factors = self._analyze_acceleration_pattern(audio, char_count)
        else:
            # ê³ ì • íŒ¨í„´ ì‚¬ìš©
            accel_factors = self._get_fixed_pattern(profile)

        # ===== 4ë‹¨ê³„: ìµœì¢… atempo ê³„ì‚° (ì •ê·œí™” + ê°€ì†ë³´ì •) =====
        final_atempos = []
        for i, accel_factor in enumerate(accel_factors):
            # ìµœì¢… = ì •ê·œí™” ì†ë„ Ã— ê°€ì† ë³´ì •
            final = base_speed_factor * accel_factor
            final = max(0.70, min(1.35, final))  # ì•ˆì „ ë²”ìœ„
            final_atempos.append(final)

        # êµ¬ê°„ë³„ atempo ì¶œë ¥
        print(f"  êµ¬ê°„ë³„ ìµœì¢… atempo ({self.num_segments}êµ¬ê°„):")
        for i, atempo in enumerate(final_atempos):
            if i == 0:
                continue  # ì²« êµ¬ê°„ì€ ì¶œë ¥ ìƒëµ
            slowdown = (1.0 - accel_factors[i]) * 100
            print(f"    êµ¬ê°„ {i+1}/{self.num_segments}: {atempo:.3f} (ë³´ì •: {slowdown:.1f}% ê°ì†)")

        # ===== 5ë‹¨ê³„: ë‹¨ì¼ íŒ¨ìŠ¤ ì ìš© =====
        processed_audio = self._apply_single_pass_processing(
            audio,
            final_atempos,
            volume_db
        )

        # ë°”ì´íŠ¸ë¡œ ë³€í™˜
        output = io.BytesIO()
        processed_audio.export(output, format="wav", parameters=["-ar", "24000", "-ac", "1"])
        output.seek(0)

        # ê²°ê³¼ í™•ì¸
        new_duration = len(processed_audio) / 1000
        new_speed = char_count / new_duration if new_duration > 0 else 0

        print(f"  â†’ ì™„ë£Œ: {duration_sec:.2f}ì´ˆ â†’ {new_duration:.2f}ì´ˆ")
        print(f"  â†’ ì†ë„: {current_speed:.2f} â†’ {new_speed:.2f} ê¸€ì/ì´ˆ")

        return output.read(), new_duration

    def _measure_lufs(self, audio: AudioSegment) -> float:
        """LUFS ì¸¡ì • (ê°„ì´ ë²„ì „)"""
        try:
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            samples = samples / (2**15)
            rms = np.sqrt(np.mean(samples**2))
            lufs = 20 * np.log10(rms + 1e-10) - 3
            return max(-60, min(0, lufs))
        except:
            return -23.0

    def _analyze_acceleration_pattern(
        self,
        audio: AudioSegment,
        char_count: int
    ) -> List[float]:
        """
        ì ì‘í˜• ê°€ì† íŒ¨í„´ ë¶„ì„

        TTS íŠ¹ì„±:
        - ì‹œì‘: ì²œì²œíˆ (attention ì§‘ì¤‘)
        - ì¤‘ê°„: ì ì§„ì  ê°€ì†
        - ë: ê¸‰ê²©í•œ ê°€ì† (attention ë¶„ì‚°)

        ë¶„ì„ ë°©ë²•:
        - êµ¬ê°„ë³„ ìŒì„± ë°€ë„ ì¸¡ì •
        - ë°€ë„ê°€ ë†’ì„ìˆ˜ë¡ ë¹ ë¥¸ ë°œí™” â†’ ë” ë§ì´ ê°ì†
        """

        total_duration = len(audio)
        segment_duration = total_duration // self.num_segments

        # êµ¬ê°„ë³„ ìŒì„± ë°€ë„ ë¶„ì„
        densities = []
        for i in range(self.num_segments):
            start = i * segment_duration
            end = start + segment_duration if i < self.num_segments - 1 else total_duration
            seg = audio[start:end]

            # ìŒì„± êµ¬ê°„ ë¹„ìœ¨ (ë°€ë„)
            try:
                nonsilent = detect_nonsilent(seg, min_silence_len=30, silence_thresh=-40)
                if nonsilent:
                    speech_ms = sum(e - s for s, e in nonsilent)
                    density = speech_ms / len(seg) if len(seg) > 0 else 1.0
                else:
                    density = 1.0
            except:
                density = 1.0

            densities.append(density)

        # ì²« êµ¬ê°„ ëŒ€ë¹„ ìƒëŒ€ì  ë°€ë„
        base_density = densities[0] if densities[0] > 0 else 1.0
        relative_densities = [d / base_density for d in densities]

        # ë°€ë„ ê¸°ë°˜ ê°ì† ê³„ìˆ˜ ê³„ì‚°
        max_slowdown = self.profiles["adaptive"]["max_slowdown"]
        accel_factors = []

        for i, rel_density in enumerate(relative_densities):
            if i == 0:
                # ì²« êµ¬ê°„ì€ ìœ ì§€
                accel_factors.append(1.0)
            else:
                # ë°€ë„ê°€ ë†’ì„ìˆ˜ë¡ (ë¹ ë¥¼ìˆ˜ë¡) ë” ë§ì´ ê°ì†
                # ë˜í•œ ìœ„ì¹˜ê°€ ë’¤ë¡œ ê°ˆìˆ˜ë¡ ë” ë§ì´ ê°ì† (TTS íŠ¹ì„±)
                position = i / (self.num_segments - 1)

                # ìœ„ì¹˜ ê¸°ë°˜ + ë°€ë„ ê¸°ë°˜ ë³µí•© ê°ì†
                position_slowdown = position * max_slowdown * 0.6  # 60%ëŠ” ìœ„ì¹˜ ê¸°ë°˜
                density_slowdown = max(0, (rel_density - 1.0) * max_slowdown * 0.4)  # 40%ëŠ” ë°€ë„ ê¸°ë°˜

                total_slowdown = position_slowdown + density_slowdown
                total_slowdown = min(max_slowdown, total_slowdown)

                accel_factors.append(1.0 - total_slowdown)

        return accel_factors

    def _get_fixed_pattern(self, profile: Dict) -> List[float]:
        """ê³ ì • íŒ¨í„´ ìƒì„±"""

        max_slowdown = profile["max_slowdown"]
        curve = profile["curve"]

        factors = []
        for i in range(self.num_segments):
            if i == 0:
                factors.append(1.0)
                continue

            position = i / (self.num_segments - 1)

            if curve == "linear":
                slowdown = position * max_slowdown
            elif curve == "exponential":
                slowdown = (position ** 2) * max_slowdown
            elif curve == "s_curve":
                x = position * 6 - 3
                s = 1 / (1 + np.exp(-x))
                slowdown = s * max_slowdown
            else:
                slowdown = position * max_slowdown

            factors.append(1.0 - slowdown)

        return factors

    def _apply_single_pass_processing(
        self,
        audio: AudioSegment,
        segment_atempos: List[float],
        volume_db: float
    ) -> AudioSegment:
        """
        ë‹¨ì¼ íŒ¨ìŠ¤ ì²˜ë¦¬ (v1.1 - ë²„ê·¸ ìˆ˜ì •)

        â­ í•µì‹¬ ìˆ˜ì •:
        - ë¨¼ì € ì „ì²´ ì˜¤ë””ì˜¤ì— ìŒëŸ‰ ì¡°ì • ì ìš© (ê· ì¼!)
        - ê·¸ í›„ êµ¬ê°„ë³„ atempoë§Œ ì ìš©
        """

        if not self.ffmpeg_available:
            print("  âš ï¸ FFmpeg ì—†ìŒ, ìŒëŸ‰ë§Œ ì¡°ì •")
            return audio + volume_db

        # â­ ë²„ê·¸ ìˆ˜ì •: ë¨¼ì € ì „ì²´ ì˜¤ë””ì˜¤ì— ìŒëŸ‰ ê· ì¼ ì ìš©
        if abs(volume_db) >= 0.5:
            print(f"  ğŸ”Š ì „ì²´ ìŒëŸ‰ ê· ì¼ ì¡°ì •: {volume_db:+.1f}dB")
            audio = audio + volume_db  # pydub ë°©ì‹ (ë¹ ë¥´ê³  ê· ì¼)

        total_duration = len(audio)
        segment_duration = total_duration // self.num_segments

        processed_segments = []

        for i in range(self.num_segments):
            start = i * segment_duration
            end = start + segment_duration if i < self.num_segments - 1 else total_duration

            seg = audio[start:end]
            atempo = segment_atempos[i]

            # atempoê°€ ê±°ì˜ 1.0ì´ë©´ ì²˜ë¦¬ ìƒëµ (ìŒëŸ‰ì€ ì´ë¯¸ ì ìš©ë¨)
            if abs(atempo - 1.0) < 0.02:
                processed_segments.append(seg)
                continue

            # â­ atempoë§Œ ì ìš© (ìŒëŸ‰ì€ ì´ë¯¸ ì „ì²´ ì ìš©ë¨)
            seg = self._apply_ffmpeg_single(seg, atempo, volume_db=0)
            processed_segments.append(seg)

        # í¬ë¡œìŠ¤í˜ì´ë“œë¡œ ë¶€ë“œëŸ½ê²Œ ì—°ê²° (ìš¸ë¦¼ ë°©ì§€)
        return self._merge_with_crossfade(processed_segments)

    def _apply_ffmpeg_single(
        self,
        audio: AudioSegment,
        atempo: float,
        volume_db: float = 0
    ) -> AudioSegment:
        """ë‹¨ì¼ FFmpeg í˜¸ì¶œ (ê³ í’ˆì§ˆ)"""

        try:
            temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
            temp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

            audio.export(temp_in, format="wav")

            # í•„í„° ì²´ì¸ êµ¬ì„±
            filters = []

            if abs(atempo - 1.0) >= 0.02:
                # atempo ë²”ìœ„ ì œí•œ (0.5 ~ 2.0)
                safe_atempo = max(0.5, min(2.0, atempo))
                filters.append(f"atempo={safe_atempo}")

            if abs(volume_db) >= 0.5:
                filters.append(f"volume={volume_db}dB")

            if not filters:
                # ì •ë¦¬
                for f in [temp_in, temp_out]:
                    try:
                        os.remove(f)
                    except:
                        pass
                return audio

            filter_str = ",".join(filters)

            # ê³ í’ˆì§ˆ FFmpeg ì„¤ì •
            cmd = [
                "ffmpeg", "-y",
                "-i", temp_in,
                "-af", filter_str,
                "-ar", "24000",
                "-ac", "1",
                "-acodec", "pcm_s16le",  # ë¬´ì†ì‹¤ PCM
                "-f", "wav",
                temp_out
            ]

            result = subprocess.run(cmd, capture_output=True, timeout=60)

            if os.path.exists(temp_out) and os.path.getsize(temp_out) > 0:
                processed = AudioSegment.from_file(temp_out)
            else:
                processed = audio

            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for f in [temp_in, temp_out]:
                try:
                    os.remove(f)
                except:
                    pass

            return processed

        except Exception as e:
            print(f"    âš ï¸ FFmpeg ì˜¤ë¥˜: {e}")
            return audio + volume_db if volume_db != 0 else audio

    def _merge_with_crossfade(
        self,
        segments: List[AudioSegment]
    ) -> AudioSegment:
        """í¬ë¡œìŠ¤í˜ì´ë“œ ë³‘í•© (ìš¸ë¦¼ ë°©ì§€)"""

        if not segments:
            return AudioSegment.empty()

        result = segments[0]

        for seg in segments[1:]:
            # ë™ì  í¬ë¡œìŠ¤í˜ì´ë“œ (êµ¬ê°„ ê¸¸ì´ì— ë¹„ë¡€)
            fade_ms = min(
                self.crossfade_ms,
                len(result) // 6,
                len(seg) // 6
            )

            if fade_ms > 10:
                result = result.append(seg, crossfade=fade_ms)
            else:
                result = result + seg

        return result

    def _adjust_volume_only(self, audio: AudioSegment) -> AudioSegment:
        """ìŒëŸ‰ë§Œ ì¡°ì • (ì§§ì€ ì˜¤ë””ì˜¤ìš©)"""

        current_lufs = self._measure_lufs(audio)
        volume_db = self.target_lufs - current_lufs
        volume_db = max(-10, min(12, volume_db))

        return audio + volume_db


# ============================================================
# ì „ì²´ ì”¬ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================

def process_all_unified(
    scenes: List[Dict],
    target_speed: float = 8.5,
    accel_profile: str = "adaptive",
    progress_callback: Optional[callable] = None
) -> List[Dict]:
    """
    ëª¨ë“  ì”¬ í†µí•© ì²˜ë¦¬ (ë‹¨ì¼ íŒ¨ìŠ¤)

    ê¸°ì¡´: PerfectNorm â†’ SpeedCorrector â†’ SegmentNorm (6~8íšŒ FFmpeg)
    ìƒˆë¡œìš´: UnifiedProcessor (êµ¬ê°„ë‹¹ 1íšŒ FFmpeg)

    Args:
        scenes: ì”¬ ë¦¬ìŠ¤íŠ¸ [{scene_id, text, audio_data, ...}, ...]
        target_speed: ëª©í‘œ ë°œí™”ì†ë„ (ê¸€ì/ì´ˆ)
        accel_profile: ê°€ì† ë³´ì • í”„ë¡œíŒŒì¼ (adaptive/strong/moderate)
        progress_callback: ì§„í–‰ ì½œë°± (current, total, message)

    Returns:
        ì²˜ë¦¬ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
    """

    processor = UnifiedAudioProcessor(
        target_speed=target_speed,
        accel_profile=accel_profile,
        num_segments=8  # 8êµ¬ê°„ (ì •ë°€)
    )

    results = []
    total = len(scenes)
    valid_scenes = [s for s in scenes if s.get("audio_data") and s.get("success")]

    if not valid_scenes:
        print("[UnifiedProcessor] ì²˜ë¦¬í•  ì”¬ ì—†ìŒ")
        return scenes

    print(f"\n{'='*60}")
    print(f"[UnifiedProcessor] {len(valid_scenes)}ê°œ ì”¬ ë‹¨ì¼ íŒ¨ìŠ¤ ì²˜ë¦¬")
    print(f"  â­ FFmpeg ìµœì†Œ í˜¸ì¶œ â†’ ìš¸ë¦¼/ë³€ì¡° ë°©ì§€")
    print(f"  â­ ì ì‘í˜• ê°€ì† ë³´ì • â†’ ì •í™•í•œ ì†ë„ ê· ì¼í™”")
    print(f"{'='*60}")

    for idx, scene in enumerate(scenes):
        if progress_callback:
            try:
                progress_callback(idx, total, f"í†µí•© ì²˜ë¦¬: ì”¬ {scene.get('scene_id', idx+1)}")
            except:
                pass

        # ì˜¤ë””ì˜¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ì”¬ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        if not scene.get("audio_data") or not scene.get("success"):
            results.append(scene)
            continue

        audio_data = scene.get("audio_data")
        text = scene.get("text", "")
        scene_id = scene.get("scene_id", idx + 1)

        # ë‹¨ì¼ íŒ¨ìŠ¤ ì²˜ë¦¬
        processed_audio, new_duration = processor.process_scene_bytes(
            audio_data, text, scene_id
        )

        results.append({
            **scene,
            "audio_data": processed_audio,
            "duration": new_duration,
            "unified_processed": True,
            "normalized": True
        })

    # ìµœì¢… ì†ë„ ë¯¸ì„¸ ì¡°ì •
    results = _final_speed_adjustment(results, target_speed, progress_callback)

    print(f"\n{'='*60}")
    print(f"[UnifiedProcessor] ë‹¨ì¼ íŒ¨ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"{'='*60}")

    if progress_callback:
        try:
            progress_callback(total, total, "í†µí•© ì²˜ë¦¬ ì™„ë£Œ")
        except:
            pass

    return results


def _final_speed_adjustment(
    scenes: List[Dict],
    target_speed: float,
    progress_callback: Optional[callable] = None
) -> List[Dict]:
    """
    ìµœì¢… ì†ë„ ê°œë³„ ì¡°ì • (v1.1 - ë²„ê·¸ ìˆ˜ì •)

    â­ í•µì‹¬ ìˆ˜ì •:
    - ê¸°ì¡´: ì „ì²´ í‰ê·  ê³„ì‚° â†’ ë™ì¼ ê³„ìˆ˜ë¡œ ëª¨ë“  ì”¬ ì¡°ì •
    - ìˆ˜ì •: ê° ì”¬ë³„ë¡œ ê°œë³„ ì¡°ì • ê³„ìˆ˜ ê³„ì‚° â†’ ê°ê° ì ìš©
    """

    print(f"\n[FinalAdjust v1.1] ì”¬ë³„ ê°œë³„ ì†ë„ ì¡°ì •")
    print(f"  ëª©í‘œ: {target_speed:.2f} ê¸€ì/ì´ˆ")

    adjusted_results = []
    total = len(scenes)
    adjustments_made = 0

    for idx, scene in enumerate(scenes):
        audio_data = scene.get("audio_data")
        text = scene.get("text", "")
        scene_id = scene.get("scene_id", idx + 1)

        if not audio_data or not scene.get("success"):
            adjusted_results.append(scene)
            continue

        if progress_callback:
            try:
                progress_callback(idx, total, f"ìµœì¢… ì¡°ì •: ì”¬ {scene_id}")
            except:
                pass

        try:
            audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
            duration = len(audio) / 1000
            char_count = len(text.replace(" ", "").replace("\n", ""))

            if duration <= 0 or char_count <= 0:
                adjusted_results.append(scene)
                continue

            current_speed = char_count / duration
            speed_diff_pct = abs(current_speed - target_speed) / target_speed * 100

            # â­ 2% ì´ìƒ ì°¨ì´ë‚˜ë©´ ê°œë³„ ì¡°ì •
            if speed_diff_pct < 2.0:
                print(f"  ì”¬ {scene_id}: {current_speed:.2f} ê¸€ì/ì´ˆ âœ…")
                adjusted_results.append(scene)
                continue

            # â­ ì”¬ë³„ ê°œë³„ ì¡°ì • ê³„ìˆ˜ ê³„ì‚°
            adjustment = target_speed / current_speed
            adjustment = max(0.85, min(1.20, adjustment))

            print(f"  ì”¬ {scene_id}: {current_speed:.2f} â†’ {target_speed:.2f} (x{adjustment:.3f})")

            # atempo ì ìš©
            temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
            temp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

            audio.export(temp_in, format="wav")

            cmd = [
                "ffmpeg", "-y", "-i", temp_in,
                "-af", f"atempo={adjustment}",
                "-ar", "24000", "-ac", "1",
                "-acodec", "pcm_s16le",
                temp_out
            ]

            subprocess.run(cmd, capture_output=True, timeout=30)

            if os.path.exists(temp_out) and os.path.getsize(temp_out) > 0:
                result_audio = AudioSegment.from_file(temp_out)
                output = io.BytesIO()
                result_audio.export(output, format="wav", parameters=["-ar", "24000", "-ac", "1"])
                output.seek(0)
                new_audio_data = output.read()
                new_duration = len(result_audio) / 1000

                # ê²°ê³¼ í™•ì¸
                new_speed = char_count / new_duration if new_duration > 0 else 0
                print(f"        â†’ ê²°ê³¼: {new_speed:.2f} ê¸€ì/ì´ˆ")

                adjustments_made += 1
            else:
                new_audio_data = audio_data
                new_duration = duration

            for f in [temp_in, temp_out]:
                try:
                    os.remove(f)
                except:
                    pass

            adjusted_results.append({
                **scene,
                "audio_data": new_audio_data,
                "duration": new_duration,
                "final_adjusted": True
            })

        except Exception as e:
            print(f"  ì”¬ {scene_id}: âš ï¸ ì‹¤íŒ¨ - {e}")
            adjusted_results.append(scene)

    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\n[FinalAdjust v1.1] ì™„ë£Œ ({adjustments_made}ê°œ ì”¬ ì¡°ì •ë¨)")

    # ìµœì¢… ì†ë„ í™•ì¸
    final_speeds = []
    for scene in adjusted_results:
        audio_data = scene.get("audio_data")
        text = scene.get("text", "")

        if audio_data and scene.get("success"):
            try:
                audio = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
                duration = len(audio) / 1000
                char_count = len(text.replace(" ", "").replace("\n", ""))
                if duration > 0 and char_count > 0:
                    final_speeds.append(char_count / duration)
            except:
                pass

    if final_speeds:
        avg = np.mean(final_speeds)
        min_s = min(final_speeds)
        max_s = max(final_speeds)
        deviation = (max_s - min_s) / avg * 100 if avg > 0 else 0
        print(f"  ìµœì¢… í‰ê· : {avg:.2f} ê¸€ì/ì´ˆ")
        print(f"  ë²”ìœ„: {min_s:.2f} ~ {max_s:.2f} (í¸ì°¨ Â±{deviation/2:.1f}%)")

    return adjusted_results
