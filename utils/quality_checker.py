# -*- coding: utf-8 -*-
"""
ë™ì˜ìƒ í’ˆì§ˆ ê²€ì¦ ìœ í‹¸ë¦¬í‹°

v1.0 - ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì˜ìƒ í”„ë ˆì„ ë¹„êµ
- ìƒ‰ìƒ ì°¨ì´ ì¸¡ì •
- ì±„ë„ ì†ì‹¤ ê°ì§€
- í’ˆì§ˆ ì§„ë‹¨ ë¦¬í¬íŠ¸ ì¶œë ¥

ì‚¬ìš©ë²•:
    python utils/quality_checker.py <original.png> <video.mp4>
"""

import sys
from pathlib import Path
from typing import Dict, Optional, Tuple

# OpenCV import
try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install opencv-python")


def extract_frame(video_path: str, frame_number: int = 0) -> Optional[np.ndarray]:
    """
    ë™ì˜ìƒì—ì„œ íŠ¹ì • í”„ë ˆì„ ì¶”ì¶œ

    Args:
        video_path: ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        frame_number: ì¶”ì¶œí•  í”„ë ˆì„ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)

    Returns:
        BGR í˜•ì‹ì˜ numpy ë°°ì—´ (ì‹¤íŒ¨ ì‹œ None)
    """
    if not CV2_AVAILABLE:
        return None

    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ë™ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
            return None

        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()
        cap.release()

        return frame if ret else None
    except Exception as e:
        print(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def compare_images(original_path: str, video_path: str, frame_number: int = 0) -> Dict:
    """
    ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì˜ìƒ í”„ë ˆì„ ë¹„êµ

    Args:
        original_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (PNG)
        video_path: ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ (MP4)
        frame_number: ë¹„êµí•  í”„ë ˆì„ ë²ˆí˜¸

    Returns:
        ë¹„êµ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not CV2_AVAILABLE:
        return {'error': 'OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}

    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
    original = cv2.imread(original_path)
    if original is None:
        return {'error': f'ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {original_path}'}

    # ë™ì˜ìƒ í”„ë ˆì„ ì¶”ì¶œ
    frame = extract_frame(video_path, frame_number)
    if frame is None:
        return {'error': f'ë™ì˜ìƒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {video_path}'}

    # í¬ê¸° ë§ì¶”ê¸° (í•„ìš”ì‹œ)
    if original.shape != frame.shape:
        print(f"âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜: ì›ë³¸ {original.shape[:2]} vs í”„ë ˆì„ {frame.shape[:2]}")
        frame = cv2.resize(frame, (original.shape[1], original.shape[0]),
                          interpolation=cv2.INTER_LANCZOS4)

    # 1. ì ˆëŒ€ ì°¨ì´ ê³„ì‚°
    diff = cv2.absdiff(original, frame)
    mean_diff = np.mean(diff)
    max_diff = np.max(diff)

    # 2. ì±„ë„ë³„ ì°¨ì´
    b_diff = np.mean(diff[:, :, 0])
    g_diff = np.mean(diff[:, :, 1])
    r_diff = np.mean(diff[:, :, 2])

    # 3. HSV ë³€í™˜ í›„ ì±„ë„ ë¹„êµ
    orig_hsv = cv2.cvtColor(original, cv2.COLOR_BGR2HSV)
    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # ì±„ë„ (Saturation) ì±„ë„
    orig_saturation = np.mean(orig_hsv[:, :, 1])
    frame_saturation = np.mean(frame_hsv[:, :, 1])
    saturation_loss = orig_saturation - frame_saturation
    saturation_loss_pct = (saturation_loss / orig_saturation * 100) if orig_saturation > 0 else 0

    # ë°ê¸° (Value) ì±„ë„
    orig_value = np.mean(orig_hsv[:, :, 2])
    frame_value = np.mean(frame_hsv[:, :, 2])
    brightness_diff = frame_value - orig_value

    # 4. SSIM (êµ¬ì¡°ì  ìœ ì‚¬ì„± - ì„ íƒì )
    ssim = None
    try:
        from skimage.metrics import structural_similarity
        gray_orig = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        ssim = structural_similarity(gray_orig, gray_frame)
    except ImportError:
        pass

    # 5. í’ˆì§ˆ íŒì •
    if mean_diff < 3 and abs(saturation_loss) < 2:
        quality = 'excellent'
        quality_ko = 'ìš°ìˆ˜'
    elif mean_diff < 5 and abs(saturation_loss) < 5:
        quality = 'good'
        quality_ko = 'ì–‘í˜¸'
    elif mean_diff < 10:
        quality = 'acceptable'
        quality_ko = 'ë³´í†µ'
    else:
        quality = 'poor'
        quality_ko = 'ë¶ˆëŸ‰'

    return {
        'mean_diff': float(mean_diff),
        'max_diff': float(max_diff),
        'channel_diff': {
            'blue': float(b_diff),
            'green': float(g_diff),
            'red': float(r_diff),
        },
        'saturation': {
            'original': float(orig_saturation),
            'frame': float(frame_saturation),
            'loss': float(saturation_loss),
            'loss_pct': float(saturation_loss_pct),
        },
        'brightness': {
            'original': float(orig_value),
            'frame': float(frame_value),
            'diff': float(brightness_diff),
        },
        'ssim': ssim,
        'quality': quality,
        'quality_ko': quality_ko,
        'sizes': {
            'original': f"{original.shape[1]}x{original.shape[0]}",
            'frame': f"{frame.shape[1]}x{frame.shape[0]}",
        }
    }


def save_diff_image(original_path: str, video_path: str, output_path: str,
                    frame_number: int = 0, amplify: int = 10) -> bool:
    """
    ì›ë³¸ê³¼ í”„ë ˆì„ì˜ ì°¨ì´ë¥¼ ì‹œê°í™”í•œ ì´ë¯¸ì§€ ì €ì¥

    Args:
        original_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        video_path: ë™ì˜ìƒ ê²½ë¡œ
        output_path: ì°¨ì´ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        frame_number: ë¹„êµí•  í”„ë ˆì„ ë²ˆí˜¸
        amplify: ì°¨ì´ ì¦í­ ë°°ìœ¨ (ë” ì„ ëª…í•˜ê²Œ ë³´ì´ë„ë¡)
    """
    if not CV2_AVAILABLE:
        return False

    original = cv2.imread(original_path)
    frame = extract_frame(video_path, frame_number)

    if original is None or frame is None:
        return False

    if original.shape != frame.shape:
        frame = cv2.resize(frame, (original.shape[1], original.shape[0]),
                          interpolation=cv2.INTER_LANCZOS4)

    # ì°¨ì´ ê³„ì‚° ë° ì¦í­
    diff = cv2.absdiff(original, frame)
    diff_amplified = np.clip(diff * amplify, 0, 255).astype(np.uint8)

    # ê²°ê³¼ ì €ì¥
    cv2.imwrite(output_path, diff_amplified)
    print(f"âœ… ì°¨ì´ ì´ë¯¸ì§€ ì €ì¥: {output_path}")

    return True


def diagnose_quality(original_path: str, video_path: str, verbose: bool = True) -> Dict:
    """
    í’ˆì§ˆ ì§„ë‹¨ ë¦¬í¬íŠ¸ ì¶œë ¥

    Args:
        original_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        video_path: ë™ì˜ìƒ ê²½ë¡œ
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        ë¹„êµ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    result = compare_images(original_path, video_path)

    if 'error' in result:
        print(f"âŒ ì˜¤ë¥˜: {result['error']}")
        return result

    if verbose:
        print()
        print("=" * 60)
        print("ğŸ“Š ë™ì˜ìƒ í’ˆì§ˆ ì§„ë‹¨ ê²°ê³¼ (v3.11)")
        print("=" * 60)
        print()
        print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€: {original_path}")
        print(f"ğŸ¬ ë¹„êµ ë™ì˜ìƒ: {video_path}")
        print(f"ğŸ“ í¬ê¸°: ì›ë³¸ {result['sizes']['original']} / í”„ë ˆì„ {result['sizes']['frame']}")
        print()
        print("-" * 60)
        print("ğŸ¨ ìƒ‰ìƒ ì°¨ì´ ë¶„ì„")
        print("-" * 60)
        print(f"  í‰ê·  ìƒ‰ìƒ ì°¨ì´: {result['mean_diff']:.2f} (0=ë™ì¼, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
        print(f"  ìµœëŒ€ ìƒ‰ìƒ ì°¨ì´: {result['max_diff']:.2f}")
        print(f"  ì±„ë„ë³„ ì°¨ì´: R={result['channel_diff']['red']:.2f}, "
              f"G={result['channel_diff']['green']:.2f}, "
              f"B={result['channel_diff']['blue']:.2f}")
        print()
        print("-" * 60)
        print("ğŸ’ ì±„ë„/ë°ê¸° ë¶„ì„")
        print("-" * 60)
        sat = result['saturation']
        print(f"  ì›ë³¸ ì±„ë„: {sat['original']:.2f}")
        print(f"  í”„ë ˆì„ ì±„ë„: {sat['frame']:.2f}")
        print(f"  ì±„ë„ ì†ì‹¤: {sat['loss']:.2f} ({sat['loss_pct']:.1f}%)")

        brt = result['brightness']
        print(f"  ë°ê¸° ì°¨ì´: {brt['diff']:+.2f}")

        if result['ssim'] is not None:
            print(f"  SSIM (êµ¬ì¡° ìœ ì‚¬ë„): {result['ssim']:.4f} (1.0=ì™„ë²½)")

        print()
        print("-" * 60)
        print("ğŸ† í’ˆì§ˆ íŒì •")
        print("-" * 60)

        quality_emoji = {
            'excellent': 'ğŸŒŸ',
            'good': 'âœ…',
            'acceptable': 'âš ï¸',
            'poor': 'âŒ'
        }

        emoji = quality_emoji.get(result['quality'], 'â“')
        print(f"  {emoji} íŒì •: {result['quality_ko']} ({result['quality']})")

        # ê¶Œì¥ ì‚¬í•­
        print()
        print("-" * 60)
        print("ğŸ’¡ ê¶Œì¥ ì‚¬í•­")
        print("-" * 60)

        if result['mean_diff'] > 10:
            print("  âš ï¸ ìƒ‰ìƒ ì°¨ì´ê°€ í½ë‹ˆë‹¤.")
            print("     â†’ FFmpeg CRF ê°’ì„ ë‚®ì¶”ì„¸ìš” (ì˜ˆ: 10 â†’ 8)")
            print("     â†’ device-scale-factor=2 í™•ì¸")

        if sat['loss'] > 5:
            print("  âš ï¸ ì±„ë„ ì†ì‹¤ì´ ìˆìŠµë‹ˆë‹¤.")
            print("     â†’ yuv420p ëŒ€ì‹  yuv444p ê³ ë ¤ (VLC ì „ìš©)")
            print("     â†’ color_preserve: true í™•ì¸")

        if result['quality'] in ['excellent', 'good']:
            print("  âœ… í˜„ì¬ í’ˆì§ˆ ì„¤ì •ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")

        print()
        print("=" * 60)

    return result


def extract_first_frame(video_path: str, output_path: str = None) -> Optional[str]:
    """
    ë™ì˜ìƒì˜ ì²« í”„ë ˆì„ì„ PNGë¡œ ì¶”ì¶œ

    Args:
        video_path: ë™ì˜ìƒ ê²½ë¡œ
        output_path: ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if not CV2_AVAILABLE:
        return None

    frame = extract_frame(video_path, 0)
    if frame is None:
        return None

    if output_path is None:
        video_name = Path(video_path).stem
        output_path = f"{video_name}_frame_0.png"

    cv2.imwrite(output_path, frame)
    print(f"âœ… ì²« í”„ë ˆì„ ì¶”ì¶œ: {output_path}")

    return output_path


# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == '__main__':
    if len(sys.argv) >= 3:
        original = sys.argv[1]
        video = sys.argv[2]

        result = diagnose_quality(original, video)

        # ì°¨ì´ ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒì )
        if len(sys.argv) >= 4 and sys.argv[3] == '--save-diff':
            diff_path = Path(original).stem + "_diff.png"
            save_diff_image(original, video, diff_path)

    elif len(sys.argv) == 2:
        # ë‹¨ì¼ ì¸ì: ë™ì˜ìƒì—ì„œ ì²« í”„ë ˆì„ ì¶”ì¶œ
        video = sys.argv[1]
        extract_first_frame(video)

    else:
        print("ì‚¬ìš©ë²•:")
        print("  í’ˆì§ˆ ë¹„êµ: python quality_checker.py <original.png> <video.mp4>")
        print("  ì°¨ì´ ì €ì¥: python quality_checker.py <original.png> <video.mp4> --save-diff")
        print("  í”„ë ˆì„ ì¶”ì¶œ: python quality_checker.py <video.mp4>")
