# -*- coding: utf-8 -*-
"""
TTS μ§μ ‘ μƒμ„±κΈ° - μ²­ν¬ λ¶„ν•  μ—†μ

μ²­ν¬ λ¶„ν• λ΅ μΈν• μ¤λ²„ν—¤λ“ μ κ±°:
- 128μ μ”¬ β†’ 3κ° μ²­ν¬ β†’ 3λ² API νΈμ¶ β†’ 38μ΄ (κΈ°μ΅΄)
- 128μ μ”¬ β†’ 1λ² API νΈμ¶ β†’ ~12μ΄ (μµμ ν™”)

200μ μ΄ν•λ” λ¶„ν• ν•μ§€ μ•κ³  μ§μ ‘ μƒμ„±
"""

import os
import time
import requests
from typing import Dict, List, Optional, Callable

# μ„Έμ… μ¬μ‚¬μ©μΌλ΅ μ—°κ²° μ¤λ²„ν—¤λ“ κ°μ†
_session = requests.Session()
_session.headers.update({
    "Content-Type": "application/json",
    "Connection": "keep-alive"
})

CHATTERBOX_URL = "http://localhost:8100"


def generate_scene_direct(
    text: str,
    params: Dict,
    timeout: int = 180
) -> Dict:
    """
    μ²­ν¬ λ¶„ν•  μ—†μ΄ μ§μ ‘ μƒμ„±

    Args:
        text: μƒμ„±ν•  ν…μ¤νΈ (200μ μ΄ν• κ¶μ¥)
        params: TTS νλΌλ―Έν„°
        timeout: μ”μ²­ νƒ€μ„μ•„μ›ƒ (μ΄)

    Returns:
        {success, audio_data, duration, generation_time, ...}
    """

    if not text.strip():
        return {"success": False, "error": "λΉ ν…μ¤νΈ"}

    request_data = {
        "text": text,
        "settings": {
            "language": params.get("language", "ko"),
            "voice_ref_path": params.get("voice_ref_path"),
            "exaggeration": params.get("exaggeration", 0.5),
            "cfg_weight": params.get("cfg_weight", 0.5),
            "temperature": params.get("temperature", 0.8),
            "speed": params.get("speed", 1.0),
            "repetition_penalty": params.get("repetition_penalty", 1.4),  # 1.3β†’1.4 ν† ν° λ°λ³µ κ°μ†
            "seed": params.get("seed"),
        }
    }

    start_time = time.time()

    try:
        response = _session.post(
            f"{CHATTERBOX_URL}/generate",
            json=request_data,
            timeout=timeout
        )

        if response.status_code == 200:
            result = response.json()

            if result.get("success"):
                # μ¤λ””μ¤ λ‹¤μ΄λ΅λ“
                audio_url = result.get("audio_url", "")
                audio_data = None

                if audio_url:
                    try:
                        audio_resp = _session.get(
                            f"{CHATTERBOX_URL}{audio_url}",
                            timeout=30
                        )
                        if audio_resp.status_code == 200:
                            audio_data = audio_resp.content
                    except Exception as e:
                        print(f"  β οΈ μ¤λ””μ¤ λ‹¤μ΄λ΅λ“ μ‹¤ν¨: {e}")

                elapsed = time.time() - start_time

                return {
                    "success": True,
                    "audio_data": audio_data,
                    "duration": result.get("duration_seconds", 0),
                    "generation_time": elapsed,
                    "audio_url": audio_url
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error", "μƒμ„± μ‹¤ν¨")
                }
        else:
            return {
                "success": False,
                "error": f"HTTP {response.status_code}"
            }

    except requests.exceptions.Timeout:
        return {"success": False, "error": f"νƒ€μ„μ•„μ›ƒ ({timeout}μ΄)"}
    except requests.exceptions.ConnectionError:
        return {"success": False, "error": "μ„λ²„ μ—°κ²° μ‹¤ν¨"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def generate_all_scenes_direct(
    scenes: List[Dict],
    params: Dict,
    timeout_per_scene: int = 180,
    progress_callback: Optional[Callable] = None
) -> List[Dict]:
    """
    λ¨λ“  μ”¬ μ§μ ‘ μƒμ„± (μ²­ν¬ λ¶„ν•  μ—†μ!)

    Args:
        scenes: μ”¬ λ¦¬μ¤νΈ [{scene_id, text, ...}, ...]
        params: TTS νλΌλ―Έν„°
        timeout_per_scene: μ”¬λ‹Ή νƒ€μ„μ•„μ›ƒ
        progress_callback: (current, total, message) μ½λ°±

    Returns:
        μƒμ„± κ²°κ³Ό λ¦¬μ¤νΈ
    """

    print("\n" + "=" * 60)
    print(f"[DirectGen] π€ {len(scenes)}κ° μ”¬ μ§μ ‘ μƒμ„± μ‹μ‘")
    print(f"[DirectGen] β΅ μ²­ν¬ λ¶„ν•  λΉ„ν™μ„±ν™” - μµλ€ μ†λ„!")
    print("=" * 60)

    results = []
    total = len(scenes)
    total_start = time.time()

    for idx, scene in enumerate(scenes):
        scene_id = scene.get("scene_id", idx + 1)
        text = scene.get("text", "")

        if progress_callback:
            progress_callback(idx, total, f"μ”¬ {scene_id} μƒμ„± μ¤‘...")

        char_count = len(text.replace(" ", "").replace("\n", ""))
        print(f"\n[Scene {scene_id}] {char_count}μ μ§μ ‘ μƒμ„±...")

        if not text.strip():
            results.append({
                "scene_id": scene_id,
                "text": text,
                "success": False,
                "error": "λΉ ν…μ¤νΈ",
                "status": "failed"
            })
            continue

        # μ§μ ‘ μƒμ„± (μ²­ν¬ λ¶„ν•  μ—†μ!)
        result = generate_scene_direct(text, params, timeout_per_scene)

        if result.get("success"):
            results.append({
                "scene_id": scene_id,
                "text": text,
                "text_preview": text[:50] + "..." if len(text) > 50 else text,
                "char_count": char_count,
                "audio_data": result.get("audio_data"),
                "duration": result.get("duration", 0),
                "generation_time": result.get("generation_time", 0),
                "chunks_count": 1,  # μ²­ν¬ λ¶„ν•  μ—†μ
                "status": "success",
                "success": True
            })
            print(f"[Scene {scene_id}] β… {result.get('generation_time', 0):.1f}μ΄, {result.get('duration', 0):.1f}μ΄ μ¤λ””μ¤")
        else:
            results.append({
                "scene_id": scene_id,
                "text": text,
                "text_preview": text[:50] + "..." if len(text) > 50 else text,
                "char_count": char_count,
                "audio_data": None,
                "status": "failed",
                "success": False,
                "error": result.get("error", "μƒμ„± μ‹¤ν¨")
            })
            print(f"[Scene {scene_id}] β {result.get('error')}")

    total_time = time.time() - total_start
    success_count = sum(1 for r in results if r.get("success"))

    print(f"\n[DirectGen] μ™„λ£: {success_count}/{total}κ° μ„±κ³µ")
    print(f"[DirectGen] μ΄ μ‹κ°„: {total_time:.1f}μ΄ (μ”¬λ‹Ή ν‰κ· : {total_time/total:.1f}μ΄)")
    print("=" * 60 + "\n")

    if progress_callback:
        progress_callback(total, total, f"μƒμ„± μ™„λ£ ({success_count}/{total})")

    return results


def generate_with_smart_chunking(
    text: str,
    params: Dict,
    max_chars: int = 200,
    timeout: int = 180
) -> Dict:
    """
    μ¤λ§νΈ μ²­ν¬ λ¶„ν•  (200μ μ΄κ³Όμ‹μ—λ§)

    - 200μ μ΄ν•: μ§μ ‘ μƒμ„±
    - 200μ μ΄κ³Ό: λ¬Έμ¥ κ²½κ³„μ—μ„ λ¶„ν• 

    Args:
        text: μƒμ„±ν•  ν…μ¤νΈ
        params: TTS νλΌλ―Έν„°
        max_chars: λ¶„ν•  κΈ°μ¤€ (κΈ°λ³Έ 200μ)
        timeout: νƒ€μ„μ•„μ›ƒ

    Returns:
        μƒμ„± κ²°κ³Ό
    """

    char_count = len(text.replace(" ", "").replace("\n", ""))

    # 200μ μ΄ν•λ” μ§μ ‘ μƒμ„±
    if char_count <= max_chars:
        return generate_scene_direct(text, params, timeout)

    # 200μ μ΄κ³Ό: λ¬Έμ¥ κ²½κ³„μ—μ„ λ¶„ν• 
    print(f"[SmartChunk] {char_count}μ β†’ λ¬Έμ¥ κ²½κ³„ λ¶„ν• ")

    sentences = _split_by_sentences(text)

    if len(sentences) <= 1:
        # λ¶„ν•  λ¶κ°€ β†’ μ§μ ‘ μƒμ„± μ‹λ„
        return generate_scene_direct(text, params, timeout)

    # μ²­ν¬λ΅ λ¬¶κΈ°
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= max_chars:
            current_chunk += sentence
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = sentence

    if current_chunk:
        chunks.append(current_chunk)

    print(f"[SmartChunk] {len(chunks)}κ° μ²­ν¬ μƒμ„±")

    # κ° μ²­ν¬ μƒμ„± λ° λ³‘ν•©
    from pydub import AudioSegment
    import io

    audio_segments = []

    for idx, chunk in enumerate(chunks):
        print(f"  μ²­ν¬ {idx+1}/{len(chunks)}: {len(chunk)}μ")
        result = generate_scene_direct(chunk, params, timeout // len(chunks) + 30)

        if result.get("success") and result.get("audio_data"):
            try:
                audio = AudioSegment.from_file(
                    io.BytesIO(result["audio_data"]), format="wav"
                )
                audio_segments.append(audio)
            except:
                pass

    if not audio_segments:
        return {"success": False, "error": "λ¨λ“  μ²­ν¬ μƒμ„± μ‹¤ν¨"}

    # λ³‘ν•©
    combined = audio_segments[0]
    pause = AudioSegment.silent(duration=100)  # 100ms λ¬΄μ

    for audio in audio_segments[1:]:
        combined = combined + pause + audio

    # λ°”μ΄νΈ λ³€ν™
    output = io.BytesIO()
    combined.export(output, format="wav")
    output.seek(0)

    return {
        "success": True,
        "audio_data": output.read(),
        "duration": len(combined) / 1000,
        "chunks": len(chunks)
    }


def _split_by_sentences(text: str) -> List[str]:
    """λ¬Έμ¥ λ‹¨μ„λ΅ λ¶„ν• """

    import re

    # ν•κµ­μ–΄/μμ–΄ λ¬Έμ¥ μΆ…κ²° ν¨ν„΄
    # λ§μΉ¨ν‘, λ¬Όμν‘, λλ‚ν‘ λ’¤μ—μ„ λ¶„ν•  (λ‹¨, μ«μ λ’¤ λ§μΉ¨ν‘ μ μ™Έ)
    pattern = r'(?<=[.!?])\s+'

    sentences = re.split(pattern, text)

    # λΉ λ¬Έμ¥ μ κ±° λ° μ •λ¦¬
    result = []
    for s in sentences:
        s = s.strip()
        if s:
            result.append(s + " ")

    return result


# ============================================================
# νΈν™μ„±μ„ μ„ν• λ³„μΉ­
# ============================================================

generate_scenes_direct = generate_all_scenes_direct
