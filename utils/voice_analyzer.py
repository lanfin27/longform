# -*- coding: utf-8 -*-
"""
ì°¸ì¡° ìŒì„± ë¶„ì„ê¸° v2.0 - í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •í™• ì¸¡ì •

í•µì‹¬ ë³€ê²½:
- í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì •í™•í•œ ë°œí™”ì†ë„ ê³„ì‚° (ê¸€ììˆ˜/ì‹œê°„)
- í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ì¶”ì • ë°©ì‹ ì‚¬ìš© (ìŒì„± ë°€ë„)
- ë¶„ì„ ê²°ê³¼ ìºì‹± (ì¬ë¶„ì„ ë°©ì§€)

ì‚¬ìš©:
    # í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë¶„ì„ (ì •í™•)
    result = analyze_voice_with_text("voice.mp3", "ì•ˆë…•í•˜ì„¸ìš”...")

    # í…ìŠ¤íŠ¸ ì—†ì´ ë¶„ì„ (ì¶”ì •)
    result = analyze_voice_and_get_params("voice.mp3")
"""

import os
import re
import json
import numpy as np
from typing import Dict, Optional, Tuple, List
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
from pathlib import Path
import warnings

warnings.filterwarnings("ignore")


class VoiceProfileManager:
    """
    ìŒì„± í”„ë¡œí•„ ê´€ë¦¬ì

    ê¸°ëŠ¥:
    1. ìŒì„± í”„ë¡œí•„ ë¡œë“œ/ì €ì¥
    2. í…ìŠ¤íŠ¸ ì—°ê²° (.txt íŒŒì¼ ë˜ëŠ” voice_profiles.json)
    3. ë¶„ì„ ê²°ê³¼ ìºì‹±
    """

    def __init__(self, base_path: str = None):
        if base_path is None:
            # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
            self.base_path = Path("data/voice_samples")
        else:
            self.base_path = Path(base_path)

        self.profiles_file = self.base_path / "voice_profiles.json"
        self.profiles: Dict[str, Dict] = {}

        self._load_profiles()

        print(f"[VoiceProfileManager] ì´ˆê¸°í™”")
        print(f"  ê²½ë¡œ: {self.base_path}")
        print(f"  í”„ë¡œí•„ ìˆ˜: {len(self.profiles)}")

    def _load_profiles(self):
        """í”„ë¡œí•„ ë¡œë“œ"""

        # 1. í†µí•© í”„ë¡œí•„ íŒŒì¼ í™•ì¸
        if self.profiles_file.exists():
            try:
                with open(self.profiles_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    voices = data.get("voices", [])
                    for voice in voices:
                        voice_id = voice.get("id") or voice.get("name", "").lower().replace(" ", "_")
                        self.profiles[voice_id] = voice
                print(f"  âœ… í†µí•© í”„ë¡œí•„ ë¡œë“œ: {len(self.profiles)}ê°œ")
                return
            except Exception as e:
                print(f"  âš ï¸ í”„ë¡œí•„ ë¡œë“œ ì˜¤ë¥˜: {e}")

        # 2. ê°œë³„ íŒŒì¼ì—ì„œ í”„ë¡œí•„ ìƒì„±
        self._scan_voice_files()

    def _scan_voice_files(self):
        """ìŒì„± íŒŒì¼ ìŠ¤ìº” ë° í”„ë¡œí•„ ìë™ ìƒì„±"""

        audio_extensions = {".mp3", ".wav", ".m4a", ".ogg", ".flac"}

        for folder in ["default", "library", "custom", ""]:
            folder_path = self.base_path / folder if folder else self.base_path

            if not folder_path.exists():
                continue

            for audio_file in folder_path.iterdir():
                if audio_file.suffix.lower() not in audio_extensions:
                    continue

                # í”„ë¡œí•„ ìƒì„±
                voice_id = audio_file.stem.lower().replace(" ", "_")

                if voice_id in self.profiles:
                    continue

                # í…ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°
                transcript = self._find_transcript(audio_file)

                self.profiles[voice_id] = {
                    "id": voice_id,
                    "name": audio_file.stem,
                    "audio_file": str(audio_file.relative_to(self.base_path)),
                    "audio_path": str(audio_file),
                    "transcript": transcript,
                    "language": "ko",
                    "analyzed": False,
                }

        print(f"  ğŸ“ ìŠ¤ìº” ì™„ë£Œ: {len(self.profiles)}ê°œ ìŒì„±")

    def _find_transcript(self, audio_file: Path) -> Optional[str]:
        """
        í…ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°

        ìš°ì„ ìˆœìœ„:
        1. ê°™ì€ ì´ë¦„ì˜ .txt íŒŒì¼
        2. ê°™ì€ ì´ë¦„ì˜ .json íŒŒì¼
        3. None
        """

        # .txt íŒŒì¼
        txt_file = audio_file.with_suffix(".txt")
        if txt_file.exists():
            try:
                with open(txt_file, "r", encoding="utf-8") as f:
                    transcript = f.read().strip()
                    if transcript:
                        print(f"    âœ… í…ìŠ¤íŠ¸ ë°œê²¬: {txt_file.name}")
                        return transcript
            except:
                pass

        # .json íŒŒì¼
        json_file = audio_file.with_suffix(".json")
        if json_file.exists():
            try:
                with open(json_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    transcript = data.get("transcript", "")
                    if transcript:
                        print(f"    âœ… í…ìŠ¤íŠ¸ ë°œê²¬: {json_file.name}")
                        return transcript
            except:
                pass

        return None

    def get_profile(self, voice_id_or_path: str) -> Optional[Dict]:
        """í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸° (ID ë˜ëŠ” ê²½ë¡œë¡œ)"""

        # IDë¡œ ê²€ìƒ‰
        voice_id_lower = voice_id_or_path.lower().replace(" ", "_")
        if voice_id_lower in self.profiles:
            return self.profiles[voice_id_lower]

        # ê²½ë¡œë¡œ ê²€ìƒ‰
        for profile in self.profiles.values():
            if profile.get("audio_path") == voice_id_or_path:
                return profile
            if profile.get("audio_file") and voice_id_or_path.endswith(profile["audio_file"]):
                return profile
            # íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰
            if os.path.basename(voice_id_or_path) == os.path.basename(profile.get("audio_path", "")):
                return profile

        # ìƒˆ í”„ë¡œí•„ ìƒì„±
        if os.path.exists(voice_id_or_path):
            return self._create_profile_from_path(voice_id_or_path)

        return None

    def _create_profile_from_path(self, audio_path: str) -> Dict:
        """ê²½ë¡œì—ì„œ í”„ë¡œí•„ ìƒì„±"""

        audio_file = Path(audio_path)
        voice_id = audio_file.stem.lower().replace(" ", "_")

        transcript = self._find_transcript(audio_file)

        profile = {
            "id": voice_id,
            "name": audio_file.stem,
            "audio_file": audio_file.name,
            "audio_path": str(audio_file),
            "transcript": transcript,
            "language": "ko",
            "analyzed": False,
        }

        self.profiles[voice_id] = profile

        return profile

    def set_transcript(self, voice_id: str, transcript: str):
        """í…ìŠ¤íŠ¸ ì„¤ì •"""

        voice_id_lower = voice_id.lower().replace(" ", "_")

        if voice_id_lower in self.profiles:
            self.profiles[voice_id_lower]["transcript"] = transcript
            self.profiles[voice_id_lower]["analyzed"] = False  # ì¬ë¶„ì„ í•„ìš”
            self.save_profiles()

            # .txt íŒŒì¼ë¡œë„ ì €ì¥
            audio_path = self.profiles[voice_id_lower].get("audio_path")
            if audio_path:
                txt_path = Path(audio_path).with_suffix(".txt")
                try:
                    with open(txt_path, "w", encoding="utf-8") as f:
                        f.write(transcript)
                    print(f"  ğŸ“ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥: {txt_path}")
                except Exception as e:
                    print(f"  âš ï¸ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_profiles(self):
        """í”„ë¡œí•„ ì €ì¥"""

        try:
            # ë””ë ‰í† ë¦¬ í™•ì¸
            self.profiles_file.parent.mkdir(parents=True, exist_ok=True)

            data = {"voices": list(self.profiles.values())}

            with open(self.profiles_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"[VoiceProfileManager] í”„ë¡œí•„ ì €ì¥ ì™„ë£Œ: {self.profiles_file}")

        except Exception as e:
            print(f"[VoiceProfileManager] ì €ì¥ ì˜¤ë¥˜: {e}")

    def list_voices(self) -> List[Dict]:
        """ëª¨ë“  ìŒì„± ëª©ë¡"""
        return list(self.profiles.values())

    def update_analysis(self, voice_id: str, analysis: Dict, params: Dict):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""

        voice_id_lower = voice_id.lower().replace(" ", "_")

        if voice_id_lower in self.profiles:
            self.profiles[voice_id_lower]["analysis"] = analysis
            self.profiles[voice_id_lower]["recommended_params"] = params
            self.profiles[voice_id_lower]["analyzed"] = True
            self.save_profiles()


class VoiceAnalyzer:
    """
    ì°¸ì¡° ìŒì„± ë¶„ì„ê¸° v2.0

    í•µì‹¬ ê¸°ëŠ¥:
    1. í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ â†’ ì •í™•í•œ ë°œí™”ì†ë„ ê³„ì‚° (ê¸€ììˆ˜/ì‹œê°„)
    2. í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ â†’ ìŒì„± ë°€ë„ë¡œ ì¶”ì •
    3. ë¶„ì„ ê²°ê³¼ ìºì‹±
    """

    def __init__(self, profile_manager: VoiceProfileManager = None):
        self.profile_manager = profile_manager or VoiceProfileManager()

        # ê¸°ì¤€ê°’
        self.reference_speed = 8.5  # ê¸€ì/ì´ˆ (í‘œì¤€ í•œêµ­ì–´)
        self.reference_lufs = -16.0  # LUFS

        print("[VoiceAnalyzer v2.0] ì´ˆê¸°í™” ì™„ë£Œ")
        print("  â­ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •í™• ì¸¡ì • ì§€ì›")

    def analyze(
        self,
        audio_path: str,
        transcript: str = None,
        force_reanalyze: bool = False
    ) -> Dict:
        """
        ì°¸ì¡° ìŒì„± ë¶„ì„

        Args:
            audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
            transcript: í…ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ í”„ë¡œí•„ì—ì„œ ê°€ì ¸ì˜´)
            force_reanalyze: ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ë¶„ì„

        Returns:
            {
                "duration_sec": float,
                "char_count": int,           # ê¸€ì ìˆ˜ (í…ìŠ¤íŠ¸ ìˆì„ ë•Œ)
                "speech_rate": float,        # ë°œí™” ì†ë„
                "speech_rate_accurate": bool, # ì •í™•í•œ ì¸¡ì • ì—¬ë¶€
                "avg_lufs": float,
                "tempo": str,
                ...
            }
        """

        print(f"\n[VoiceAnalyzer] ë¶„ì„ ì‹œì‘: {os.path.basename(audio_path)}")

        # 1. í”„ë¡œí•„ í™•ì¸ (ìºì‹œ)
        profile = self.profile_manager.get_profile(audio_path)

        if profile and profile.get("analyzed") and not force_reanalyze:
            if "analysis" in profile:
                print(f"  âœ… ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")
                return profile["analysis"]

        # 2. í…ìŠ¤íŠ¸ í™•ì¸
        if transcript is None and profile:
            transcript = profile.get("transcript")

        has_transcript = bool(transcript and len(transcript.strip()) > 0)

        if has_transcript:
            print(f"  âœ… í…ìŠ¤íŠ¸ ìˆìŒ: {len(transcript)}ì")
        else:
            print(f"  âš ï¸ í…ìŠ¤íŠ¸ ì—†ìŒ - ì¶”ì • ëª¨ë“œ")

        # 3. ì˜¤ë””ì˜¤ ë¡œë“œ
        if not os.path.exists(audio_path):
            print(f"  âŒ íŒŒì¼ ì—†ìŒ")
            return self._get_default_analysis()

        try:
            audio = AudioSegment.from_file(audio_path)
        except Exception as e:
            print(f"  âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._get_default_analysis()

        # 4. ê¸°ë³¸ ë¶„ì„
        duration_sec = len(audio) / 1000
        avg_lufs = self._measure_lufs(audio)
        energy_variation = self._measure_energy_variation(audio)
        speech_ratio, _ = self._analyze_speech_segments(audio)

        print(f"  ê¸¸ì´: {duration_sec:.2f}ì´ˆ")
        print(f"  ìŒëŸ‰: {avg_lufs:.1f} LUFS")

        # 5. â­ ë°œí™” ì†ë„ ê³„ì‚° (í•µì‹¬!)
        if has_transcript:
            # ì •í™•í•œ ê³„ì‚°
            char_count = self._count_chars(transcript)
            speech_rate = char_count / duration_sec if duration_sec > 0 else 8.5
            speech_rate_accurate = True

            print(f"  â­ ì •í™•í•œ ì¸¡ì •: {char_count}ì / {duration_sec:.2f}ì´ˆ = {speech_rate:.2f} ê¸€ì/ì´ˆ")
        else:
            # ì¶”ì •
            char_count = 0
            speech_rate = self._estimate_speech_rate(audio, speech_ratio, duration_sec)
            speech_rate_accurate = False

            print(f"  ğŸ“Š ì¶”ì • ì¸¡ì •: {speech_rate:.2f} ê¸€ì/ì´ˆ (ìŒì„± ë°€ë„ ê¸°ë°˜)")

        # 6. í…œí¬ ë¶„ë¥˜
        tempo = self._classify_tempo(speech_rate)
        print(f"  í…œí¬: {tempo}")

        # 7. ë¶„ì„ ê²°ê³¼
        analysis = {
            "duration_sec": round(duration_sec, 2),
            "char_count": char_count,
            "speech_rate": round(speech_rate, 2),
            "speech_rate_accurate": speech_rate_accurate,
            "avg_lufs": round(avg_lufs, 1),
            "energy_variation": round(energy_variation, 3),
            "speech_ratio": round(speech_ratio, 2),
            "tempo": tempo,
            "has_transcript": has_transcript,
        }

        print(f"[VoiceAnalyzer] ë¶„ì„ ì™„ë£Œ")

        return analysis

    def _count_chars(self, text: str) -> int:
        """
        ë°œí™” ê¸€ì ìˆ˜ ê³„ì‚°

        ì œì™¸: ê³µë°±, ì¤„ë°”ê¿ˆ, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ì
        í¬í•¨: í•œê¸€, ìˆ«ì, ì˜ë¬¸
        """

        # ê³µë°±, ì¤„ë°”ê¿ˆ ì œê±°
        text = text.replace(" ", "").replace("\n", "").replace("\t", "")

        # ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì„ íƒì )
        text = re.sub(r'[.,!?â€¦Â·\-\[\](){}""''ã€Œã€ã€ã€:;\'\"<>]', '', text)

        return len(text)

    def recommend_params(self, analysis: Dict) -> Dict:
        """
        ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ TTS íŒŒë¼ë¯¸í„° ì¶”ì²œ

        â­ ì •í™•í•œ ì¸¡ì •ì¼ ë•Œ ë” ì •ë°€í•œ ì¶”ì²œ
        """

        print(f"\n[VoiceAnalyzer] íŒŒë¼ë¯¸í„° ì¶”ì²œ")

        speech_rate = analysis.get("speech_rate", self.reference_speed)
        energy_var = analysis.get("energy_variation", 0.1)
        tempo = analysis.get("tempo", "normal")
        accurate = analysis.get("speech_rate_accurate", False)

        if accurate:
            print(f"  â­ ì •í™•í•œ ì¸¡ì • ê¸°ë°˜ ì¶”ì²œ")
        else:
            print(f"  ğŸ“Š ì¶”ì • ê¸°ë°˜ ì¶”ì²œ (ì •í™•ë„ ì œí•œ)")

        # 1. Speed íŒŒë¼ë¯¸í„° ê³„ì‚°
        speed_ratio = speech_rate / self.reference_speed

        if accurate:
            # ì •í™•í•œ ì¸¡ì •: ë” ì„¸ë°€í•œ ì¡°ì •
            recommended_speed = speed_ratio
            recommended_speed = max(0.70, min(1.30, recommended_speed))
        else:
            # ì¶”ì •: ë³´ìˆ˜ì  ì¡°ì •
            if tempo == "slow":
                recommended_speed = max(0.80, min(0.95, speed_ratio * 0.95))
            elif tempo == "fast":
                recommended_speed = max(1.05, min(1.20, speed_ratio * 1.05))
            else:
                recommended_speed = max(0.90, min(1.10, speed_ratio))

        print(f"  ë°œí™”ì†ë„: {speech_rate:.2f} â†’ speed: {recommended_speed:.2f}")

        # 2. CFG Weight
        if energy_var > 0.15:
            cfg_weight = 0.4
        elif energy_var < 0.08:
            cfg_weight = 0.6
        else:
            cfg_weight = 0.5

        # 3. Exaggeration
        exaggeration = max(0.3, min(0.7, 0.3 + energy_var * 2))

        # 4. Temperature
        if tempo == "slow":
            temperature = 0.7
        elif tempo == "fast":
            temperature = 0.9
        else:
            temperature = 0.8

        # 5. ëª©í‘œ ë°œí™”ì†ë„ (ì •ê·œí™”ìš©)
        # ì •í™•í•œ ì¸¡ì •ì´ë©´ í•´ë‹¹ ì†ë„ ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ì¤€ê°’ ì‚¬ìš©
        target_speed = speech_rate if accurate else self.reference_speed

        params = {
            "speed": round(recommended_speed, 2),
            "cfg_weight": round(cfg_weight, 2),
            "exaggeration": round(exaggeration, 2),
            "temperature": round(temperature, 2),
            "target_speed": round(target_speed, 2),
            "based_on_accurate": accurate,
        }

        print(f"[VoiceAnalyzer] ì¶”ì²œ: {params}")

        return params

    def analyze_and_recommend(
        self,
        audio_path: str,
        transcript: str = None,
        force_reanalyze: bool = False
    ) -> Dict:
        """ë¶„ì„ + ì¶”ì²œ í†µí•©"""

        analysis = self.analyze(audio_path, transcript, force_reanalyze)
        params = self.recommend_params(analysis)

        # ìºì‹œ ì €ì¥
        profile = self.profile_manager.get_profile(audio_path)
        if profile:
            self.profile_manager.update_analysis(profile["id"], analysis, params)

        return {
            "analysis": analysis,
            "recommended_params": params,
        }

    # ============================================================
    # ì¸¡ì • í•¨ìˆ˜ë“¤
    # ============================================================

    def _measure_lufs(self, audio: AudioSegment) -> float:
        """LUFS ì¸¡ì •"""
        try:
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            samples = samples / (2**15)
            rms = np.sqrt(np.mean(samples**2))
            lufs = 20 * np.log10(rms + 1e-10) - 3
            return max(-60, min(0, lufs))
        except:
            return -23.0

    def _analyze_speech_segments(self, audio: AudioSegment) -> Tuple[float, list]:
        """ìŒì„± êµ¬ê°„ ë¶„ì„"""
        try:
            nonsilent = detect_nonsilent(audio, min_silence_len=100, silence_thresh=-40)
            if not nonsilent:
                return 1.0, []
            speech_ms = sum(end - start for start, end in nonsilent)
            speech_ratio = speech_ms / len(audio)
            return speech_ratio, nonsilent
        except:
            return 1.0, []

    def _estimate_speech_rate(self, audio, speech_ratio, duration_sec) -> float:
        """ìŒì„± ë°€ë„ ê¸°ë°˜ ë°œí™”ì†ë„ ì¶”ì •"""
        base_rate = 8.5
        base_ratio = 0.70
        if speech_ratio > 0:
            estimated_rate = base_rate * (speech_ratio / base_ratio)
        else:
            estimated_rate = base_rate
        return max(5.0, min(12.0, estimated_rate))

    def _measure_energy_variation(self, audio: AudioSegment) -> float:
        """ì—ë„ˆì§€ ë³€í™”ëŸ‰ ì¸¡ì • (ê°ì • í‘œí˜„ ì •ë„)"""
        try:
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            frame_size = int(len(samples) / 100)
            if frame_size < 100:
                return 0.1
            energies = []
            for i in range(0, len(samples) - frame_size, frame_size):
                frame = samples[i:i + frame_size]
                energy = np.sqrt(np.mean(frame**2))
                energies.append(energy)
            if not energies:
                return 0.1
            mean_energy = np.mean(energies)
            std_energy = np.std(energies)
            if mean_energy > 0:
                variation = std_energy / mean_energy
            else:
                variation = 0.1
            return max(0.0, min(0.5, variation))
        except:
            return 0.1

    def _classify_tempo(self, speech_rate: float) -> str:
        """í…œí¬ ë¶„ë¥˜"""
        if speech_rate < 7.0:
            return "slow"
        elif speech_rate > 9.5:
            return "fast"
        else:
            return "normal"

    def _get_default_analysis(self) -> Dict:
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"""
        return {
            "duration_sec": 0,
            "char_count": 0,
            "speech_rate": self.reference_speed,
            "speech_rate_accurate": False,
            "avg_lufs": self.reference_lufs,
            "energy_variation": 0.1,
            "speech_ratio": 0.7,
            "tempo": "normal",
            "has_transcript": False,
        }


# ============================================================
# ì‹±ê¸€í†¤ ë° ê°„í¸ í•¨ìˆ˜
# ============================================================

_analyzer = None
_profile_manager = None

def get_profile_manager() -> VoiceProfileManager:
    """í”„ë¡œí•„ ê´€ë¦¬ì ì‹±ê¸€í†¤"""
    global _profile_manager
    if _profile_manager is None:
        _profile_manager = VoiceProfileManager()
    return _profile_manager

def get_analyzer() -> VoiceAnalyzer:
    """ë¶„ì„ê¸° ì‹±ê¸€í†¤"""
    global _analyzer
    if _analyzer is None:
        _analyzer = VoiceAnalyzer(get_profile_manager())
    return _analyzer


def analyze_voice_with_text(
    audio_path: str,
    transcript: str = None,
    force_reanalyze: bool = False
) -> Dict:
    """
    ì°¸ì¡° ìŒì„± ë¶„ì„ (í…ìŠ¤íŠ¸ í¬í•¨)

    ì‚¬ìš© ì˜ˆ:
        result = analyze_voice_with_text(
            "path/to/voice.mp3",
            "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€..."
        )
        print(result["analysis"]["speech_rate"])  # ì •í™•í•œ ê°’!
        print(result["recommended_params"]["speed"])
    """
    return get_analyzer().analyze_and_recommend(audio_path, transcript, force_reanalyze)


def analyze_voice_and_get_params(audio_path: str) -> Dict:
    """
    ì°¸ì¡° ìŒì„± ë¶„ì„ í›„ ì¶”ì²œ íŒŒë¼ë¯¸í„° ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜)

    í…ìŠ¤íŠ¸ê°€ í”„ë¡œí•„ì— ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš©
    """
    return get_analyzer().analyze_and_recommend(audio_path)


def set_voice_transcript(voice_path: str, transcript: str):
    """ìŒì„±ì— í…ìŠ¤íŠ¸ ì—°ê²°"""
    profile_manager = get_profile_manager()
    profile = profile_manager.get_profile(voice_path)
    if profile:
        profile_manager.set_transcript(profile["id"], transcript)
        print(f"[VoiceAnalyzer] í…ìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ: {len(transcript)}ì")
    else:
        print(f"[VoiceAnalyzer] í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {voice_path}")


def get_voice_transcript(voice_path: str) -> Optional[str]:
    """ìŒì„±ì˜ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    profile_manager = get_profile_manager()
    profile = profile_manager.get_profile(voice_path)
    if profile:
        return profile.get("transcript")
    return None


def get_recommended_speed(audio_path: str) -> float:
    """ì°¸ì¡° ìŒì„±ì—ì„œ ì¶”ì²œ speed ê°’ë§Œ ë°˜í™˜"""
    result = analyze_voice_and_get_params(audio_path)
    return result.get("recommended_params", {}).get("speed", 1.0)


def get_recommended_target_speed(audio_path: str) -> float:
    """ì°¸ì¡° ìŒì„±ì—ì„œ ëª©í‘œ ë°œí™”ì†ë„ ë°˜í™˜"""
    result = analyze_voice_and_get_params(audio_path)
    return result.get("recommended_params", {}).get("target_speed", 8.5)


# ============================================================
# VoiceOptimizer - ì°¸ì¡° ìŒì„± ìµœì í™” (Voice Cloningìš©)
# ============================================================

class VoiceOptimizer:
    """
    ì°¸ì¡° ìŒì„± ìµœì í™”ê¸°

    ê¸´ ìŒì„±ì—ì„œ voice cloningì— ìµœì ì¸ êµ¬ê°„(15~30ì´ˆ) ì¶”ì¶œ
    - ìŒì„±ì´ ì—°ì†ì ì¸ êµ¬ê°„ ì„ íƒ
    - ìŒëŸ‰ì´ ì•ˆì •ì ì¸ êµ¬ê°„ ì„ íƒ
    - ì‹œì‘ë³´ë‹¤ ì¤‘ê°„ ë¶€ë¶„ ì„ í˜¸
    """

    # ìµœì  êµ¬ê°„ ì„¤ì •
    OPTIMAL_MIN_SEC = 15   # ìµœì†Œ 15ì´ˆ
    OPTIMAL_MAX_SEC = 30   # ìµœëŒ€ 30ì´ˆ
    OPTIMAL_TARGET_SEC = 20  # ëª©í‘œ 20ì´ˆ

    def __init__(self):
        self.cache_dir = Path("data/voice_samples/optimized")
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        print("[VoiceOptimizer] ì´ˆê¸°í™”")
        print(f"  ìµœì  êµ¬ê°„: {self.OPTIMAL_MIN_SEC}~{self.OPTIMAL_MAX_SEC}ì´ˆ")

    def optimize_for_cloning(
        self,
        audio_path: str,
        force: bool = False
    ) -> str:
        """
        Voice cloningì„ ìœ„í•œ ìµœì  êµ¬ê°„ ì¶”ì¶œ

        Args:
            audio_path: ì›ë³¸ ìŒì„± ê²½ë¡œ
            force: ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ì¶”ì¶œ

        Returns:
            ìµœì í™”ëœ ìŒì„± ê²½ë¡œ (15~30ì´ˆ)
        """

        if not os.path.exists(audio_path):
            print(f"[VoiceOptimizer] âŒ íŒŒì¼ ì—†ìŒ: {audio_path}")
            return audio_path

        # ìºì‹œ í™•ì¸
        cache_path = self._get_cache_path(audio_path)
        if cache_path.exists() and not force:
            print(f"[VoiceOptimizer] âœ… ìºì‹œ ì‚¬ìš©: {cache_path.name}")
            return str(cache_path)

        # ì˜¤ë””ì˜¤ ë¡œë“œ
        try:
            audio = AudioSegment.from_file(audio_path)
        except Exception as e:
            print(f"[VoiceOptimizer] âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return audio_path

        duration_sec = len(audio) / 1000
        print(f"\n[VoiceOptimizer] ì›ë³¸ ê¸¸ì´: {duration_sec:.1f}ì´ˆ")

        # ì´ë¯¸ ìµœì  ë²”ìœ„ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if self.OPTIMAL_MIN_SEC <= duration_sec <= self.OPTIMAL_MAX_SEC:
            print(f"[VoiceOptimizer] âœ… ì´ë¯¸ ìµœì  ë²”ìœ„")
            return audio_path

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if duration_sec < self.OPTIMAL_MIN_SEC:
            print(f"[VoiceOptimizer] âš ï¸ ë„ˆë¬´ ì§§ìŒ, ì›ë³¸ ì‚¬ìš©")
            return audio_path

        # ìµœì  êµ¬ê°„ ì¶”ì¶œ
        print(f"[VoiceOptimizer] ğŸ” ìµœì  êµ¬ê°„ ì¶”ì¶œ ì¤‘...")

        optimized = self._extract_best_segment(audio)

        # ì €ì¥
        optimized.export(
            str(cache_path),
            format="mp3",
            parameters=["-q:a", "2"]  # ê³ í’ˆì§ˆ
        )

        new_duration = len(optimized) / 1000
        print(f"[VoiceOptimizer] âœ… ìµœì í™” ì™„ë£Œ: {duration_sec:.1f}ì´ˆ â†’ {new_duration:.1f}ì´ˆ")
        print(f"[VoiceOptimizer] ğŸ“ ì €ì¥: {cache_path.name}")

        return str(cache_path)

    def _extract_best_segment(self, audio: AudioSegment) -> AudioSegment:
        """
        ìµœì  êµ¬ê°„ ì¶”ì¶œ

        ê¸°ì¤€:
        1. ìŒì„±ì´ ì—°ì†ì ì¸ êµ¬ê°„ (ë¬µìŒ ì ìŒ)
        2. ìŒëŸ‰ì´ ì•ˆì •ì ì¸ êµ¬ê°„
        3. ì‹œì‘ ë¶€ë¶„ë³´ë‹¤ ì¤‘ê°„ ë¶€ë¶„ ì„ í˜¸ (ì›Œë°ì—… í›„)
        """

        duration_ms = len(audio)
        target_ms = self.OPTIMAL_TARGET_SEC * 1000

        # í›„ë³´ êµ¬ê°„ë“¤ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        best_score = -1
        best_start = 0

        # 1ì´ˆ ë‹¨ìœ„ë¡œ ìŠ¤ìº”
        step_ms = 1000

        for start_ms in range(0, duration_ms - target_ms, step_ms):
            segment = audio[start_ms:start_ms + target_ms]
            score = self._calculate_segment_quality(segment, start_ms, duration_ms)

            if score > best_score:
                best_score = score
                best_start = start_ms

        print(f"  ìµœì  êµ¬ê°„: {best_start/1000:.1f}ì´ˆ ~ {(best_start + target_ms)/1000:.1f}ì´ˆ")
        print(f"  í’ˆì§ˆ ì ìˆ˜: {best_score:.3f}")

        return audio[best_start:best_start + target_ms]

    def _calculate_segment_quality(
        self,
        segment: AudioSegment,
        start_ms: int,
        total_ms: int
    ) -> float:
        """
        êµ¬ê°„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

        ì ìˆ˜ = ìŒì„±ë¹„ìœ¨(40%) + ìŒëŸ‰ì•ˆì •ì„±(30%) + ìœ„ì¹˜ì ìˆ˜(30%)
        """

        # 1. ìŒì„± ë¹„ìœ¨ (ë¬µìŒì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
        try:
            nonsilent = detect_nonsilent(
                segment,
                min_silence_len=100,
                silence_thresh=-40
            )
            speech_ms = sum(end - start for start, end in nonsilent) if nonsilent else len(segment)
            speech_ratio = speech_ms / len(segment)
        except:
            speech_ratio = 0.7

        # 2. ìŒëŸ‰ ì•ˆì •ì„± (ë³€í™”ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
        try:
            samples = np.array(segment.get_array_of_samples()).astype(np.float32)

            # í”„ë ˆì„ë³„ RMS
            frame_size = len(samples) // 20
            if frame_size > 0:
                rms_values = []
                for i in range(0, len(samples) - frame_size, frame_size):
                    frame = samples[i:i + frame_size]
                    rms = np.sqrt(np.mean(frame**2))
                    rms_values.append(rms)

                if rms_values:
                    mean_rms = np.mean(rms_values)
                    std_rms = np.std(rms_values)
                    stability = 1.0 - min(1.0, std_rms / (mean_rms + 1e-10))
                else:
                    stability = 0.5
            else:
                stability = 0.5
        except:
            stability = 0.5

        # 3. ìœ„ì¹˜ ì ìˆ˜ (ì‹œì‘ë³´ë‹¤ ì¤‘ê°„ ì„ í˜¸)
        position = start_ms / total_ms
        # 10%~50% êµ¬ê°„ ì„ í˜¸
        if 0.1 <= position <= 0.5:
            position_score = 1.0
        elif position < 0.1:
            position_score = position * 10  # 0~0.1 â†’ 0~1
        else:
            position_score = max(0, 1.0 - (position - 0.5))  # 0.5~1 â†’ 1~0

        # ì¢…í•© ì ìˆ˜
        score = (
            speech_ratio * 0.4 +
            stability * 0.3 +
            position_score * 0.3
        )

        return score

    def _get_cache_path(self, audio_path: str) -> Path:
        """ìºì‹œ ê²½ë¡œ ìƒì„±"""
        import hashlib

        # íŒŒì¼ í•´ì‹œë¡œ ê³ ìœ  ì´ë¦„ ìƒì„±
        with open(audio_path, "rb") as f:
            file_hash = hashlib.md5(f.read()[:10000]).hexdigest()[:8]

        original_name = Path(audio_path).stem
        cache_name = f"{original_name}_opt_{file_hash}.mp3"

        return self.cache_dir / cache_name


# VoiceOptimizer ì‹±ê¸€í†¤
_voice_optimizer = None

def get_voice_optimizer() -> VoiceOptimizer:
    """VoiceOptimizer ì‹±ê¸€í†¤"""
    global _voice_optimizer
    if _voice_optimizer is None:
        _voice_optimizer = VoiceOptimizer()
    return _voice_optimizer


def optimize_voice_for_cloning(audio_path: str, force: bool = False) -> str:
    """
    Voice cloningì„ ìœ„í•´ ì°¸ì¡° ìŒì„± ìµœì í™” (ê°„í¸ í•¨ìˆ˜)

    ì‚¬ìš© ì˜ˆ:
        optimized_path = optimize_voice_for_cloning("path/to/long_voice.mp3")
        # 15~30ì´ˆ êµ¬ê°„ìœ¼ë¡œ ìµœì í™”ëœ ê²½ë¡œ ë°˜í™˜
    """
    return get_voice_optimizer().optimize_for_cloning(audio_path, force)
